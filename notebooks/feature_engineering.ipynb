{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37155c0",
   "metadata": {},
   "source": [
    "### Moving onto feature engineering. Our goal is to Predict which products a user will reorder in their next purchase.\n",
    "\n",
    "### Instacart wants to improve product recommendation in their shopping cart reordering system by predicting the next set of items each customer will buy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c496e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4752437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Load Data ===\n",
    "orders = pd.read_csv('./data/orders.csv')\n",
    "products = pd.read_csv('./data/products.csv')\n",
    "order_products_prior = pd.read_csv('./data/order_products__prior.csv')\n",
    "order_products_train = pd.read_csv('./data/order_products__train.csv')\n",
    "aisles = pd.read_csv('./data/aisles.csv')\n",
    "departments = pd.read_csv('./data/departments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24fb5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384612</th>\n",
       "      <td>3421063</td>\n",
       "      <td>14233</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384613</th>\n",
       "      <td>3421063</td>\n",
       "      <td>35548</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384614</th>\n",
       "      <td>3421070</td>\n",
       "      <td>35951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384615</th>\n",
       "      <td>3421070</td>\n",
       "      <td>16953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384616</th>\n",
       "      <td>3421070</td>\n",
       "      <td>4724</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1384617 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered\n",
       "0               1       49302                  1          1\n",
       "1               1       11109                  2          1\n",
       "2               1       10246                  3          0\n",
       "3               1       49683                  4          0\n",
       "4               1       43633                  5          1\n",
       "...           ...         ...                ...        ...\n",
       "1384612   3421063       14233                  3          1\n",
       "1384613   3421063       35548                  4          1\n",
       "1384614   3421070       35951                  1          1\n",
       "1384615   3421070       16953                  2          1\n",
       "1384616   3421070        4724                  3          1\n",
       "\n",
       "[1384617 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91395dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32434489 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered\n",
       "0                2       33120                  1          1\n",
       "1                2       28985                  2          1\n",
       "2                2        9327                  3          0\n",
       "3                2       45918                  4          1\n",
       "4                2       30035                  5          0\n",
       "...            ...         ...                ...        ...\n",
       "32434484   3421083       39678                  6          1\n",
       "32434485   3421083       11352                  7          0\n",
       "32434486   3421083        4600                  8          0\n",
       "32434487   3421083       24852                  9          1\n",
       "32434488   3421083        5020                 10          1\n",
       "\n",
       "[32434489 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55ae30cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421078</th>\n",
       "      <td>2266710</td>\n",
       "      <td>206209</td>\n",
       "      <td>prior</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421079</th>\n",
       "      <td>1854736</td>\n",
       "      <td>206209</td>\n",
       "      <td>prior</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421080</th>\n",
       "      <td>626363</td>\n",
       "      <td>206209</td>\n",
       "      <td>prior</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421081</th>\n",
       "      <td>2977660</td>\n",
       "      <td>206209</td>\n",
       "      <td>prior</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421082</th>\n",
       "      <td>272231</td>\n",
       "      <td>206209</td>\n",
       "      <td>train</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3421083 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  user_id eval_set  order_number  order_dow  \\\n",
       "0         2539329        1    prior             1          2   \n",
       "1         2398795        1    prior             2          3   \n",
       "2          473747        1    prior             3          3   \n",
       "3         2254736        1    prior             4          4   \n",
       "4          431534        1    prior             5          4   \n",
       "...           ...      ...      ...           ...        ...   \n",
       "3421078   2266710   206209    prior            10          5   \n",
       "3421079   1854736   206209    prior            11          4   \n",
       "3421080    626363   206209    prior            12          1   \n",
       "3421081   2977660   206209    prior            13          1   \n",
       "3421082    272231   206209    train            14          6   \n",
       "\n",
       "         order_hour_of_day  days_since_prior_order  \n",
       "0                        8                     NaN  \n",
       "1                        7                    15.0  \n",
       "2                       12                    21.0  \n",
       "3                        7                    29.0  \n",
       "4                       15                    28.0  \n",
       "...                    ...                     ...  \n",
       "3421078                 18                    29.0  \n",
       "3421079                 10                    30.0  \n",
       "3421080                 12                    18.0  \n",
       "3421081                 12                     7.0  \n",
       "3421082                 14                    30.0  \n",
       "\n",
       "[3421083 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb24b62",
   "metadata": {},
   "source": [
    "Why are we given both prior and train?\n",
    "\n",
    "prior = Historical order data\n",
    "This is your feature generation base:\n",
    "\n",
    "- What each user has ordered before\n",
    "- When, how often, in what quantity, and in what order\n",
    "- Contains many past orders per user\n",
    "\n",
    "train = Label data (ground truth)\n",
    "This is what you use to train your model:\n",
    "\n",
    "It's each user's most recent known order\n",
    "\n",
    "You simulate predicting this order using only prior behavior\n",
    "\n",
    "It is like asking the question, “Given what this user did in the prior orders, can you predict which products they bought in their latest (train) order?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f5f34",
   "metadata": {},
   "source": [
    "💡 Analogy:\n",
    "- prior = Your model's memory of what the user likes\n",
    "- train = The correct answer you're trying to learn to predict\n",
    "- test = The future answer you'll predict (but don’t have labels for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8490c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32434489 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered\n",
       "0                2       33120                  1          1\n",
       "1                2       28985                  2          1\n",
       "2                2        9327                  3          0\n",
       "3                2       45918                  4          1\n",
       "4                2       30035                  5          0\n",
       "...            ...         ...                ...        ...\n",
       "32434484   3421083       39678                  6          1\n",
       "32434485   3421083       11352                  7          0\n",
       "32434486   3421083        4600                  8          0\n",
       "32434487   3421083       24852                  9          1\n",
       "32434488   3421083        5020                 10          1\n",
       "\n",
       "[32434489 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7edbb1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                       0\n",
       "user_id                        0\n",
       "eval_set                       0\n",
       "order_number                   0\n",
       "order_dow                      0\n",
       "order_hour_of_day              0\n",
       "days_since_prior_order    206209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0c634ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "product_id           0\n",
       "add_to_cart_order    0\n",
       "reordered            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products_prior.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "339e3bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                    int64\n",
      "user_id                     int64\n",
      "eval_set                   object\n",
      "order_number                int64\n",
      "order_dow                   int64\n",
      "order_hour_of_day           int64\n",
      "days_since_prior_order    float64\n",
      "dtype: object\n",
      "order_id             int64\n",
      "product_id           int64\n",
      "add_to_cart_order    int64\n",
      "reordered            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(orders.dtypes)\n",
    "print(order_products_prior.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4f554b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products_prior.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b60208f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this tells us who and when\n",
    "prior_orders = orders[orders['eval_set'] == 'prior'][['order_id', 'user_id', 'order_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f857379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421077</th>\n",
       "      <td>2558525</td>\n",
       "      <td>206209</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421078</th>\n",
       "      <td>2266710</td>\n",
       "      <td>206209</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421079</th>\n",
       "      <td>1854736</td>\n",
       "      <td>206209</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421080</th>\n",
       "      <td>626363</td>\n",
       "      <td>206209</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421081</th>\n",
       "      <td>2977660</td>\n",
       "      <td>206209</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214874 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  user_id  order_number\n",
       "0         2539329        1             1\n",
       "1         2398795        1             2\n",
       "2          473747        1             3\n",
       "3         2254736        1             4\n",
       "4          431534        1             5\n",
       "...           ...      ...           ...\n",
       "3421077   2558525   206209             9\n",
       "3421078   2266710   206209            10\n",
       "3421079   1854736   206209            11\n",
       "3421080    626363   206209            12\n",
       "3421081   2977660   206209            13\n",
       "\n",
       "[3214874 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4422620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32434489 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered\n",
       "0                2       33120                  1          1\n",
       "1                2       28985                  2          1\n",
       "2                2        9327                  3          0\n",
       "3                2       45918                  4          1\n",
       "4                2       30035                  5          0\n",
       "...            ...         ...                ...        ...\n",
       "32434484   3421083       39678                  6          1\n",
       "32434485   3421083       11352                  7          0\n",
       "32434486   3421083        4600                  8          0\n",
       "32434487   3421083       24852                  9          1\n",
       "32434488   3421083        5020                 10          1\n",
       "\n",
       "[32434489 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this tells us What\n",
    "order_products_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04b4a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_merged = order_products_prior.merge(prior_orders, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "852f00e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prior_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprior_merged\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prior_merged' is not defined"
     ]
    }
   ],
   "source": [
    "prior_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f4d3f",
   "metadata": {},
   "source": [
    "Lets step back and thing about what features are useful for predicting whether a user will reorder a product?\n",
    "\n",
    "- User Behavior: More orders means more reliable pattern. Someone who buys more frequently may mean they reorder more. Bigger baskets → higher reorder chance for staples\n",
    "- Staples like banana, milk will be rordered more frequentiy. Frequently bought = more likely to be reordered. Usually the product added earlier in the cart means they are more important\n",
    "- Relation between user and product: How many times this user bought this product? Recency — recently ordered → more likely to reorder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a8f11",
   "metadata": {},
   "source": [
    "### Product Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e3e5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each product was ordered and reordered\n",
    "# The result of the groupby will have 'product_id' as the index\n",
    "\n",
    "product_features = prior_merged.groupby('product_id').agg(\n",
    "    product_total_orders=('order_id', 'count'),\n",
    "    product_total_reorders=('reordered', 'sum')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01373a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the reorder rate for each product\n",
    "product_features['product_reorder_rate'] = product_features['product_total_reorders'] / product_features['product_total_orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1cec5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Product's Breadth (Unique Users)\n",
    "# This requires a simple groupby on prior_merged\n",
    "prod_unique_users = prior_merged.groupby('product_id')['user_id'].nunique().reset_index()\n",
    "prod_unique_users.rename(columns={'user_id': 'product_unique_users'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8633a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Product's Cart Position Statistics\n",
    "# Calculate both mean and standard deviation\n",
    "prod_cart_stats = prior_merged.groupby('product_id')['add_to_cart_order'].agg(['mean', 'std']).reset_index()\n",
    "prod_cart_stats.rename(columns={'mean': 'product_avg_cart_position', 'std': 'product_std_cart_position'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a2a079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaNs for std (products ordered only once have no std dev)\n",
    "prod_cart_stats.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13b31e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aisle and Department-Level Reorder Rates\n",
    "# We need to merge prior_merged with product/aisle/dept details first\n",
    "\n",
    "full_product_details = products.merge(aisles, on='aisle_id').merge(departments, on='department_id')\n",
    "prior_merged_full = prior_merged.merge(full_product_details[['product_id', 'aisle_id', 'department_id']], on='product_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "83e48162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate reorder rates at the aisle and department level\n",
    "aisle_reorder_rate = prior_merged_full.groupby('aisle_id')['reordered'].mean().reset_index()\n",
    "aisle_reorder_rate.rename(columns={'reordered': 'aisle_reorder_rate'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "338f17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_reorder_rate = prior_merged_full.groupby('department_id')['reordered'].mean().reset_index()\n",
    "dept_reorder_rate.rename(columns={'reordered': 'dept_reorder_rate'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c76212bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_features = product_features.merge(prod_unique_users, on='product_id', how='left')\n",
    "product_features = product_features.merge(prod_cart_stats, on='product_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d070457",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_features = product_features.merge(products[['product_id', 'aisle_id', 'department_id']], on='product_id', how='left')\n",
    "product_features = product_features.merge(aisle_reorder_rate, on='aisle_id', how='left')\n",
    "product_features = product_features.merge(dept_reorder_rate, on='department_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49b43c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_total_orders</th>\n",
       "      <th>product_total_reorders</th>\n",
       "      <th>product_reorder_rate</th>\n",
       "      <th>product_unique_users</th>\n",
       "      <th>product_avg_cart_position</th>\n",
       "      <th>product_std_cart_position</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>aisle_reorder_rate</th>\n",
       "      <th>dept_reorder_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1852</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.613391</td>\n",
       "      <td>716</td>\n",
       "      <td>5.801836</td>\n",
       "      <td>5.575389</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>0.548698</td>\n",
       "      <td>0.574180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>78</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>7.821670</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>0.152391</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>203</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>74</td>\n",
       "      <td>6.415162</td>\n",
       "      <td>6.472701</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>0.527615</td>\n",
       "      <td>0.653460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>329</td>\n",
       "      <td>147</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>182</td>\n",
       "      <td>9.507599</td>\n",
       "      <td>6.861485</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556655</td>\n",
       "      <td>0.541885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>3.563038</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.280627</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49672</th>\n",
       "      <td>49684</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>8</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>0.572344</td>\n",
       "      <td>0.569924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49673</th>\n",
       "      <td>49685</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>43</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>9.652288</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542171</td>\n",
       "      <td>0.541885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49674</th>\n",
       "      <td>49686</td>\n",
       "      <td>120</td>\n",
       "      <td>84</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>36</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5.447997</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>0.670168</td>\n",
       "      <td>0.628141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49675</th>\n",
       "      <td>49687</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>7</td>\n",
       "      <td>7.538462</td>\n",
       "      <td>9.315000</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>0.620883</td>\n",
       "      <td>0.601285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49676</th>\n",
       "      <td>49688</td>\n",
       "      <td>89</td>\n",
       "      <td>15</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>74</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.921374</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>0.316871</td>\n",
       "      <td>0.321129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49677 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  product_total_orders  product_total_reorders  \\\n",
       "0               1                  1852                    1136   \n",
       "1               2                    90                      12   \n",
       "2               3                   277                     203   \n",
       "3               4                   329                     147   \n",
       "4               5                    15                       9   \n",
       "...           ...                   ...                     ...   \n",
       "49672       49684                     9                       1   \n",
       "49673       49685                    49                       6   \n",
       "49674       49686                   120                      84   \n",
       "49675       49687                    13                       6   \n",
       "49676       49688                    89                      15   \n",
       "\n",
       "       product_reorder_rate  product_unique_users  product_avg_cart_position  \\\n",
       "0                  0.613391                   716                   5.801836   \n",
       "1                  0.133333                    78                   9.888889   \n",
       "2                  0.732852                    74                   6.415162   \n",
       "3                  0.446809                   182                   9.507599   \n",
       "4                  0.600000                     6                   6.466667   \n",
       "...                     ...                   ...                        ...   \n",
       "49672              0.111111                     8                   4.333333   \n",
       "49673              0.122449                    43                   9.571429   \n",
       "49674              0.700000                    36                   7.500000   \n",
       "49675              0.461538                     7                   7.538462   \n",
       "49676              0.168539                    74                  10.000000   \n",
       "\n",
       "       product_std_cart_position  aisle_id  department_id  aisle_reorder_rate  \\\n",
       "0                       5.575389        61             19            0.548698   \n",
       "1                       7.821670       104             13            0.152391   \n",
       "2                       6.472701        94              7            0.527615   \n",
       "3                       6.861485        38              1            0.556655   \n",
       "4                       3.563038         5             13            0.280627   \n",
       "...                          ...       ...            ...                 ...   \n",
       "49672                   2.449490       124              5            0.572344   \n",
       "49673                   9.652288        42              1            0.542171   \n",
       "49674                   5.447997       112              3            0.670168   \n",
       "49675                   9.315000        41              8            0.620883   \n",
       "49676                   8.921374        73             11            0.316871   \n",
       "\n",
       "       dept_reorder_rate  \n",
       "0               0.574180  \n",
       "1               0.346721  \n",
       "2               0.653460  \n",
       "3               0.541885  \n",
       "4               0.346721  \n",
       "...                  ...  \n",
       "49672           0.569924  \n",
       "49673           0.541885  \n",
       "49674           0.628141  \n",
       "49675           0.601285  \n",
       "49676           0.321129  \n",
       "\n",
       "[49677 rows x 11 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9874ad4",
   "metadata": {},
   "source": [
    "## User-Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41fc9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_order_stats = orders[orders['eval_set'] == 'prior'].groupby('user_id').agg(\n",
    "    user_total_orders=('order_number', 'max'),\n",
    "    user_avg_days_since_prior=('days_since_prior_order', 'mean'),\n",
    "    user_std_days_since_prior=('days_since_prior_order', 'std')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "11f3ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Features from 'prior_merged' (Product Interactions)\n",
    "user_product_stats = prior_merged.groupby('user_id').agg(\n",
    "    user_total_products=('product_id', 'count'),\n",
    "    user_distinct_products=('product_id', 'nunique'),\n",
    "    user_reorder_ratio=('reordered', 'mean')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb7b1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Features for Basket Size Consistency\n",
    "# First, calculate the size of each individual basket\n",
    "user_basket_size = prior_merged.groupby(['user_id', 'order_number']).size().reset_index(name='basket_size')\n",
    "# Now, calculate the mean and std of basket sizes for each user\n",
    "user_basket_consistency = user_basket_size.groupby('user_id')['basket_size'].agg(['mean', 'std']).reset_index()\n",
    "user_basket_consistency.rename(columns={'mean': 'user_avg_basket_size', 'std': 'user_std_basket_size'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b09d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the main order stats\n",
    "user_features = user_order_stats.merge(user_product_stats, on='user_id', how='left')\n",
    "user_features = user_features.merge(user_basket_consistency, on='user_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "443f224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate the final exploration ratio feature\n",
    "user_features['user_distinct_product_ratio'] = user_features['user_distinct_products'] / user_features['user_total_products']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f57ffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaNs that appear for users with only one order (no std dev)\n",
    "user_features.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b9485e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_total_orders</th>\n",
       "      <th>user_avg_days_since_prior</th>\n",
       "      <th>user_std_days_since_prior</th>\n",
       "      <th>user_total_products</th>\n",
       "      <th>user_distinct_products</th>\n",
       "      <th>user_reorder_ratio</th>\n",
       "      <th>user_avg_basket_size</th>\n",
       "      <th>user_std_basket_size</th>\n",
       "      <th>user_distinct_product_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>9.395625</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>1.523884</td>\n",
       "      <td>0.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>9.867065</td>\n",
       "      <td>195</td>\n",
       "      <td>102</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>5.717238</td>\n",
       "      <td>0.523077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>12.090909</td>\n",
       "      <td>5.375026</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>2.103388</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.073644</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>4.932883</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>3.095696</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206204</th>\n",
       "      <td>206205</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.142136</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.507571</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206205</th>\n",
       "      <td>206206</td>\n",
       "      <td>67</td>\n",
       "      <td>3.772727</td>\n",
       "      <td>3.294730</td>\n",
       "      <td>285</td>\n",
       "      <td>150</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>4.253731</td>\n",
       "      <td>3.230270</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206206</th>\n",
       "      <td>206207</td>\n",
       "      <td>16</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>11.536691</td>\n",
       "      <td>223</td>\n",
       "      <td>92</td>\n",
       "      <td>0.587444</td>\n",
       "      <td>13.937500</td>\n",
       "      <td>6.038419</td>\n",
       "      <td>0.412556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206207</th>\n",
       "      <td>206208</td>\n",
       "      <td>49</td>\n",
       "      <td>7.437500</td>\n",
       "      <td>4.109699</td>\n",
       "      <td>677</td>\n",
       "      <td>198</td>\n",
       "      <td>0.707533</td>\n",
       "      <td>13.816327</td>\n",
       "      <td>5.592679</td>\n",
       "      <td>0.292467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206208</th>\n",
       "      <td>206209</td>\n",
       "      <td>13</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>11.098730</td>\n",
       "      <td>129</td>\n",
       "      <td>68</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>9.923077</td>\n",
       "      <td>5.345739</td>\n",
       "      <td>0.527132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206209 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  user_total_orders  user_avg_days_since_prior  \\\n",
       "0             1                 10                  19.555556   \n",
       "1             2                 14                  15.230769   \n",
       "2             3                 12                  12.090909   \n",
       "3             4                  5                  13.750000   \n",
       "4             5                  4                  13.333333   \n",
       "...         ...                ...                        ...   \n",
       "206204   206205                  3                  20.000000   \n",
       "206205   206206                 67                   3.772727   \n",
       "206206   206207                 16                  14.333333   \n",
       "206207   206208                 49                   7.437500   \n",
       "206208   206209                 13                  17.500000   \n",
       "\n",
       "        user_std_days_since_prior  user_total_products  \\\n",
       "0                        9.395625                   59   \n",
       "1                        9.867065                  195   \n",
       "2                        5.375026                   88   \n",
       "3                        9.500000                   18   \n",
       "4                        4.932883                   37   \n",
       "...                           ...                  ...   \n",
       "206204                  14.142136                   32   \n",
       "206205                   3.294730                  285   \n",
       "206206                  11.536691                  223   \n",
       "206207                   4.109699                  677   \n",
       "206208                  11.098730                  129   \n",
       "\n",
       "        user_distinct_products  user_reorder_ratio  user_avg_basket_size  \\\n",
       "0                           18            0.694915              5.900000   \n",
       "1                          102            0.476923             13.928571   \n",
       "2                           33            0.625000              7.333333   \n",
       "3                           17            0.055556              3.600000   \n",
       "4                           23            0.378378              9.250000   \n",
       "...                        ...                 ...                   ...   \n",
       "206204                      24            0.250000             10.666667   \n",
       "206205                     150            0.473684              4.253731   \n",
       "206206                      92            0.587444             13.937500   \n",
       "206207                     198            0.707533             13.816327   \n",
       "206208                      68            0.472868              9.923077   \n",
       "\n",
       "        user_std_basket_size  user_distinct_product_ratio  \n",
       "0                   1.523884                     0.305085  \n",
       "1                   5.717238                     0.523077  \n",
       "2                   2.103388                     0.375000  \n",
       "3                   2.073644                     0.944444  \n",
       "4                   3.095696                     0.621622  \n",
       "...                      ...                          ...  \n",
       "206204              5.507571                     0.750000  \n",
       "206205              3.230270                     0.526316  \n",
       "206206              6.038419                     0.412556  \n",
       "206207              5.592679                     0.292467  \n",
       "206208              5.345739                     0.527132  \n",
       "\n",
       "[206209 rows x 10 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fda9c6",
   "metadata": {},
   "source": [
    "## The most predictive part of feature engineering. User-product interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de61fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate basic UP interaction stats in one go\n",
    "up_features = prior_merged.groupby(['user_id', 'product_id']).agg(\n",
    "    up_total_purchases=('order_id', 'count'),\n",
    "    up_first_order_number=('order_number', 'min'),\n",
    "    up_last_order_number=('order_number', 'max'),\n",
    "    up_avg_cart_position=('add_to_cart_order', 'mean')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c5f999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Merge with user_features to get user_total_orders\n",
    "# This is essential for calculating recency and loyalty rates\n",
    "up_features = up_features.merge(user_features[['user_id', 'user_total_orders']], on='user_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45a2888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate the advanced recency and loyalty features\n",
    "# RECENCY: How many orders ago was the last purchase?\n",
    "up_features['up_orders_since_last_purchase'] = up_features['user_total_orders'] - up_features['up_last_order_number']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "14aed405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOYALTY: In what ratio of orders has the user bought this product since first trying it?\n",
    "# The denominator is the number of orders placed since the first purchase. Add 1 to include the first order itself.\n",
    "up_features['up_reorder_rate'] = up_features['up_total_purchases'] / (up_features['user_total_orders'] - up_features['up_first_order_number'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "732b538f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>up_total_purchases</th>\n",
       "      <th>up_first_order_number</th>\n",
       "      <th>up_last_order_number</th>\n",
       "      <th>up_avg_cart_position</th>\n",
       "      <th>user_total_orders</th>\n",
       "      <th>up_orders_since_last_purchase</th>\n",
       "      <th>up_reorder_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307948</th>\n",
       "      <td>206209</td>\n",
       "      <td>43961</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307949</th>\n",
       "      <td>206209</td>\n",
       "      <td>44325</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307950</th>\n",
       "      <td>206209</td>\n",
       "      <td>48370</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307951</th>\n",
       "      <td>206209</td>\n",
       "      <td>48697</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307952</th>\n",
       "      <td>206209</td>\n",
       "      <td>48742</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13307953 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  product_id  up_total_purchases  up_first_order_number  \\\n",
       "0               1         196                  10                      1   \n",
       "1               1       10258                   9                      2   \n",
       "2               1       10326                   1                      5   \n",
       "3               1       12427                  10                      1   \n",
       "4               1       13032                   3                      2   \n",
       "...           ...         ...                 ...                    ...   \n",
       "13307948   206209       43961                   3                      4   \n",
       "13307949   206209       44325                   1                      7   \n",
       "13307950   206209       48370                   1                     11   \n",
       "13307951   206209       48697                   1                      7   \n",
       "13307952   206209       48742                   2                      7   \n",
       "\n",
       "          up_last_order_number  up_avg_cart_position  user_total_orders  \\\n",
       "0                           10              1.400000                 10   \n",
       "1                           10              3.333333                 10   \n",
       "2                            5              5.000000                 10   \n",
       "3                           10              3.300000                 10   \n",
       "4                           10              6.333333                 10   \n",
       "...                        ...                   ...                ...   \n",
       "13307948                    12              8.000000                 13   \n",
       "13307949                     7              8.000000                 13   \n",
       "13307950                    11              8.000000                 13   \n",
       "13307951                     7              6.000000                 13   \n",
       "13307952                    12              9.000000                 13   \n",
       "\n",
       "          up_orders_since_last_purchase  up_reorder_rate  \n",
       "0                                     0         1.000000  \n",
       "1                                     0         1.000000  \n",
       "2                                     5         0.166667  \n",
       "3                                     0         1.000000  \n",
       "4                                     0         0.333333  \n",
       "...                                 ...              ...  \n",
       "13307948                              1         0.300000  \n",
       "13307949                              6         0.142857  \n",
       "13307950                              2         0.333333  \n",
       "13307951                              6         0.142857  \n",
       "13307952                              1         0.285714  \n",
       "\n",
       "[13307953 rows x 9 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca4fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "37a220a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembling the final training dataset...\n"
     ]
    }
   ],
   "source": [
    "# --- Assemble the Training Data ---\n",
    "print(\"Assembling the final training dataset...\")\n",
    "\n",
    "# 1. Get the 'train' orders from the main orders table. This tells us which user corresponds to which 'train' order.\n",
    "train_orders = orders[orders['eval_set'] == 'train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ba4f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_20768\\3602360003.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_labels['reordered'] = 1\n"
     ]
    }
   ],
   "source": [
    "train_labels = order_products_train[['order_id', 'product_id']]\n",
    "train_labels['reordered'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1beea9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge the labels with the train_orders to link them to a user_id.\n",
    "train_labels = train_orders.merge(train_labels, on='order_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "893b2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The candidates are all the unique (user_id, product_id) pairs from their entire prior history.\n",
    "# We can get this directly from our 'up_features' DataFrame, as it contains every historical user-product interaction.\n",
    "candidates = up_features[['user_id', 'product_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a807a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only care about users who are in the training set for this step.\n",
    "candidates = candidates[candidates['user_id'].isin(train_orders['user_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "64befbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_20768\\3539146209.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['reordered'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 4. Merge the candidates with the labels.\n",
    "# We use a 'left' merge to keep every candidate. If a product wasn't in the train_labels,\n",
    "# its 'reordered' value will be NaN. We'll fill these NaNs with 0.\n",
    "data = candidates.merge(train_labels[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n",
    "data['reordered'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e7c62aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474656</th>\n",
       "      <td>206209</td>\n",
       "      <td>43961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474657</th>\n",
       "      <td>206209</td>\n",
       "      <td>44325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474658</th>\n",
       "      <td>206209</td>\n",
       "      <td>48370</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474659</th>\n",
       "      <td>206209</td>\n",
       "      <td>48697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474660</th>\n",
       "      <td>206209</td>\n",
       "      <td>48742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474661 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  product_id  reordered\n",
       "0              1         196        1.0\n",
       "1              1       10258        1.0\n",
       "2              1       10326        0.0\n",
       "3              1       12427        0.0\n",
       "4              1       13032        1.0\n",
       "...          ...         ...        ...\n",
       "8474656   206209       43961        0.0\n",
       "8474657   206209       44325        0.0\n",
       "8474658   206209       48370        0.0\n",
       "8474659   206209       48697        0.0\n",
       "8474660   206209       48742        0.0\n",
       "\n",
       "[8474661 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdddc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "afafa1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging all feature sets...\n"
     ]
    }
   ],
   "source": [
    "# --- Merge all features onto the labeled data ---\n",
    "print(\"Merging all feature sets...\")\n",
    "\n",
    "# Merge User-Product features\n",
    "data = data.merge(up_features, on=['user_id', 'product_id'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4676315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge User features\n",
    "data = data.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "# Merge Product features\n",
    "data = data.merge(product_features, on='product_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e7a8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are leaky or no longer needed\n",
    "data.drop(['aisle_id', 'department_id'], axis=1, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11a4f126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reordered</th>\n",
       "      <th>up_total_purchases</th>\n",
       "      <th>up_first_order_number</th>\n",
       "      <th>up_last_order_number</th>\n",
       "      <th>up_avg_cart_position</th>\n",
       "      <th>user_total_orders_x</th>\n",
       "      <th>up_orders_since_last_purchase</th>\n",
       "      <th>up_reorder_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>user_std_basket_size</th>\n",
       "      <th>user_distinct_product_ratio</th>\n",
       "      <th>product_total_orders</th>\n",
       "      <th>product_total_reorders</th>\n",
       "      <th>product_reorder_rate</th>\n",
       "      <th>product_unique_users</th>\n",
       "      <th>product_avg_cart_position</th>\n",
       "      <th>product_std_cart_position</th>\n",
       "      <th>aisle_reorder_rate</th>\n",
       "      <th>dept_reorder_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523884</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>35791</td>\n",
       "      <td>27791</td>\n",
       "      <td>0.776480</td>\n",
       "      <td>8000</td>\n",
       "      <td>3.721774</td>\n",
       "      <td>4.110813</td>\n",
       "      <td>0.638832</td>\n",
       "      <td>0.653460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523884</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>1946</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.713772</td>\n",
       "      <td>557</td>\n",
       "      <td>4.277492</td>\n",
       "      <td>3.567502</td>\n",
       "      <td>0.519170</td>\n",
       "      <td>0.574180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523884</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>5526</td>\n",
       "      <td>3603</td>\n",
       "      <td>0.652009</td>\n",
       "      <td>1923</td>\n",
       "      <td>4.191097</td>\n",
       "      <td>3.611700</td>\n",
       "      <td>0.718104</td>\n",
       "      <td>0.649913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523884</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>6476</td>\n",
       "      <td>4797</td>\n",
       "      <td>0.740735</td>\n",
       "      <td>1679</td>\n",
       "      <td>4.760037</td>\n",
       "      <td>4.782450</td>\n",
       "      <td>0.591986</td>\n",
       "      <td>0.574180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523884</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>3751</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.657158</td>\n",
       "      <td>1286</td>\n",
       "      <td>5.622767</td>\n",
       "      <td>5.345184</td>\n",
       "      <td>0.571584</td>\n",
       "      <td>0.560922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474656</th>\n",
       "      <td>206209</td>\n",
       "      <td>43961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.345739</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>55371</td>\n",
       "      <td>34916</td>\n",
       "      <td>0.630583</td>\n",
       "      <td>20455</td>\n",
       "      <td>9.194723</td>\n",
       "      <td>6.846376</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.649913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474657</th>\n",
       "      <td>206209</td>\n",
       "      <td>44325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>5.345739</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>3485</td>\n",
       "      <td>1398</td>\n",
       "      <td>0.401148</td>\n",
       "      <td>2087</td>\n",
       "      <td>10.109900</td>\n",
       "      <td>7.696170</td>\n",
       "      <td>0.453062</td>\n",
       "      <td>0.461076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474658</th>\n",
       "      <td>206209</td>\n",
       "      <td>48370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>5.345739</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>3934</td>\n",
       "      <td>2751</td>\n",
       "      <td>0.699288</td>\n",
       "      <td>1183</td>\n",
       "      <td>8.344942</td>\n",
       "      <td>7.257547</td>\n",
       "      <td>0.528005</td>\n",
       "      <td>0.402178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474659</th>\n",
       "      <td>206209</td>\n",
       "      <td>48697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>5.345739</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>9783</td>\n",
       "      <td>3499</td>\n",
       "      <td>0.357661</td>\n",
       "      <td>6284</td>\n",
       "      <td>8.763058</td>\n",
       "      <td>7.582887</td>\n",
       "      <td>0.350843</td>\n",
       "      <td>0.346721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474660</th>\n",
       "      <td>206209</td>\n",
       "      <td>48742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>5.345739</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>1723</td>\n",
       "      <td>859</td>\n",
       "      <td>0.498549</td>\n",
       "      <td>864</td>\n",
       "      <td>7.991294</td>\n",
       "      <td>7.076850</td>\n",
       "      <td>0.499501</td>\n",
       "      <td>0.560922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474661 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  product_id  reordered  up_total_purchases  \\\n",
       "0              1         196        1.0                  10   \n",
       "1              1       10258        1.0                   9   \n",
       "2              1       10326        0.0                   1   \n",
       "3              1       12427        0.0                  10   \n",
       "4              1       13032        1.0                   3   \n",
       "...          ...         ...        ...                 ...   \n",
       "8474656   206209       43961        0.0                   3   \n",
       "8474657   206209       44325        0.0                   1   \n",
       "8474658   206209       48370        0.0                   1   \n",
       "8474659   206209       48697        0.0                   1   \n",
       "8474660   206209       48742        0.0                   2   \n",
       "\n",
       "         up_first_order_number  up_last_order_number  up_avg_cart_position  \\\n",
       "0                            1                    10              1.400000   \n",
       "1                            2                    10              3.333333   \n",
       "2                            5                     5              5.000000   \n",
       "3                            1                    10              3.300000   \n",
       "4                            2                    10              6.333333   \n",
       "...                        ...                   ...                   ...   \n",
       "8474656                      4                    12              8.000000   \n",
       "8474657                      7                     7              8.000000   \n",
       "8474658                     11                    11              8.000000   \n",
       "8474659                      7                     7              6.000000   \n",
       "8474660                      7                    12              9.000000   \n",
       "\n",
       "         user_total_orders_x  up_orders_since_last_purchase  up_reorder_rate  \\\n",
       "0                         10                              0         1.000000   \n",
       "1                         10                              0         1.000000   \n",
       "2                         10                              5         0.166667   \n",
       "3                         10                              0         1.000000   \n",
       "4                         10                              0         0.333333   \n",
       "...                      ...                            ...              ...   \n",
       "8474656                   13                              1         0.300000   \n",
       "8474657                   13                              6         0.142857   \n",
       "8474658                   13                              2         0.333333   \n",
       "8474659                   13                              6         0.142857   \n",
       "8474660                   13                              1         0.285714   \n",
       "\n",
       "         ...  user_std_basket_size  user_distinct_product_ratio  \\\n",
       "0        ...              1.523884                     0.305085   \n",
       "1        ...              1.523884                     0.305085   \n",
       "2        ...              1.523884                     0.305085   \n",
       "3        ...              1.523884                     0.305085   \n",
       "4        ...              1.523884                     0.305085   \n",
       "...      ...                   ...                          ...   \n",
       "8474656  ...              5.345739                     0.527132   \n",
       "8474657  ...              5.345739                     0.527132   \n",
       "8474658  ...              5.345739                     0.527132   \n",
       "8474659  ...              5.345739                     0.527132   \n",
       "8474660  ...              5.345739                     0.527132   \n",
       "\n",
       "         product_total_orders  product_total_reorders  product_reorder_rate  \\\n",
       "0                       35791                   27791              0.776480   \n",
       "1                        1946                    1389              0.713772   \n",
       "2                        5526                    3603              0.652009   \n",
       "3                        6476                    4797              0.740735   \n",
       "4                        3751                    2465              0.657158   \n",
       "...                       ...                     ...                   ...   \n",
       "8474656                 55371                   34916              0.630583   \n",
       "8474657                  3485                    1398              0.401148   \n",
       "8474658                  3934                    2751              0.699288   \n",
       "8474659                  9783                    3499              0.357661   \n",
       "8474660                  1723                     859              0.498549   \n",
       "\n",
       "         product_unique_users  product_avg_cart_position  \\\n",
       "0                        8000                   3.721774   \n",
       "1                         557                   4.277492   \n",
       "2                        1923                   4.191097   \n",
       "3                        1679                   4.760037   \n",
       "4                        1286                   5.622767   \n",
       "...                       ...                        ...   \n",
       "8474656                 20455                   9.194723   \n",
       "8474657                  2087                  10.109900   \n",
       "8474658                  1183                   8.344942   \n",
       "8474659                  6284                   8.763058   \n",
       "8474660                   864                   7.991294   \n",
       "\n",
       "         product_std_cart_position  aisle_reorder_rate  dept_reorder_rate  \n",
       "0                         4.110813            0.638832           0.653460  \n",
       "1                         3.567502            0.519170           0.574180  \n",
       "2                         3.611700            0.718104           0.649913  \n",
       "3                         4.782450            0.591986           0.574180  \n",
       "4                         5.345184            0.571584           0.560922  \n",
       "...                            ...                 ...                ...  \n",
       "8474656                   6.846376            0.638514           0.649913  \n",
       "8474657                   7.696170            0.453062           0.461076  \n",
       "8474658                   7.257547            0.528005           0.402178  \n",
       "8474659                   7.582887            0.350843           0.346721  \n",
       "8474660                   7.076850            0.499501           0.560922  \n",
       "\n",
       "[8474661 rows x 27 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a23861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b8dff23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de57eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our features (X) and target (y)\n",
    "# We drop user_id and product_id as they are identifiers, not features.\n",
    "X = data.drop(['user_id', 'product_id', 'reordered'], axis=1)\n",
    "y = data['reordered']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fd718c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbe2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and validation set (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1113e0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (6779728, 24)\n",
      "Validation set shape: (1694933, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2a518f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training XGBoost ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training XGBoost ---\")\n",
    "\n",
    "# Define the XGBoost classifier with some common parameters\n",
    "# 'objective': 'binary:logistic' for binary classification\n",
    "# 'eval_metric': 'logloss' is a good choice for binary classification\n",
    "# 'n_estimators': A high number, but early stopping will find the optimal number\n",
    "# 'use_label_encoder=False' is modern best practice\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    early_stopping_rounds=50,  # 🔑 Move it here\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59be66e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [11:05:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.30421\n",
      "[50]\tvalidation_0-logloss:0.24706\n",
      "[100]\tvalidation_0-logloss:0.24641\n",
      "[150]\tvalidation_0-logloss:0.24612\n",
      "[200]\tvalidation_0-logloss:0.24589\n",
      "[250]\tvalidation_0-logloss:0.24570\n",
      "[300]\tvalidation_0-logloss:0.24553\n",
      "[350]\tvalidation_0-logloss:0.24537\n",
      "[400]\tvalidation_0-logloss:0.24524\n",
      "[450]\tvalidation_0-logloss:0.24511\n",
      "[500]\tvalidation_0-logloss:0.24500\n",
      "[550]\tvalidation_0-logloss:0.24489\n",
      "[600]\tvalidation_0-logloss:0.24480\n",
      "[650]\tvalidation_0-logloss:0.24473\n",
      "[700]\tvalidation_0-logloss:0.24466\n",
      "[750]\tvalidation_0-logloss:0.24459\n",
      "[800]\tvalidation_0-logloss:0.24451\n",
      "[850]\tvalidation_0-logloss:0.24445\n",
      "[900]\tvalidation_0-logloss:0.24438\n",
      "[950]\tvalidation_0-logloss:0.24433\n",
      "[999]\tvalidation_0-logloss:0.24427\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# We provide the validation set to 'eval_set' to monitor performance\n",
    "# 'early_stopping_rounds' will stop training if the validation score doesn't improve for 50 rounds\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=50) # Print progress every 50 trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14d011a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Validation AUC: 0.8358\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "y_pred_xgb = xgb_clf.predict_proba(X_val)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_val, y_pred_xgb)\n",
    "print(f\"\\nXGBoost Validation AUC: {auc_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58dc9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training LightGBM ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training LightGBM ---\")\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='logloss',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c1dc98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 663059, number of negative: 6116669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.319137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4780\n",
      "[LightGBM] [Info] Number of data points in the train set: 6779728, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.097800 -> initscore=-2.221909\n",
      "[LightGBM] [Info] Start training from score -2.221909\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.245013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;logloss&#x27;, n_estimators=1000, n_jobs=-1,\n",
       "               objective=&#x27;binary&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(metric=&#x27;logloss&#x27;, n_estimators=1000, n_jobs=-1,\n",
       "               objective=&#x27;binary&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='logloss', n_estimators=1000, n_jobs=-1,\n",
       "               objective='binary', random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf.fit(X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='logloss',\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6eb5c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Validation AUC: 0.8345\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "y_pred_lgb = lgb_clf.predict_proba(X_val)[:, 1]\n",
    "auc_lgb = roc_auc_score(y_val, y_pred_lgb)\n",
    "print(f\"\\nLightGBM Validation AUC: {auc_lgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82a93b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81a83226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABxUAAANXCAYAAADzVAHvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA94lJREFUeJzs3QWYldX6N+CFIKmgoKigggoGGNgt2KCoiArGEbsLW4/HDlQM7FbsTjzGsVBsQLG7u8XCnu961vft/e0ZZjYzCAxx39e1/zPz5nrXuznX9T+/8zyrQUVFRUUCAAAAAAAAqMFMNe0AAAAAAAAACEJFAAAAAAAAoCyhIgAAAAAAAFCWUBEAAAAAAAAoS6gIAAAAAAAAlCVUBAAAAAAAAMoSKgIAAAAAAABlCRUBAAAAAACAsoSKAAAAAAAAQFlCRQAAgKnc+++/nxo0aJCGDh060eeedtppk2VswMT5+++/0+KLL55OPPHENL375ptvUosWLdI999xT30MBAOAfECoCAADUowgKI/QbNWpUfQ8l/xf+xxxzTI37f/vtt3TOOeek1VZbLc0+++ypcePGqV27dmnjjTdO119/ffrrr7/GCzNLPy1btkzdunVL5557bqVjQ48ePfIxnTt3rvbeDzzwQPE6t9xyS9nnqO7ehc9KK62UJodPP/00z92YMWPS1GZ6CJYn9N2cFsW/mY8++ijtvffe+e+avrNVP8OHD5+s44oxHXvssWmFFVbI/87nmGOO/O/zwQcfrPb477//Pu26665pzjnnzMHhmmuumZ577rlKx7Rp0ybtvPPO6cgjj5ysYwcAYPJqNJmvDwAAwD/UoUOHNG7cuDTzzDNP9uDmvPPOqza8+eqrr1KvXr3S6NGj0/rrr5/+85//pNatW6fPP/88hw1bb711evvtt8cLDbbaaqu0wQYb5N/Hjh2b77HPPvukDz74IA0ePLjSsU2bNs3XePbZZ3OgUeraa6/N+3/99ddaP0/pvQsi+JhcoWIEMR07dszBKVPuuzmtiu//lltumVq1apX/vvrqqyvtv+qqq3KYXnX7YostNlnHdeedd6ZTTjkl9enTJ2233Xbpzz//zGNZd9110+WXX5522GGHStWWG264YXrhhRfSwQcfnAPI888/P4eQ8Z8Vpf8jgd133z2dffbZ6eGHH05rrbXWZH0GAAAmD6EiAADAVC6qkyJQq0/bbrttev7559Ott96a+vbtW2nf4Ycfnist33jjjfHOW2aZZdK//vWv4t977rlnWnHFFdN11103Xqi40EIL5QAjKrhKQ8UIEm+//fYcXsT9a6vqvadF8exRETrTTDNmo6Gff/45V79Nb+LfUgRxp59+enFb1e/q008/nUPFKf0djkrDDz/8MAeEpYFghOVHHXVUpVAxqoaffPLJdPPNN6fNN988b+vXr19aeOGF09FHH53/nZeGodHuNaqzhYoAANOmGfP/KwEAAJgO1lSM/yK/S5cuOXCM/7I+grftt98+V8tV5+KLL87BXZMmTdLyyy+fRo4cWdwX50UlWChttRieeuqpdP/99+cWh1UDxYLlllsubbPNNhN8lrjmXHPNlRo1alRjdeGNN96YK6AKhg0bln755ZccVkxKr7/+eg5CouIy5jCe4a677qp0zLfffpsOOuigtMQSS6RZZpklt3CNis0IhAqiHWXMZ4jApTB3hfcV7yPmt6qo5opP6XXivBtuuCFXgrZv3z41b948/fDDD3n/M888k3r27Jkr22J79+7d0xNPPPGP2u4+/vjjad99980VnLPNNlvabbfd0u+//55bWg4YMCC3v4zPIYcckioqKqptqXrmmWfmatpmzZrlMb388svj3S+q01ZfffUcEMZ9Ntlkk/Taa69VOiaqEOOar776aq58jftGq91y380QY1hllVVyi80Yw7LLLltti9w4J1qN3nHHHfnfS/w76Nq1a7rvvvvGO/aTTz5JO+20U27vG8ctsMACaY899shzUxBzNHDgwDTffPPlYzp16pQr/Eq/uzWJMURYvMYaa6S6hqwHHnhg8Z6LLLJIfv7Sd1P6rFHhG8fE9zvm5bHHHpvgPWJOSgPFEPeKqt+PP/44/fjjj8XtMc/x77n0PxfiuxT/VqPiMVoml4pqx/j3XHW8AABMG1QqAgAATIP++9//pv79++ewa9CgQem7777LIUgEUdWJiqEIAyI0isDh1FNPzUHAu+++m9uqxvZo4Vldu8UIAcLEVExFGPj111/n3yMcu/fee3OIE9WN1YkwKcKlCNgK1Uwx9rXXXju1bdt2ou9dEIFcPO8rr7ySVl111Txfhx12WA67brrpptzyMaohN91003x8zE8EQFtssUUOlr744ot00UUX5fAswq8InaIC67jjjstVXBG8RngWIuiaGMcff3wOnCLMjFAmfo9QLsLMCIaiAiwqF6+44oo8RyNGjBivXWxtRSvaueeeO7dujcq4CJ4j9Ivqs/nnnz+ddNJJufVoVJVGEBdBY6loixnfq7322itXVZ511ll5TC+99FIOm0K0x42xL7jggvndRivfWJsz5j/W3qsagsdcR9vMuHeET0svvXSN380Q94x1PSPUjtAvQtm4xt13352rW0tFiHrbbbflitlZZ501t+PcbLPNcmVehJIh7hXzWVgrcNFFF80hYwRo8Z2K9xE/4zsQ2+PfTsxVzFl8rz/77LM0ZMiQsvMex8Z81qWlccxFPOcjjzyS/61H5WCE/dF2NMYR4W6pRx99NAf0ERpHKBhtSSOUjvbCce+6ilbHEWbHp7TiMiqCq1bSxvzFd+nNN9/M/xlVEN/fGGf8+5uYMQAAUM8qAAAAqDdXXHFFlOxUjBw5ssZj3nvvvXxMHFuwxBJLVMw777wVP/74Y3Hb8OHD83EdOnQY79w2bdpUfPvtt8Xtd955Z94+bNiw4ra99torb6tq0003zdu///77StvHjRtX8dVXXxU/33333Xj3re6zxx57VPz999+VrtW9e/eKrl275t+XW265ip122in/Htds3LhxxZVXXlnxyCOP5PNvvvnmsnNa7t5xjbD22mvnOfz111+L58WYVllllYrOnTsXt8X+v/76a7zrN2nSpOK4444rbov3V/UdFcT72G677cbbHs8cn4LC8y244IIVv/zyS6VxxZjWX3/9SvMWxyywwAIV6667bq3mY/DgweN976pec+WVV65o0KBBxe67717c9ueff+bvWulYC9ds1qxZxccff1zc/swzz+Tt+++/f3Fbt27dKtq2bVvxzTffFLe98MILFTPNNFPFgAEDituOPvrofO5WW2013jPU9N0szEOp33//vWLxxRevWGuttSptj/Pju/T2229XGkdsP+ecc4rbYkwxtur+TRbm6vjjj69o0aJFxZtvvllp/2GHHVbRsGHDig8//LCinJjPzTbbrOwxVZ/5jjvuyH+fcMIJlY7bfPPN8zsrfa7C933UqFHFbR988EFF06ZN87/nunrrrbfyudtuu22l7TEHO+6443jH//e//833v++++yptf/LJJ/P2G2+8sc5jAACg/ml/CgAAMI2JSqqoBIuqsWjJWRCVU6VVQaWiqjHaSRYUqumiEm9CCu03S+8VLrzwwtzqsPCJVpVVRaVXVJjFJyoAo6ItKv0OOOCAGu8X1YpRTRZVZ1Ed1rBhw2LlYF2U3rvwWWqppXJL06j8ixaNUWUX1Yzx+eabb9L666+f3nrrrVz5FaLCq1CF9ddff+VjYh6ipWRU2U0O2223XW7jWTBmzJg8ppiXuH9hvNEKMyo4o6VlbVpuVicq3kpbicZ6l5FJxfaCmP9oDVvddyUqO0urY6NCLa4R1Y0hqvZi/NHCNNrMFiy55JK5FWbhuFKxfl9dlM5VVOyOHTs2f7+rez/rrLNObgFcOo5oaVt4tpjHqEzdaKON8jNXVZiraD0c94h/U4X3EZ+4fnxPJtRmNN5j6b/H2oi5incRlYeloh1qvLOoAi618sor58rAgqimjLazUd0YY6ytqMqMys+Y55NPPrnSvqg6jX8jVRXWgI39pQrPXLWCGACAaYP2pwAAANOYDz74IP+MNdyqim3VhSkRKFT3X+5HCDMh0SYy/PTTT7l9aEG0jSy0MIxgo7qgItpYRtBSEC1XI5iJ9pA77rhjtSHolltumVt/RkgSa8L17t27OIa6qHrvgmj/GCHMkUcemT/V+fLLL3NYFiFTtNeM1pHvvfdepWcstMuc1KLNaqkIFAthY00iSKtrSFXd96LwfmPNvqrbq/uuxBxXtfDCC+dWsqXf1Qhhq4q2sRFwRTga7Wdrev4JiTanJ5xwQg4vS9fwKw1La3reEPNWeLavvvoqh+gTas0Z7+TFF1/MYXpN358Jqeu6gjGX0W636r+FmMfC/tq8mwgJ4zmj7e2ExPc9/j1Gq9/49xj3LxVBY9V1E0O0wi3sr+6Zq3s3AABM/YSKAAAAM4CocJrYYCPWlAsvv/xyXgevIIKnQvhUqNiqjaiuO/fcc3M1V3Wh4jzzzJN69OiRTj/99PTEE0/kCsdJqVDVF8FlVCZWpxDYxrp+ETxGABprHUa1XVQuDhw4sNbVgTUFKBHYVPdeqgYxhfvEuoaxjl51qlaR/tPvRXXb6xqCTayqz19OrCcZ6wyuscYaOfiN706sUxjrTcZanJPy30HVdxKVlocccki1+yO8KycC6doE+vVtl112yaFthPuFNU5LxXxHNWpVhW1VQ8jCM88xxxyTbcwAAEw+QkUAAIBpTIcOHfLPt99+e7x91W2rrZrCr6gUjLaHESyUhooT688//yxWPtYkWn3uvPPOabbZZksbbLBBmpQWXHDB/DPCp+oqGUtF+9U111wzXXbZZZW2f//995WCkXKVVxG4xvFVRWVZYSzlFNp1RpvOCY13SitUUZZ68803U8eOHSt9V994443xjnv99dfzHJZWKdakpvmNwDlabUbFY2kbzggVJ0ZUHsY8R4A+oXcS39+JfR8R1Efla13EXD744IO5ZW9ptWLMY2F/bd5N8+bNa6ywLHXwwQfneYyq4q222qraYyLkjmA3QtZCm+DwzDPP5PtUDVcLz1yorgQAYNpiTUUAAIBpTFT/RHvGq666qlIw9+ijj+a1FidWIdypGoBFkBhVWRdffHG68847/3Gl17Bhw/LPWN+wJptvvnk6+uijc/VZ48aN06TUtm3bXAkZaztWV2UVrSFLK9uqPlusp1dYc3FCc1cIoJ5++um8RmRBVH999NFHtRpvrIsX1zjttNOqDWJLxzulxfqDpXMRrWUjUOrVq1exki2CpyuvvLLS3ERo97///a/WgXFN8xvvJwLH0ra077//fh7XxIhgLNaJjO/oqFGjxttf+C7EepxPPfVUDjOrijEWgvOaxHqHMQfVtQ6tScxVPGdU+ZY688wz8xwU5rwgxlfaCjm+b/Hvd7311quxYrMgqmLj+/bvf/877bfffmX/nX7xxRd5DdSCqFiOfyOxLmXV9RZHjx6dW+l27dq11s8NAMDUQ6UiAADAVODyyy9P991333jba/ov9KMt5yabbJIDvx122CG3FYywIcLGchWAEwqvwr777pvbgkbwEOuphWuuuSb17NkzBy4RXkSFVlTgff7557l6KlqZVg01QoQacW6ICquHHnooV5etssoqOdyoSQQPxxxzTJpczjvvvLTaaqvl9qvR4jEqBiMciSDm448/Ti+88EKxSvO4447LcxxjjtA2KjarVhhG6BdVlRdeeGGuIosQbMUVV8zrA0bFZVQ8xvxFGPXOO+/kOSlUIE5IBF2XXnppnt8IY2Issd5jhHmPPPJIrqwrBLVTWrSJjXncY489ckAWVW3R2rO0LWgEVDH2CNJ22mmnNG7cuHTOOefU6R3X9N3ccMMN0xlnnJHnNqpbYy3DeLcxrljzcGLEv60IPLt375523XXXXFUX4XMEZY8//nh+z1HFd9ddd+Xvx/bbb5/HF2tDxvcj3nUEm+VafMa/3WinG/9DgHL/DkpFSBdVs0cccUS+foTyMc4ICqMdb9XvU/xnQcxVzFmEexHQh2OPPbbsfW6//fb8/mJNxnj2wr/fgvgfGMw111zFUHGllVbK38lYdzGeOe4T4Wd193nggQfyc1hTEQBgGlUBAABAvbniiiui9KnGz0cffVTx3nvv5d/j2FI33HBDxaKLLlrRpEmTisUXX7zirrvuqthss83ytoLCuYMHDx7v3rH96KOPLv79559/Vuyzzz4Vc845Z0WDBg3y/lLjxo2rGDJkSMXKK69c0bJly4pGjRpVzD333BW9e/euuPbaa/P5Ve9b+onjF1xwwYqDDz644scff6x07e7du1d07dq17Fw98sgj+To333xz2ePKPXOpd955p2LAgAH5GWaeeeaK9u3b52e55ZZbisf8+uuvFQceeGDFPPPMU9GsWbOKVVddteKpp57K441PqTvvvLOiS5cu+Tmrvq/TTz89Xz/eVVxj1KhR411jQs/3/PPPV/Tt27eiTZs2+TodOnSo6NevX8VDDz1U5/kofO9GjhxZ6dj4PsT2r776qtL27bbbrqJFixbVXjOebb755stjWn311SteeOGF8cbw4IMP5ueOOYzvzkYbbVTx6quv1ureE/puXnbZZRWdO3fO94/vfjxb4Vql4u+99tprvGvHPMbzlfrggw/ydyPuF9eN722c+9tvvxWPie/w4YcfXtGpU6eKxo0bV8wxxxwVq6yySsVpp51W8fvvv1dMyJJLLlmx00471bg/7lf1GeKe+++/f0W7du3ydzaeO97B33//Xe2zXnPNNcW5WXrppfN3bEIKc1fTp+o1vv322/wc8b1s3rx5/k5X/V6F1157LZ8f3wUAAKZNDeL/1HewCQAAwKQRrSZjvbSoCILJJSrlogozqhAPOuig+h7ONOnqq69Oe+21V/rwww9z9eOkFJWAce2qrVLrU1RTRkVztEBVqQgAMG2ypiIAAMA06I8//hhv3bbhw4fntp2xXiAwddtmm23S/PPPn9u1Tu+++eab3ML3hBNOECgCAEzDrKkIAAAwDYr19GJdw3/961+pXbt26fXXX8/r+c0999xp9913r+/hAbVYK/Pll19OM4JYZ3Ni13oFAGDqIVQEAACYBs0+++xp2WWXzdU/X331VWrRokXacMMN08knn5z/C3wAAACYlKypCAAAAAAAAJRlTUUAAAAAAACgLKEiAAAAAAAAUJY1FWEG8/fff6dPP/00zTrrrKlBgwb1PRwAAAAAAKAexUqJP/74Y2rXrl2aaaaa6xGFijCDiUBxvvnmq+9hAAAAAAAAU5GPPvoozTvvvDXuFyrCDCYqFAv/4dCyZcv6Hg4AAAAAAFCPfvjhh1yMVMgPaiJUhBlMoeVpBIpCRQAAAAAAIExoybSaG6MCAAAAAAAAqFSEGdca/7k+NWzSrL6HAQAAAAAAk83owQPqewjTDZWKAAAAAAAAQFlCRQAAAAAAAKAsoSIAAAAAAABQllARAAAAAAAAKEuoCAAAAAAAAJQlVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkWq1bFjxzRkyJA0tZtWxjkhxxxzTOrWrVt9DwMAAAAAAKBajarfDNOGkSNHphYtWqRp3UEHHZT22Wef+h4GAAAAAABAtYSKk9Fff/2VGjRokGaaSUHo5DLnnHOmaVlFRUX+nswyyyz580/88ccfaeaZZ55kYwMAAAAAACiY4dKu6tplRtvJaD8ZAU/8nH/++VOTJk1Su3bt0r777ls87rfffssVZe3bt8/VcSuuuGIaPnx4cf/QoUPTbLPNlu66667UpUuXfI0PP/xwgpV26667bppjjjlSq1atUvfu3dNzzz1X3L/11lun/v37jxcexfFXXXVV/vvHH39M22yzTR7TPPPMk84888zUo0ePNHDgwFrNyZdffpk22mij1KxZs7TAAguka6+9drxjzjjjjLTEEkvke8w333xpzz33TD/99FPe9/PPP6eWLVumW265pdI5d9xxRz4+xvf777+nvffeO4+vadOmqUOHDmnQoEETHNuE3knV9xkh7qWXXpo23XTT1Lx589S5c+f8Pkq98sorqXfv3nnMs846a1p99dXTO++8U9wf5y+22GJ5nIsuumg6//zzazWP77//fr7/DTfckFZZZZV8/uKLL54effTR4jHxfYlj7r333rTsssvmZ3r88cfHa3/6999/p+OOOy7NO++8+ZjYd9999413rxtvvDF/Z+Je1b03AAAAAACASWGGCxXLufXWW3Mgd9FFF6W33norh2IRpBVEKPbUU0/l0OjFF19MW2yxRerZs2c+tuCXX35Jp5xySg6mIrxq27Zt2XtG4LbddtvlYOnpp5/OIdgGG2yQt4cIC4cNG1YM8ML999+f7xPBWTjggAPSE088kcOzBx54II0YMaJSMDkh22+/ffroo4/SI488koPBCNEiaCwV1ZZnn312fqYrr7wyPfzww+mQQw7J+yI43HLLLdMVV1xR6Zz4e/PNN8/BXZwb47vpppvSG2+8kQOwCAT/6TupzrHHHpv69euX31HMZczht99+m/d98sknaY011shBXTzD6NGj04477pj+/PPPvD/GddRRR6UTTzwxvfbaa+mkk05KRx55ZH7m2jr44IPTgQcemJ5//vm08sor58D2m2++qXTMYYcdlk4++eR8jyWXXHK8a5x11lnp9NNPT6eddlp+jvXXXz9tvPHGlb5rhevst99++TpxTHUiDP/hhx8qfQAAAAAAAOpC+9MSUVU499xzp3XWWSe3kYzquBVWWKG4L0Ky+BnVciGqFqN6LLZH+FSoIoxQbqmllqrVPddaa61Kf1988cW52jGq26KaLoKiCO1uv/32tO222+ZjrrvuuhwwRVgX4WMEXrFt7bXXzvtjPIUxTsibb76Zq+aeffbZtPzyy+dtl112Wa7UK1Va9Rhh4AknnJB23333YhXfzjvvnKvzPvvss1yNGKHkPffckx588MHi/EVgutpqq+UKu6hU/KfvpFxIutVWW+Xf471EoBnPFwHweeedlytCIxgutApdeOGFi+ceffTROczr27dv/jsqN1999dUcakb4WxsRPm+22Wb59wsuuCB/R2JOCyFsiCrEqFCtSYSJhx56aA5rQwTVEfpGVWY8Q+l7KYy1JlERGkErAAAAAADAxFKpWCIqD8eNG5cWXHDBtMsuu+Qgr1DB9tJLL+W17yKAKqx/F58I/0pbZzZu3LjayrOafPHFF/leEbhF2BUtOaMqsdA2tVGjRrnqrtDaMlqN3nnnnbn6Lrz77rs5yCwN2uI6iyyySK3uHxVucY9oxVkQLT8j2CwV4WCEltH6NcLMCDij+i4qJkPcv2vXrsWKvmuuuSYHh1EVWAj6xowZk8cV7Uv/97///eN3UpPS+Y9ANua0UHkZY4h2p9WtPRhzG+9yp512qvSOI0AtfccTEtWJBTG3yy23XJ7nUrGtJlFJ+Omnn6ZVV1210vb4uy7XKTj88MPT2LFji5+oSgUAAAAAAKiLGS5UjDaesU5fqQjlQqwVGK05o/ou1heMdQMjFIv9EfQ1bNgwt8uMYKrwiZAnWlUWxHlRiVdbUf0W14lrPPnkk/n3Nm3a5DUICyJAfOihh3IwFu0/4x5RdTelxPp9UTUZYV20I405KFTLlY4zqhVjXclCteQOO+xQnItlllkmvffee+n444/PIWEEpdEadULKvZOaVA0MYwyxRmGIa9Sk0GL2kksuqfSOX3755dyadlKKsHNKXSdavUawWvoBAAAAAACoixkuVJxzzjlzi87SqrAIuwoidIo18KJl5vDhw/MailGluPTSS+dKxQj2OnXqVOkT7TknVqyFGJV7sfZfVPpFAPT1119XOibaika4duONN+aKxajeKwRnUcEXv48cObJ4fFSjRVvT2oiqxKj8i6CwIEK877//vvh37ItQLtqCrrTSSrlaMyrpqvrXv/6VPvjggzx30TK0arvQCLP69++fQ7t4lggoC2sdllPTO5kYEYzGmpPVhZJzzTVXbhsb1Z9V33G0Qa2t0gCyMLdV28mWE/MU44jvRqn4u0uXLrW+DgAAAAAAwKQyw62pGGsYRjVdhFTR4vOoo47KFYghtkdwuOKKK6bmzZvnFp4RaEUbz6gejIrBAQMG5HAtQsavvvoqVxBGULXhhhtO1Hii7enVV1+d21hGwHnwwQdXW0239dZbpwsvvDCHhbG2XkG0Io3wLs5r3bp1atu2bV4XMCoya1MxGe1Io+pxt912y+v/RbvOWKevdAwRqkUId8455+R5i3ArxlLV7LPPntf3i7Gst956ad555y3uO+OMM/JaizFvMbabb745h7FV26xWVe6dTIxY7zCeI9YqjLag0So2QsBo3xpzEWsPRsgb22NefvvttzRq1Kj03XffpQMOOKBW94gqznivESSeeeaZ+dwdd9yxTuOMOYz3uNBCC6Vu3brlys+omiy0wQUAAAAAAJiSZrhKxQiSunfvntt5RhDYp0+fHNyECLiiii7WrougMNYRHDZsWA4UQwQ7ESoeeOCBOYCKc6NCcP7555/o8Vx22WU5dIr2oLFOYQRaEQxWFYFmVP/FmoZV19qLwC7W8YtnWmeddfL+CLSaNm1aqzHEc0VlXMxLhIK77rprpTEstdRS+R6nnHJKWnzxxXOwNWjQoGqvFesRRkvUqiFahJ+nnnpqDk+XX3753FL1nnvuyQFjORN6J3UV5z388MO51Wk8b6wlGdcvVH5GC9dLL700z8kSSyyRj4lgsy6ViieffHL+xLw9/vjj6a677kpzzDFHncYZ34MIMeO7FuO477778nUirAQAAAAAAJjSGlRUXWCQad7PP/+cw8eoqIyQb0qKqsv9998/t0dt3LhxmpFEUBrh4/PPP5+rC6dWUREblZhL7XNhatik5jUmAQAAAABgWjd68ID6HsJUr5AbxPJ6sURbTWa49qfTowixXn/99dzCM174cccdl7dvsskmU2wMv/zyS16rMir0opXqjBYoAgAAAAAATM9muPanU9oss8xS42fEiBGT7D6nnXZabrcZ7U+jUjGuHS0342e5MUwq0dp00UUXzeskRovZ2opWqjWNrWvXrmlqctJJJ9U41l69etX38AAAAAAAACYb7U8ns7fffrvGfdGitFmzydt+cty4cemTTz6pcX+nTp1Sffrxxx/TF198Ue2+WOewQ4cOaWrx7bff5k914j3G+5wWaH8KAAAAAMCMQvvTCdP+dCpR36FdhF31PYZyZp111vyZFrRu3Tp/AAAAAAAAZjTanwIAAAAAAABlCRUBAAAAAACAsoSKAAAAAAAAQFlCRQAAAAAAAKCsRuV3A9Orx07YKrVs2bK+hwEAAAAAAEwDVCoCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACU1aj8bmB6tcZ/rk8NmzSr72EAAAAAAEwXRg8eUN9DgMlKpSIAAAAAAABQllARAAAAAAAAKEuoCAAAAAAAAJQlVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqDidatCgQbrjjjsm6tz3338/nz9mzJg0NZtWxlkbPXr0SAMHDqzvYQAAAAAAAFSrUfWbmRodc8wxOSicHkK0SWG++eZLn332WZpjjjnStO62225LM888c30PAwAAAAAAoFpCxSnor7/+ypV1M82kQHRSaNiwYZp77rnTtOz3339PjRs3Tq1bt/5H1/HdAgAAAAAAJqcZPoHo2LFjGjJkSKVt3bp1y1WBFRUV+ef888+fmjRpktq1a5f23Xff4nG//fZbOuigg1L79u1TixYt0oorrpiGDx9e3D906NA022yzpbvuuit16dIlX+PDDz8sO544f4UVVsjXi3NXXXXV9MEHH+RrHXvssemFF17I4VF8Ylt466230hprrJGaNm2a7/PAAw/UaQ6effbZtPTSS+fzl1tuufT888+PF1jttNNOaYEFFkjNmjVLiyyySDrrrLOK+x977LFcZff5559XOi/aea6++ur593iGjTbaKM0+++z52bp27ZruueeeCY7tu+++S9tss02ac8458707d+6crrjiimrbn8bcxd8PPfRQfo7mzZunVVZZJb3xxhuVrjls2LC0/PLL5+eNKsdNN9201u+0nML7jmrSGGdcf/31108fffRR8Zj4PsX369JLL83zGcdU1/40nnvAgAF5vuI5evXqld/zxHy34pl++OGHSh8AAAAAAIC6UKlYxq233prOPPPMdMMNN+QQLEKzCPUK9t577/Tqq6/m/RE43n777alnz57ppZdeyqFS+OWXX9Ipp5ySQ6Q2bdqktm3b1ni/P//8M/Xp0yftsssu6frrr89VbBH4RVDWv3//9PLLL6f77rsvPfjgg/n4Vq1apb///jv17ds3zTXXXOmZZ55JY8eOrdPafD/99FPq3bt3WnfdddM111yT3nvvvbTffvtVOibuMe+886abb745P8OTTz6Zdt111zTPPPOkfv365UBzwQUXTFdffXU6+OCD8zl//PFHuvbaa9Opp56a/95rr73y80QAGWFdzNsss8wywfEdeeSR+dh77703B4Bvv/12GjduXNlzjjjiiHT66afnIHL33XdPO+64Y3riiSfyvv/+9785RIxjrrrqqjym0nCzNu+0nHjfJ554Yr52VCDuueeeacsttyzeP8QzxHcrWp5GtWV1tt9++xwiRmjYsmXLdOihh6YNNtggj63QJrW2361BgwblQBoAAAAAAGBiCRXLiMqvaK+5zjrr5CAnKhajirCwLyrm4meETyEq3CL0i+0nnXRSMVw7//zz01JLLTXB+0UFWYSCEfIttNBCedtiiy1W3B8hXKNGjSq1/Pzf//6XXn/99XT//fcXxxH3jsq22rjuuutyaHjZZZflqrkITz/++OO0xx57FI+JZy8NpaLC7qmnnko33XRTDhVDVDLGcxdCxagG/PXXX4v7Y54222yztMQSS+S/I4SsjTgvqiij8rBQWTohEep17949/37YYYelDTfcMI8lni/2RchX+jyFd1Pbd1pOvO9zzz03VziGK6+8Mr/DCIcL350IMiN0jNCzOoUwMYLIqLQMEdDGGpJRBbnFFlvU6bt1+OGHpwMOOKDS9yyuBQAAAAAAUFszfPvTciK8iaq4CMCiejCq1qKaMETlWrQFXXjhhXPYV/g8+uij6Z133ileI6rVllxyyVrdL9bViwq1aJkZrUKjxehnn31W9pzXXnstB0SFECysvPLKtX7GOD/GV2jDWdP55513Xlp22WVzEBbPefHFF1dqtxnjjgq8p59+utieMwLFqEoM0Tb2hBNOyO1cjz766PTiiy/WanwRbkbVYLQMPeSQQ3KV5ISUzndUU4Yvv/wy/4xWqWuvvXa159X2nZYToW+0Vi1YdNFFc5vSmOeCDh061Bgohjg2rlMIJkNUIkbb2dLr1Pa7Fa1Ro9qx9AMAAAAAAFAXM3yoONNMM+W1E0tFBViIsC7W44tqsFjPL1pZRqvP2B9tQ6N15ejRo3NQVfhE6FO63mCcF+1Laysq4qIKMCrUbrzxxhxwFYK6+hKhXlTsRTViVEbGc+6www654q4gWm9GEBrj/+KLL3K70mg7WrDzzjund999N2277bY5vIvKw3POOWeC946Ky1iPcf/990+ffvppDgRjLOUU2oOGwtxHNWbhfdSktu/0nyoErf9UXb9bAAAAAAAAE2uGDxWjYqy0GjBaQ8a6gqXBTYRlZ599dho+fHgO/CIUi5acUdUWFXCdOnWq9CltTzox4trRsjKq8hZffPHcorRQmRb3LBWtNT/66KNKz1CXEDLOj6rBaA9a0/mFNpwRqsbY4hmrq9yL4DCC0KhijPatUZVYKkLaWOMw1hI88MAD0yWXXFLrd7TddtvlNR+HDBmSrz+xorLvoYceqnbfpHinUck6atSo4t8RSn///feV2thOSBwb14k1Mgu++eabfK0uXbrU+joAAAAAAACTygwfKq611lrp6quvTiNGjMhhYYRXUa1WaOEZaw2+/PLLucouQq0IGaN9ZVQQbrPNNmnAgAE5JIsgMtbNGzRoUPrvf/87UWOJa0SYGMFlVOdFVWCsr1cIpGI9wTgmque+/vrr9Ntvv+X1HmMsMe4XXnghP8cRRxxR63tuvfXWudot2ru++uqr6Z577kmnnXZapWM6d+6cg7JYt/HNN99MRx55ZBo5cuR414q2rdFaM9qcRiVjqYEDB+bzY/zPPfdceuSRR2oVtB111FHpzjvvzK1VX3nllXT33XfXKaCrKlqvXn/99flnVCDGOz/llFPyvknxTqNKcp999smBYFQ8RlvYlVZaqbieYm3EfG+yySb5nTz++OP5vf7rX/9K7du3z9sBAAAAAACmtBk+VIwQr3v37ql3795pww03TH369MlVdiHWwotquqi4iwq3Bx98MA0bNiyvbxei1WcEUFF1F+vdxbkRts0///wTNZbmzZun119/PW222WY54Np1113TXnvtlXbbbbe8P7b37Nkzrbnmmrl6L8KxaN8aaz3G2o8RXEW14Iknnljre8aagfFMherLCCQLIVtB3L9v376pf//+eZ2/qJqLqsWqYiwRokW1X8xLqdgWzxKBYDxDPF+0lZ2QqM6MdxTzH61nI/CNdqwTq0ePHunmm29Od911V16nMULlCA4L/uk7jXd46KGH5rA2vjcxv1G9WVcxjljDMr6XscZltOiNwLe0tSsAAAAAAMCU0qCi6oKC8A/EuotfffVVDu1mNFHZGhWZ0e50ahYtflu1apWW2ufC1LBJzWtMAgAAAABQe6MHVy62gWlFITcYO3Zs7khZk0ZTdFRMt+KLFtWOsf7jjBgoAgAAAAAATM9m+PanU1q0w6zpE+shTmonnXRSjffr1avXJLtPrPW33nrrpd133z2tu+66tT4vjq9pfLFvahLzVdNYY54BAAAAAACmV9qfTmFvv/12jfvat2+fmjWbtO0ov/322/ypTtwr7lmfvvzyy1xWW50osW3btm2aWnzyySd57crqtG7dOn+mBdqfAgAAAABMetqfMq3S/nQq1alTpyl6v6k97IrQcGoKDsup7wAWAAAAAACgvmh/CgAAAAAAAJQlVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLIald8NTK8eO2Gr1LJly/oeBgAAAAAAMA1QqQgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGUJFQEAAAAAAICyhIoAAAAAAABAWUJFAAAAAAAAoCyhIgAAAAAAAFBWo/K7genVGv+5PjVs0qy+hwEAAAAAMMWMHjygvocA0yyVigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGUJFQEAAAAAAICyhIoAAAAAAABAWUJFpogGDRqkO+64Y4LHvf/++/nYMWPGTLaxHHPMMalbt25patGjR480cODA+h4GAAAAAABAjYSKTDfh3JQydOjQNNtss02y6912223p+OOPn2TXAwAAAAAAmNQaTfIrMs3466+/clXgTDPJlutT69at63sIAAAAAAAAZUmTpjIdO3ZMQ4YMqbQtqgGjKrCioiL/nH/++VOTJk1Su3bt0r777ls87rfffksHHXRQat++fWrRokVaccUV0/Dhw8ersLvrrrtSly5d8jU+/PDDsuOJ81dYYYV8vTh31VVXTR988EG+1rHHHpteeOGFHEzGJ7aFt956K62xxhqpadOm+T4PPPBAnefh9ddfT6usskq+xuKLL54effTRSmHoTjvtlBZYYIHUrFmztMgii6SzzjqrVuOuzjvvvJMWXHDBtPfee+c5LjeP8XOHHXZIY8eOLT53vJMJOf/881Pnzp3z88w111xp8803r7b9aVy/cN3Sz/bbb188/s4770zLLLNMvlaMO97Dn3/+Wec5BgAAAAAAqC2VitOQW2+9NZ155pnphhtuSF27dk2ff/55DvUKIhR79dVX8/4IHG+//fbUs2fP9NJLL+VAK/zyyy/plFNOSZdeemlq06ZNatu2bY33i6CqT58+aZdddknXX399+v3339Ozzz6bQ67+/funl19+Od13333pwQcfzMe3atUq/f3336lv3745OHvmmWdy+DYx6wUefPDBOVyNUPKMM85IG220UXrvvffymOMe8847b7r55pvz308++WTadddd0zzzzJP69etXdtxVvfjii2n99dfPIeUJJ5wwwXmMoDPGddRRR6U33ngjHz/LLLOUfZZRo0bl8Pfqq6/O53/77bdpxIgR1R4b+z/77LPi36+99lraYIMNckgb4rwBAwaks88+O62++uo5EI1nD0cffXS114yQND4FP/zwQy3eAAAAAAAAwP8nVJyGRFXh3HPPndZZZ50088wz54rFqMYr7LviiivyzwjCQlTbRegX20866aS87Y8//shVc0sttdQE7xfhU4SCvXv3TgsttFDetthiixX3R5jWqFGjPKaC//3vf7nK8P777y+OI+7dq1evOj1rBHubbbZZ/v2CCy7Iz3HZZZelQw45JD97VOcVRMXiU089lW666aYcKk5o3AURRsYxRxxxRDrwwANrPY8RnkZAWfrc5cS1ouIx7jXrrLOmDh06pKWXXrraYxs3bly87jfffJN23nnntOOOO+ZPiOc+7LDD0nbbbZf/jkrFWI8x5qWmUHHQoEGV5gsAAAAAAKCutD+dhmyxxRZp3LhxOUiKKryooCu0vYwqumgLuvDCC+ewr/CJtqFRzVYaWi255JK1Xusv2m5GJV9UCkaL0dIquupEZd18881XDOTCyiuvXOdnLT0ngsvlllsuX7vgvPPOS8suu2yac84583NefPHFxVautRl3HLvuuuvmisNCoFiXeayLuE8EifHett1223TttdfmitFyIvyNUDXOK23tGpWpxx13XKWxxXchnq+max5++OE5ZC18Pvroo4l6DgAAAAAAYMYlVJzKzDTTTHldv6oBU4iwLlpuRqVhrCW455575raYsf+nn35KDRs2TKNHj05jxowpfiKIKw2l4rzq2oDWJKrzogow2nLeeOONOWx7+umnU32KtqRRPRgtS6MyMp4z1jmMNqe1HXeEkVHlGe1RS9uB1nYe6yKqE5977rl8r2jRGkFmVIp+//33NZ6zxx575PAvWrxGqFo6vqg6LB1bBKGxjmWssVidWDuzZcuWlT4AAAAAAAB1IVScykTYVVpVF4FXrCVYGgpG9V2sqTd8+PAcnEWoFO00o8Luyy+/TJ06dar0qW2bzprEtaPaLdqFLr744um6664rVj3GPUtFm9EIw0qfYWJCyNJzohozQr5CC9Mnnngih4URqsbY4hmrqyKsadyFebz77rtzEBcVjT/++GPxnAnNY3XPPSERDEbb2lNPPTWv4/j++++nhx9+uNpjYw3JaOV655135jUjSy2zzDI5WK46tvhEIA0AAAAAADA5WFNxKrPWWmuloUOH5uBwttlmy1VtUTkXYnuEWSuuuGJq3rx5uuaaa3I4Fi0yI3zaZptt0oABA9Lpp5+ew7GvvvoqPfTQQ7nd6YYbbljnsUSYGW1FN95449zONMKsqIiLe4SOHTvmY6Jabt55580VeRGcRVVgrPk3ePDgHIrGmoV1Fe1NO3funIPEM888M3333XfFdQVj+1VXXZXXbYz1FK+++uo0cuTI/Httxl0Q6xz+97//zes9xifWTYyxT2ge47mjYjC2RcVhvIv41CTCy3fffTdXlc4+++zpnnvuSX///XdaZJFFxjv2wQcfzOsjxvPPMccc6fPPP8/b4z3HWo7xfYi1GWM9zc033zwHidES9eWXX04nnHBCnecZAAAAAACgNpQ2TWWisq579+45OIoAq0+fPmmhhRbK+yJkvOSSS9Kqq66aA64IoIYNG1asZouWnxGGxRqBEVjFuRG2RQA1MSIoe/311/PafhG27brrrmmvvfZKu+22W94f23v27JnWXHPNXGEZ7T0j5Iq1HmPtx2gvuvPOO6cTTzyxzvc++eST8ydCu8cffzzdddddOWQLcf++ffum/v3754D1m2++yVWLtR13qViT8N57780tZ2O+f/755wnOY1RJ7r777vn+8dxRfVhOvLfbbrstB8YRkl544YV5rrp27TresfGsERzH9aNVauGz33775f1RVRkhZbR9XX755dNKK62UQ9cIlgEAAAAAACaXBhVVF/ADpmtRPRpVj0vtc2Fq2KRZfQ8HAAAAAGCKGT24ckc7IBVzg7Fjx6aWLVvWeJxKRQAAAAAAAKAsoeIMLtp/1vQZMWLEJL/fSSedVOP9Yl3DaVHMU7l5BAAAAAAAmNY1qu8BUL/GjBlT47727dtP8vvFWoH9+vWrdl+zZtNmK87llluu7DwCAAAAAABM64SKM7hOnTpN0fu1bt06f6YnEYZO6XkEAAAAAACYkrQ/BQAAAAAAAMoSKgIAAAAAAABlCRUBAAAAAACAsoSKAAAAAAAAQFmNyu8GplePnbBVatmyZX0PAwAAAAAAmAaoVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAACirUfndwPRqjf9cnxo2aVbfwwAAAAAAmKxGDx5Q30OA6YJKRQAAAAAAAKAsoSIAAAAAAABQllARAAAAAAAAKEuoCAAAAAAAAJQlVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQkalKx44d05AhQybb9YcPH54aNGiQvv/++zQ1OOaYY1K3bt3qexgAAAAAAABlCRWhDt5///0cSo4ZM2aSXO+ggw5KDz300CS5FgAAAAAAwOTSaLJdmanKX3/9lcOwmWaSI09NZplllvwBAAAAAACYmkmYprJWn9EKM1piVlRU5J/zzz9/atKkSWrXrl3ad999i8f99ttvucqtffv2qUWLFmnFFVfMrT0Lhg4dmmabbbZ01113pS5duuRrfPjhh2XHM3LkyLTuuuumOeaYI7Vq1Sp17949Pffcc8X9W2+9derfv3+lc/744498/FVXXZX//vHHH9M222yTxzTPPPOkM888M/Xo0SMNHDiw1vMS19hqq63yNeL5zjvvvEr7zzjjjLTEEkvk/fPNN1/ac889008//VTc/8EHH6SNNtoozT777PmYrl27pnvuuafae/3yyy+pV69eadVVVy22RL300kvTYostlpo2bZoWXXTRdP755xePX2CBBfLPpZdeOoe08WwTEu9lhRVWyGOJdxL3ijFW1/40rln1E9+TgpdffjmPN4LIueaaK2277bbp66+/Lnv/+K788MMPlT4AAAAAAAB1IVScSt166605kLvooovSW2+9le64444cpBXsvffe6amnnko33HBDevHFF9MWW2yRevbsmY8tDcxOOeWUHJK98sorqW3bthMM87bbbrv0+OOPp6effjp17tw5bbDBBnl7iLBw2LBhlQK8+++/P99n0003zX8fcMAB6Yknnshh5gMPPJBGjBhRKZisjcGDB6ellloqPf/88+mwww5L++23X75WQVRbnn322fmZrrzyyvTwww+nQw45pLh/r732ykHaY489ll566aU8B9VVA0aIGCHq33//na8fgd+1116bjjrqqHTiiSem1157LZ100knpyCOPzPcJzz77bP754IMPps8++yzddtttZZ/lzz//TH369MkBbbyneGe77rprDgurE9csfN5+++3UqVOntMYaaxTHu9Zaa+VAc9SoUem+++5LX3zxRerXr1/ZMQwaNCiHxIVPBLEAAAAAAAB1of3pVCqqCueee+60zjrrpJlnnjlXLEa1W2HfFVdckX9GBWOIqsUImWJ7BGGFKsKosouArjYisCp18cUX56Dt0UcfTb17907rr79+rra7/fbbc4VcuO6669LGG2+cZp111hw+RvgW29Zee+28P8ZTGGNtRSVfhIlh4YUXziFlBKwRAIbSqseo4jvhhBPS7rvvXqwojHnZbLPNiiHsggsuON49Pv/881x1GcFpjLdx48Z5+9FHH51OP/301Ldv32Jl4quvvprD3Qhc55xzzry9TZs2+f1MSFQFjh07Ns/fQgstlLdFFWRNCteMStV4hggB497h3HPPzYFi4f2Gyy+/PIeEb775Zp6r6hx++OE57C0dk2ARAAAAAACoC5WKU6moPBw3blwOxHbZZZcc5EXVW4jqu1gjMUKkwpp88Ynw75133ileI4KyJZdcstb3jKq3uFcEbRFmtWzZMlclFtqmNmrUKFfFRTVf+Pnnn9Odd96ZKxjDu+++m4PMQvgZ4jqLLLJInZ595ZVXHu/vqBosiCrBCC2jNWqEmRFwfvPNN7liMkSb2AgaI5yMkDAqBKuKgDKqAG+88cZioBjPE/O30047VZrXuFbpvNZF69at0/bbb58D2WjJetZZZ+UqxAn597//nasaY36bNWuWt73wwgvpkUceqTS2aM8ayo0vWt/Guyz9AAAAAAAA1IVQsR5FG8+oSCsVoVyISrI33ngjV99FqBTrBkYbzNgfQV/Dhg3T6NGj05gxY4qfCN4itCqI82pqs1mdqMSL68Q1nnzyyfx7VOT9/vvvxWMiQHzooYfSl19+mVuyxj2i7eqU8v777+eqvwhLo0VszEFhzcXCOHfeeecccEbYGAHscsstl84555xK19lwww1ze9SoQiwotHW95JJLKs1rrGMY7WAnVlRrRkC4yiqr5BAzwuBy17vmmmtyZWYEyRGclo4vgsnSscUnWt4WWqQCAAAAAABMDtqf1qNopVlatRZtKd97773i3xHYRYgUn1gnMKrSIiSLFphRqRjB3uqrrz7JxhNtRiPEjHUUw0cffZS+/vrrSsdEMBaBZ4Rj9957b66ojPasIaoq4/eRI0fmdq0hWn9Ga866hF5VA7f4u9AyNELEWAMxWpRGKBtuuumm8a4RY4yWqPGJ9p8RFO6zzz7F/SeffHKu9IuKx+HDh6cuXbqkueaaK7dqjUCyUH1ZVaGqMea/LuKdxSfGEpWX0XJ1pZVWGu+4CB8jFI2Wp1X3L7PMMjlIjZavUTUKAAAAAAAwpUgm6lGsYTh06NAcGsbahUcddVSuQAyxPYKrFVdcMTVv3jxXr0XI2KFDh1w9GKHXgAEDcrgWYdVXX32VKwijgi+q8CZGtD29+uqrc2VfBJwHH3xwsfVmqa233jpdeOGFOSyMdpwF0Yo0qh3jvGj72bZt29x+NMK/ulRMRrh56qmnpj59+qQHHngg3Xzzzem///1v3hctS6NaMyoPY97i2BhLqVhzsVevXrki8LvvvstjrG4dw9NOOy3PcbyHCBYjtD322GNz+9Ro2xoVmL/99lsaNWpUvk6sSxjPFHMS61fOO++8qWnTpvnYmkRIHGtTxrqTEVhG9WlUFsa7q26dx0033TRtueWWuV1q/B3iOxEBdATLEY5utdVW6ZBDDslz/Pbbb6cbbrghXXrppcXvDgAAAAAAwKSm/Wk9iqq17t2753aeEQRGiLbQQgvlfREyRoAU6wJGUBjrCA4bNiwHioWWmhFMHXjggXnNwji3tEJwYlx22WU5PIuKuGgdGuFahGhVRaAZbUOjNWeMr9QZZ5yRK/HimdZZZ528PwK9CN9qK54pgrwIS2M9w7hmhGxhqaWWyn+fcsopafHFF8/rOw4aNKjS+REURgAX941gMMLFqMCsTrQZjXUiI1iMkDSqBCOgi/ldYokl8vuJgHeBBRbIx0eF4Nlnn50rCSMk3GSTTco+SwTCr7/+etpss83yOHbdddc8tt122228Y+O4WNfyyiuvTPPMM0/xs/zyy+f9cb8IUeP51ltvvTy+CFDju1Ko2gQAAAAAAJgcGlRUXdQPJqGff/45h49RUbnTTjvV93D4f212o7pyqX0uTA2bjF+JCgAAAAAwPRk9ePzOccD4uUEsadeyZctUE+1PmaSef/75XHG3wgor5C/fcccdl7dPqKIPAAAAAACAqZdQcQYyyyyz1Ljv3nvvTauvvvokuU+sVRhrBzZu3Dgtu+yyacSIEWmOOebIP2Otw5r89NNPaVo0peYVAAAAAACgvggVZyBjxoypcV+0KJ0UYh3E0aNHV7tvueWWKzuGadWUmFcAAAAAAID6JFScgXTq1Kle79+sWbN6H8PkMD0+EwAAAAAAQKmZKv0FAAAAAAAAUIVQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAympUfjcwvXrshK1Sy5Yt63sYAAAAAADANEClIgAAAAAAAFCWUBEAAAAAAAAoS6gIAAAAAAAAlCVUBAAAAAAAAMoSKgIAAAAAAABlCRUBAAAAAACAsoSKAAAAAAAAQFmNyu8Gpldr/Of61LBJs/oeBgAAAADUq9GDB9T3EACmCSoVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGUJFQEAAAAAAICyhIpk22+/ferTp0/x7x49eqSBAwdO9PWGDx+eGjRokL7//vs0o84hAAAAAADA9EKoSLVuu+22dPzxx9fq2OoCyFVWWSV99tlnqVWrVpNsTBFS3nHHHWlGMXTo0DTbbLPV9zAAAAAAAABSo/oeAJPWX3/9lcO3mWb6Z3lx69at/9H5jRs3TnPPPXea1vz+++957AAAAAAAAPx/KhWngI4dO6YhQ4ZU2tatW7d0zDHHpIqKivxz/vnnT02aNEnt2rVL++67b/G43377LR100EGpffv2qUWLFmnFFVfMrUWrVrPdddddqUuXLvkaH3744QSDxwMOOCCf16ZNm3TIIYfkcZSrPjz//PNT586dU9OmTdNcc82VNt9882LLz0cffTSdddZZOcyMz/vvvz9e+9PCOO+///602GKLpVlmmSX17NkzVzOWuvzyy1PXrl3zc8wzzzxp7733Ls5h2HTTTfN1C3+XE/Ma83zRRRel+eabLzVv3jz169cvjR07dryWpSeeeGKe+0UWWSRvf+mll9Jaa62VmjVrludo1113TT/99FOd5rDcey+I+dltt93ynMbcLr744unuu+/O87fDDjvksRbmtXBeTe8CAAAAAABgchEq1rNbb701nXnmmTn4euutt3J7zyWWWKK4P0K1p556Kt1www3pxRdfTFtssUUO4+LYgl9++SWdcsop6dJLL02vvPJKatu2bdl7nn766TnkiwDv8ccfT99++226/fbbazx+1KhROeg87rjj0htvvJHuu+++tMYaa+R9ESauvPLKaZdddskBYXwiwKtOjPO0005LV199dXrsscdy+BmBacEFF1yQ9tprrxzgRagXQWmnTp3yvpEjR+afV1xxRb5H4e8Jefvtt9NNN92Uhg0blsf9/PPPpz333LPSMQ899FB+rgceeCAHej///HNaf/310+yzz57vc/PNN6cHH3ywGHBOzBxW5++//069evVKTzzxRLrmmmvSq6++mk4++eTUsGHD3D42AsmWLVsW5zXmqty7qEkE0z/88EOlDwAAAAAAQF1of1rPIliLNqHrrLNOmnnmmXPF4gorrFDcFyFa/IwquhDBUgRJsf2kk07K2/74449cvbbUUkvV6p4RVh1++OGpb9+++e8LL7wwVxCWG2NUSfbu3TvNOuusqUOHDmnppZfO+2LNxGgXGlWAE2p3GuOMey200EL57wjpIhwrOOGEE9KBBx6Y9ttvv+K25ZdfPv+cc84588+oDKxLW9Vff/01XXXVVbnSM5xzzjlpww03zKFg4TrxbBHIFtqeXnLJJcXzYl8499xz00YbbZTD26gOrOscVieCymeffTa99tpraeGFF87bFlxwweL+mNuoUCx93nLvoiaDBg1Kxx57bJ3GBgAAAAAAUEqlYj2LysNx48blMCmq/aLa7c8//8z7olov2mxG4BTtQgufaDf6zjvvFK8RYdiSSy5Zq/tFO82oeos2qgWNGjVKyy23XI3nrLvuujm8ijFuu+226dprr81Vh3UVwWMhUAzR3vTLL7/Mv8fPTz/9NK299tppUoqQthAohqiqjArBqPIriMrQ0nUUI+SLgLYQKIZVV121eN7EzGF1xowZk+add95ioFgbE/MuIvyMMRc+H330UZ3GCQAAAAAAIFScAmaaaabx1tuLqr0QrUIjqIpKw1i/L1pzRjvL2B9r+EUrzNGjR+cAqvCJ0CvajhbEeVHRNrlERdxzzz2Xrr/++hwEHnXUUTl0K6yXWFtRiVkqxlyYl3iG+lIaHk6p9z6xzzwx7yLWp4w2qqUfAAAAAACAuhAqTgHRujMq2wpiTbv33nuvUrgUrTXPPvvsNHz48LyGYlQpRlvLqFSMKr5YW7D0U5cWoKWipWaEUc8880xxW1RGRnBZTlTiRYvWU089Na/t+P7776eHH34474sqvxjnPxFhWceOHfP6huVCybreJ9qFRgVkwdNPP53DvkUWWaTGcxZbbLH0wgsv5LUVC2Ldw8J5tZ3DCb33qC79+OOP05tvvlntOGqa13LvAgAAAAAAYHKwpuIUsNZaa6WhQ4fm4DDWBIzqsqhADLE9gqNopRntQa+55pocMkaLyzZt2qRtttkmDRgwIK8BGCHjV199lYO3CKRibcCJEWsWnnzyyalz585p0UUXTWeccUbZSre77747vfvuu7mCcvbZZ0/33HNPbgVaCOYiDIyALcKtaM/aunXriRrXMccck3bffffUtm3b1KtXr/Tjjz/mMG+fffYp3ieePVqRRvVdjGVCmjZtmrbbbrt02mmn5VBv3333Tf369SsbysacH3300fm8GFPMeYwh2o3Geoq1ncNy7z107949z+lmm22Wz4+w+PXXX88VnD179szPG9Wq8cxRjRjfjwgPy70LAAAAAACAyUGl4hQQa9pFgNS7d+8cBPbp06e4tmCETZdcckkOyiIofPDBB9OwYcNyoBiuuOKKHCoeeOCBOTiKc0eOHJnXCpxYca0IyCI0izUGo0pw0003rfH4GONtt92WQ7Ko4rvwwgtz+82uXbvm/QcddFAOy7p06ZKr86I6cGLEeIYMGZJbwca1Y77eeuut4v4IVh944IHcMjYC1tqIoK5v375pgw02SOutt16e47h+ORHe3X///enbb79Nyy+/fNp8883zWo/nnntuneaw3HsvuPXWW/M9ttpqqzx/hxxySLE6cZVVVskha//+/fO8RmXihN4FAAAAAADA5NCgouqibzCdiCrDO+64I69Dyf8XFZvRwnWpfS5MDZvU31qWAAAAADA1GD14QH0PAWCqyA3Gjh2bWrZsWeNxKhUBAAAAAACAsqypOB2KdQ1rcu+996bVV189TQ+i5ecHH3xQ7b6LLrpoio8HAAAAAABgeiVUnA6Va/fZvn37NL2455570h9//FHtvrnmmiuvcxgtUAEAAAAAAPhnhIrToU6dOqUZQYcOHep7CAAAAAAAADMEayoCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgrEbldwPTq8dO2Cq1bNmyvocBAAAAAABMA1QqAgAAAAAAAGUJFQEAAAAAAICyhIoAAAAAAABAWUJFAAAAAAAAoCyhIgAAAAAAAFCWUBEAAAAAAAAoS6gIAAAAAAAAlNWo/G5gerXGf65PDZs0q+9hAAAAAGSjBw+o7yEAAGWoVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGUJFWdAHTt2TEOGDEkzsvfffz81aNAgjRkzpr6HAgAAAAAAMNUTKvKPbb/99qlPnz71PYzpijkFAAAAAACmJkLFadTvv/+epid//PHHNDdPE3PtyfWcAAAAAAAAk5NQcSrRo0ePtPfee+dPq1at0hxzzJGOPPLIVFFRUWxZevzxx6cBAwakli1bpl133TVvv/XWW1PXrl1TkyZN8jGnn356pet++eWXaaONNkrNmjVLCyywQLr22msn2Ab0+++/z9uGDx9e3PbKK6+k3r1753vPOuusafXVV0/vvPNOOuaYY9KVV16Z7rzzznxO1fOqU7jnjTfemLp3756aNm1aHNell16aFltssbxt0UUXTeeff36lc1966aW01lpr5edp06ZNnoeffvppvAq/E088MbVr1y4tssgiefuzzz6bll566Xzd5ZZbLj3//PPjjevll19OvXr1SrPMMkuaa6650rbbbpu+/vrr8d7RwIED8/tZf/3104TEc15wwQVp4403Ti1atMjj+uuvv9JOO+2U30c8R4zxrLPOKp5Tbk4/+uij1K9fvzTbbLOl1q1bp0022STPZzm//fZb+uGHHyp9AAAAAAAA6qJRnY5msoogKcKmCMBGjRqVA7P5558/7bLLLnn/aaedlo466qh09NFH579Hjx6dA6YIofr375+efPLJtOeee+awLcK1ED8//fTT9Mgjj6SZZ5457bvvvjlorItPPvkkrbHGGjlUe/jhh3Ow+MQTT6Q///wzHXTQQem1117LQdUVV1yRj4+wqzYOO+ywHIIWwr4IFuP5zj333Lwtgr949gjjtttuu/Tzzz/nIG/llVdOI0eOzM+x884756Bv6NChxes+9NBDeYwPPPBA/jtCxwhE11133XTNNdek9957L+23336VxhJBaoSVcb0zzzwzjRs3Lh166KF5fuOZS9/RHnvskZ+/tuL9nHzyyXkdy0aNGqW///47zTvvvOnmm2/O7yreW7zreeaZJ9+vpjmNKsfC848YMSJf64QTTkg9e/ZML774YmrcuHG19x80aFA69thjaz1eAAAAAACAqoSKU5H55psvB1pRmRbVa1GVF38XQsUIvQ488MDi8dtss01ae+21c0VjWHjhhdOrr76aBg8enMPEN998M9177705pFx++eXzMZdddlmuBKyL8847L1dP3nDDDTmYLNyrIKrtohpu7rnnrtN1o+Kvb9++xb8jLI2QsbAtKvnieS666KIcKl533XXp119/TVdddVUOGkMEkFGJecopp+TqwhD7ouKxELJdfPHFOciLZ4/wMio7P/744xwOFhSCzJNOOqm47fLLL8/vJOax8LydO3dOp556ap2ec+utt0477LBDpW2lIV8851NPPZVuuummHCpGpWR1cxqBaDxHPFt8R0KEjlG1GJWM6623XrX3P/zww9MBBxxQ/DvCynguAAAAAACA2hIqTkVWWmmlYlgUoiItQrZolxmibWepqGaL9pelVl111VwRF+fE/qhmW3bZZYv7o6VohFB1Ea1Ro91pIVCcVEqfJ6oQo51qVGoWQtQQ1ZARaIZ4nqWWWqoYKBaeN4K2N954oxgqLrHEEpWq9uK8JZdcMgeKpXNb6oUXXsjVnBHoVRXjKoSKpXM5Mc9ZGtRGaPnhhx/mqshYn7Fbt25lrxNjfPvtt3P72VIRtMYYaxKtceMDAAAAAAAwsYSK05DSMG1SmWmm/7usZmHtxhBtNktF1dzkfp7CuoiXXHJJWnHFFSsd17Bhw4m+bm3F/QsVj1VFW9J/cu2q50TFZ7Q4jcA4ws0ICaO69JlnnpngGCPUrLouZphzzjnrPC4AAAAAAIDaEipORaqGSk8//XRut1lTqBZtTKuu7Rd/R1VdnBNViVHpF2svFtqfRkVfrB9YNYz67LPPcvvPQmViqajyi7UEI2ysrloxqgIL1ZQTK6oM27Vrl959993c1rWm5421E6OqsRDUxfNGMBrtYmsS51199dW5oq9QrRhzW2qZZZZJt956a+rYsWOu7pycYsyrrLJKXv+yoGqlYXVzGmO88cYbU9u2bfOakQAAAAAAAFPK/y1TY6oQrTBj7bsI/q6//vp0zjnnpP3226/G42N9xYceeigdf/zxed2/CP5ibcCoggsRtPXs2TPttttuObCMcHHnnXeuVHkYv0fb1ZNPPjm3CX300UfTf/7zn0r32XvvvfM6fFtuuWUaNWpUeuutt3JIF+MMEcS9+OKL+e+vv/56vErH2op1BgcNGpTOPvvs/DyxpmSsGXjGGWfk/RE2RigY6yu+/PLLuV3pPvvsk7bddtti69Oa1jSMtrLRVjXWaLznnnvSaaedVumYvfbaK3377bdpq622SiNHjswh3/3335/XQvyngWlVERTHPMb14zljTcy4Z6nq5jSef4455sgtb0eMGJHee++9vJbivvvum9eIBAAAAAAAmFyEilORAQMG5PX1VlhhhRxyRaC466671nh8VK7ddNNNuZ3m4osvno466qh03HHHpe233754TIRyUQHYvXv31Ldv33y9qHQrFWv7RUVjtNYcOHBgOuGEEyrtb9OmTXr44Ydz+824ThwXbUoLVYsR1kWAGWsHRuVj1erJ2orA89JLL81jjnUR415RmbjAAgvk/c2bN89BXIR/UXm5+eabp7XXXjsHqeXEOonDhg3LIWVUYx5xxBHjtTmNOYpxR4C43nrr5fvHXMT6k4UWsZNKhLzxLvr3759bvX7zzTeVqhZrmtN4/sceeyzNP//8+fyowIw1KKMCU+UiAAAAAAAwOTWoKF1Mj3rTo0eP1K1btzRkyJD6HgrTuag6bdWqVVpqnwtTwyaTZ71MAAAAgLoaPXhAfQ8BAGbo3GDs2LFli5hUKgIAAAAAAABlCRWZ5E466aTccrS6T69evdL04tprr63xObt27VrfwwMAAAAAAJhkGtX3APi/hg8fnqYXu+++e+rXr1+1+5o1m37abW688cZ5TcTqFNabBAAAAAAAmB4IFZnkWrdunT/Tu1lnnTV/AAAAAAAApnfanwIAAAAAAABlCRUBAAAAAACAsoSKAAAAAAAAQFlCRQAAAAAAAKCsRuV3A9Orx07YKrVs2bK+hwEAAAAAAEwDVCoCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACU1aj8bmB6tcZ/rk8NmzSr72EAAAAAU4nRgwfU9xAAgKmYSkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGUJFQEAAAAAAICyhIoAAAAAAABAWUJFAAAAAAAAoCyhIjOM7bffPvXp0ydNS6bFMQMAAAAAANOfRvU9ACCl999/Py2wwALp+eefT926dStuP+uss1JFRUW9jg0AAAAAAEClIv/YX3/9lf7+++86nfP7779PtvH88ccfk+W6Ee79+eefU/Q5W7VqlWabbbZ/dA0AAAAAAIB/Sqg4nerYsWMaMmRIpW1RAXfMMcfkcCx+zj///KlJkyapXbt2ad999y0e99tvv6WDDjootW/fPrVo0SKtuOKKafjw4cX9Q4cOzUHXXXfdlbp06ZKv8eGHH9aqjeeJJ56Y77fIIovk7R999FHq169fvl7r1q3TJptskqv2CiKsPO6449K8886b7xPPcN999xX3x7ENGjRIN954Y+revXtq2rRpuvbaa3PQecABB+TrtmnTJh1yyCHjVfzFtQcNGpQrBJs1a5aWWmqpdMsttxT3xzPHte+999607LLL5vs//vjjZZ8z5jXGeOmll+brxnhCjHm11VYrjqd3797pnXfeKZ4Xx4all14637NHjx6V5q303cS7atu2bb52XHPkyJFlxwQAAAAAAPBPCRVnQLfeems688wz00UXXZTeeuutdMcdd6QllliiuH/vvfdOTz31VLrhhhvSiy++mLbYYovUs2fPfGzBL7/8kk455ZQcnr3yyis55JqQhx56KL3xxhvpgQceSHfffXeuKFx//fXTrLPOmkaMGJGeeOKJNMsss+R7FSr8ov3n6aefnk477bQ8ljh+4403rjSWcNhhh6X99tsvvfbaa/mYOCfCz8svvzwHgd9++226/fbbK50TgeJVV12VLrzwwvwM+++/f/rXv/6VHn300fGuffLJJ+drL7nkkhN8zrfffjvP8W233ZbGjBmTt/3888855Bw1alSeh5lmmiltuummxQrPZ599Nv988MEH02effZbPrU6Eo3HtK6+8Mj333HOpU6dO+Xnj+WoSQeQPP/xQ6QMAAAAAAFAX1lScAUVV4dxzz53WWWedNPPMM+eKxRVWWKG474orrsg/o6IwRNViVNrF9pNOOilvi0Dw/PPPz9V9tRVVjxFCNm7cOP99zTXX5FAttkV1Xoh7RDVfVAmut956OUw89NBD05Zbbpn3R5D5yCOP5CrM8847r3jtgQMHpr59+xb/jv2HH354cVsEh/fff3+loC2eJUK8lVdeOW9bcMEFcwAZYWtUPRZEpeS6665b6+eMQDTCyjnnnLO4bbPNNqt0TISdsf/VV19Niy++ePHYqGKMd1OdCCYvuOCCHJb26tUrb7vkkktySHvZZZelgw8+uNrzIjw99thjaz1+AAAAAACAqlQqzoCi8nDcuHE5RNtll11yBV9hrcCXXnoptw5deOGFc9Vg4RPVe6XtOiMYrE3VXqmohiwEiuGFF17IVX1RqVi4T7RA/fXXX/O9oqLu008/Tauuumql68TfUTVYarnlliv+Pnbs2FztF21bCxo1alTpmLhvVFtGWFj6nBEGlj5n1WvXRocOHSoFiiEqK7faaqs85y1btsztacOE2saWinFFmFs6HxEKRyBcdT5KRbgac1L4RMtZAAAAAACAulCpOJ2K9ppV1xCMQCrMN998uQ1pVOlFlduee+6ZBg8enIPDn376KTVs2DCNHj06/ywVoVtBrEFYqC6sS6ViqbhXrFUYayBWVTWUq+u1JyTuHf773//mtSNLxdqJ/+Ta1R2/0UYb5bAxKgujAjQqNKNCsdDmdXKK56n6TAAAAAAAAHUhVJxORSgX1XoFUfX33nvvVQoFI+iKz1577ZUWXXTRXKW49NJL50rFL7/8Mq2++uqTdYzLLLNMuvHGG/N6jFG9V50I4GKtxdJ2pPF3oV1rdVq1apXmmWee9Mwzz6Q11lgjb4tKzAhK456hS5cuOWiLSsHSa08O33zzTQ5xI1AszGm0WS1VqOCMua/JQgstlI+L54+AshAUjxw5Mrd/BQAAAAAAmFyEitOptdZaK6+9F6FhrFF41FFHFSsPY3uEV9EetHnz5nltwwgZI6iKNf222WabNGDAgHT66afnkPGrr75KDz30UG53uuGGG06yMcZ9okJyk002yesWzjvvvOmDDz5It912WzrkkEPy37FO4NFHH50DtW7duuU1F8eMGVNtdWOp/fbbL5188smpc+fOOTA944wz0vfff1/cHy1XY63I/fffP1cNrrbaark1aAR2EXBut912k+w5Z5999jyvF198cQ47I8g87LDDKh0TwWq8g1i7Mp67adOmORytWgG5xx575DmJNrGxFuapp56a27jutNNOk2y8AAAAAAAAVQkVp1Oxjl5UJvbu3TuHU8cff3yxUjFCxgjcDjjggBwuxlqHw4YNy8FXiODuhBNOSAceeGD65JNP0hxzzJFWWmmlfK1JKQLNxx57LB166KGpb9++6ccff8ytSNdee+1i5eK+++6bw74YS1RPRoXhXXfdlcPCcuL4qNSMcDBawe64445p0003zdcqiDmJis5Bgwald999N89LVDL++9//nqTPGfe/4YYb8rNEy9NFFlkknX322alHjx6V1nyMbRGuRgAcFY3Dhw8f71rx3iIE3XbbbfN8xXqP999/fw4uAQAAAAAAJpcGFVUX3gOma9EKN4Lmpfa5MDVs0qy+hwMAAABMJUYPHlDfQwAA6jE3iMKsmparCzNN0VEBAAAAAAAA0xyhIpPELLPMUuNnxIgRaXrRtWvXGp9zQus8AgAAAAAATKusqcgkMWbMmBr3xTqJ04t77rkn/fHHH9Xum2uuuab4eAAAAAAAAKYEoSKTRKdOndKMoEOHDvU9BAAAAAAAgClO+1MAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACU1aj8bmB69dgJW6WWLVvW9zAAAAAAAIBpgEpFAAAAAAAAoCyhIgAAAAAAAFCWUBEAAAAAAAAoS6gIAAAAAAAAlCVUBAAAAAAAAMoSKgIAAAAAAABlCRUBAAAAAACAshqV3w1Mr9b4z/WpYZNm9T0MAAAA4P8ZPXhAfQ8BAKBGKhUBAAAAAACAsoSKAAAAAAAAQFlCRQAAAAAAAKAsoSIAAAAAAABQllARAAAAAAAAKEuoCAAAAAAAAJQlVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkVmSO+//35q0KBBGjNmTH0PBQAAAAAAYKonVISp0Pbbb5/69OlT38MAAAAAAADIhIpMFf7444/Jct3ff/99slx3Yq89uZ4TAAAAAABgchIqUq2OHTumIUOGVNrWrVu3dMwxx+Tfo3XoBRdckHr16pWaNWuWFlxwwXTLLbfUqfXojTfemLp3756aNm2arr322rzv0ksvTYsttljetuiii6bzzz+/0rkvvfRSWmuttfI927Rpk3bdddf0008/jVfhd+KJJ6Z27dqlRRZZJG9/9tln09JLL52vu9xyy6Xnn39+vHG9/PLL+XlmmWWWNNdcc6Vtt902ff3118X9PXr0SHvvvXcaOHBgmmOOOdL6668/wWctzNPGG2+cWrRokcf1119/pZ122iktsMAC+TlijGeddVbxnJjjK6+8Mt155535/PgMHz487/voo49Sv3790myzzZZat26dNtlkkzyf5fz222/phx9+qPQBAAAAAACoC6EiE+3II49Mm222WXrhhRfSNttsk7bccsv02muv1fr8ww47LO233375nAjoIlg86qijcvAW20466aR8jwjYws8//5yPm3322dPIkSPTzTffnB588MEc9JV66KGH0htvvJEeeOCBdPfdd+fQsXfv3qlLly5p9OjRObQ76KCDKp3z/fff57AygsdRo0al++67L33xxRc5wCsVY2ncuHF64okn0oUXXlir54z7bbrppjkQ3XHHHdPff/+d5p133jz+V199NT/zv//973TTTTfl42Nscd+ePXumzz77LH9WWWWVXOUYzz/rrLOmESNG5DFEABrHlauaHDRoUGrVqlXxM99889X6HQEAAAAAAIRGpoGJtcUWW6Sdd945/3788cfnEO+cc84Zr7qwJlHx17dv3+LfRx99dDr99NOL26KSL0K3iy66KG233XbpuuuuS7/++mu66qqrctVfOPfcc9NGG22UTjnllFxdGGJfVDxG+BcuvvjiHORddtlluVKxa9eu6eOPP0577LFH8d5xnQgUI8gsuPzyy3MA9+abb6aFF144b+vcuXM69dRT6zRPW2+9ddphhx0qbTv22GOLv8dzPvXUUzlUjDAxgsKoYIwKw7nnnrt43DXXXJOfI54tqhfDFVdckasWo5JxvfXWq/b+hx9+eDrggAOKf0elomARAAAAAACoC6EiE23llVce7+8xY8bU+vxoQ1oQVYjvvPNObgu6yy67FLf/+eefubouRPXiUkstVQwUw6qrrpqDtqhMLISKSyyxRDFQLJy35JJL5kCxprFHteUjjzySA72qYlyFUHHZZZet9fNV95wF5513Xg4tP/zwwzRu3LhcaRjtZcuJMb799tu5UrFUBK0xxpo0adIkfwAAAAAAACaWUJFqzTTTTKmioqLStmi/OSmVhoOFdREvueSStOKKK1Y6rmHDhhN93dqK+xcqHquaZ555/tG1q55zww035BanUZUZ4WaEhIMHD07PPPPMBMcYoWZh/clSc845Z53HBQAAAAAAUFtCRaoVIVWs5VfaMvO9996rdMzTTz+dBgwYUOnvaCE6MaLKsF27dundd9/N6zNWZ7HFFktDhw7NVY2FoC7WFYwAdJFFFqnx2nHe1VdfnSv6CtWKMdZSyyyzTLr11ltTx44dU6NGk/efRYw51kjcc889i9uqVhpGpeVff/013hhvvPHG1LZt29SyZcvJOkYAAAAAAIBSM1X6C/6ftdZaKwdxI0aMSC+99FJe07BqxeDNN9+cW3jGmoOxHuKzzz6b9t5774m+Z6wzOGjQoHT22Wfna8Z9Y83AM844I++PsDFCwRjLyy+/nNuV7rPPPmnbbbcttj6taU3DWIMw2qrGGo333HNPOu200yods9dee6Vvv/02bbXVVmnkyJE55Lv//vvzWohVw71/KtZlHDVqVL5+POeRRx6Z71kqws0XX3wxt3X9+uuvc5VoPP8cc8yRNtlkk/xeIuSNtRT33XffvEYkAAAAAADA5CJUpFqHH3546t69e+rdu3facMMNU58+fdJCCy00XggYrTxjvcKrrroqXX/99alLly4Tfc+dd945XXrppTlIjHUR4/5RmbjAAgvk/c2bN89BXIR/yy+/fNp8883T2muvnc4999yy1411EocNG5ZDyqikPOKII8ZrcxpVklFBGAHieuutl+8/cODANNtss+VKyElpt912S3379k39+/fPrV6/+eabSlWLIQLQqL6M9RijajTGFs//2GOPpfnnnz+fHxWYsQZlVGCqXAQAAAAAACanBhVVF86DWojKv9tvvz2HjUxbopVtq1at0lL7XJgaNmlW38MBAAAA/p/Rg///MjMAAFM6Nxg7dmzZIiaVigAAAAAAAEBZQkUmuZNOOim3HK3u06tXrzS9uPbaa2t8zq5du9b38AAAAAAAACaZRpPuUsxIynXN3X333VO/fv2q3des2fTTbnPjjTfOayJWZ+aZZ57i4wEAAAAAAJhchIpMcq1bt86f6d2ss86aPwAAAAAAANM77U8BAAAAAACAsoSKAAAAAAAAQFlCRQAAAAAAAKAsoSIAAAAAAABQVqPyu4Hp1WMnbJVatmxZ38MAAAAAAACmASoVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAympUfjcwvVrjP9enhk2a1fcwAAAAYJozevCA+h4CAMAUp1IRAAAAAAAAKEuoCAAAAAAAAJQlVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLKEigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqMg05ZhjjkndunVLU6MePXqkgQMH1vcwAAAAAAAAJjmhIv/I9ttvn/r06TPFzpuRTM0BKgAAAAAAMGMRKlKjv/76K/39999pRvL777/X9xAAAAAAAACmOkLFaUzHjh3TkCFDKm2LaraoaquoqMg/559//tSkSZPUrl27tO+++xaP++2339JBBx2U2rdvn1q0aJFWXHHFNHz48OL+oUOHptlmmy3dddddqUuXLvkaH374YY1jiXtdeeWV6c4770wNGjTIn8L1XnrppbTWWmulZs2apTZt2qRdd901/fTTTxM879BDD00LL7xwat68eVpwwQXTkUcemf7444+JmqtCNeSxxx6b5pxzztSyZcu0++67VwoOo2Xp3nvvnduWzjHHHGn99dfP2x999NG0wgor5DmYZ5550mGHHZb+/PPP4nk///xzGjBgQJplllny/tNPP328+8dz3XHHHZW2xfzGPBd8/PHHaauttkqtW7fO72S55ZZLzzzzTD4mxv3CCy8U5yi2TegdAwAAAAAATA6NJstVqRe33nprOvPMM9MNN9yQunbtmj7//PMcShVEePbqq6/m/RFG3X777alnz545AOzcuXM+5pdffkmnnHJKuvTSS3MY2LZt2xrvFwHla6+9ln744Yd0xRVX5G0RjkXgFuHcyiuvnEaOHJm+/PLLtPPOO+f7RzBW03lh1llnzcfE+GJcu+yyS952yCGHTNScPPTQQ6lp06Y5tHz//ffTDjvskJ/rxBNPLB4TAecee+yRnnjiifz3J598kjbYYIMcSl511VXp9ddfz+OI60SgFw4++OAcPEYwGnP073//Oz333HN1alcaIWv37t1zyBtB7txzz52vEdWh/fv3Ty+//HK677770oMPPpiPb9Wq1QTfcXUiTI5PQcw7AAAAAABAXQgVpyNRVRjB1DrrrJNmnnnmXM0W1XaFfRHgxc8I7EKEexFaxfaTTjopb4uqwPPPPz8ttdRSE7xfVOlFJWIEVnHf0pDu119/zYFcVN+Fc889N2200UY5sJxrrrmqPS/85z//qVSVGWOMAG1iQ8XGjRunyy+/PFc+Rgh33HHH5UDw+OOPTzPN9H8LdSNQPfXUU4vnHHHEEWm++ebLY44KwUUXXTR9+umnuYryqKOOysHrZZddlq655pq09tprF5953nnnrdPYrrvuuvTVV1/l4LUQqnbq1KnS/DZq1KjSHJV7xzUZNGhQrnoEAAAAAACYWNqfTke22GKLNG7cuNw2NCrrohKx0LIzqv5ijcRoLRphVeET1XbvvPNOpRBuySWX/EfjiCrECCULgWJYddVVcwXeG2+8UfbcG2+8MR8bwVmML0LGci1YJyTGEYFiQVRPRoXgRx99VNy27LLLjjf+OC4CxdLxx3nRrjTmK1qoRvvYgggFF1lkkTqNbcyYMWnppZcuBor/9B3X5PDDD09jx44tfkqfHQAAAAAAoDaEitOYqK6LdfVKFdYcjOq6CO2i0jAqAffcc8+0xhpr5P0RiDVs2DCNHj06h1mFTwRoZ511VvFacV5pmDYlPfXUU2mbbbbJrUfvvvvu9Pzzz+eqwdI1ECeH0vBzUop5rOldFea6rsq945rE2ouxnmTpBwAAAAAAoC6EitOYOeecM3322WeV1sd77733in9H0BRtRs8+++y8jmAEdVGlGBVxUakY6xtGi83ST9UWpHURlY1x3VKLLbZYXucv1lYsiPUKIxAtVPNVd96TTz6ZOnTokIPE5ZZbLrcl/eCDD9I/EeOIyr6Cp59+OldARjhXkxh/zFtpIBjjj7Udo8XpQgstlFuPPvPMM8X93333XXrzzTfLvqu33nort04tiIrQCHa//fbbasdR3RyVe8cAAAAAAACTi1BxGrPWWmulq6++Oo0YMSIHSdttt12uQAxDhw7Na/29/PLL6d13381r/kUAFUFdtD2NKsABAwak2267LQeRzz77bF5v77///e9EjyfWPXzxxRdz9dzXX3+dK+biPk2bNs1ji7E88sgjaZ999knbbrttXk+xpvMiRIxWp7GGYrQYjdAs2nv+E1HluNNOO6VXX3013XPPPenoo49Oe++9d3E9xepE9V+0CI0xv/766+nOO+/M5x1wwAH5vAgl45qxNuPDDz+cn3H77bcf75rxrmJdxqi4HDVqVNp9991zGFmw1VZb5UC3T58+ObSMd3brrbfmkLAwR/GeIniMOYo1KMu9YwAAAAAAgMlFqDiNifXxunfvnnr37p023HDDHEhF5VyYbbbZ0iWXXJLX/4squAcffDANGzYstWnTJu+/4oorcqh44IEH5orBOHfkyJFp/vnnn+jxxLp+ca2oLIzKvAjHYg3D+++/P1fgLb/88mnzzTdPa6+9dg7Yyp238cYbp/333z+Hft26dcuVi0ceeeQ/mq+4b4SV0SK0f//++R7HHHNM2XPat2+fA8gIXWNNxggDI0SM9R0LBg8enFZfffVcMbjOOuuk1VZbbby1GU8//fRcERnHbb311umggw6qtL5jVCL+73//S23bts0tX5dYYol08sknF0PizTbbLPXs2TOtueaaeY6uv/76Cb5jAAAAAACAyaFBRdVF32A6EdWD33//fbrjjjvqeyhTlWiZ26pVq7TUPhemhk3qvq4jAAAAzOhGDx5Q30MAAJjkucHYsWNTy5YtazxOpSIAAAAAAABQVqPyu5nRxfqBNbn33ntza8+pdWwAAAAAAABMGkJFyhozZkzZtQen5rHVZ+AJAAAAAAAwPREqUlanTp3S1GpqHhsAAAAAAMD0xJqKAAAAAAAAQFlCRQAAAAAAAKAsoSIAAAAAAABQllARAAAAAAAAKKtR+d3A9OqxE7ZKLVu2rO9hAAAAAAAA0wCVigAAAAAAAEBZQkUAAAAAAACgLKEiAAAAAAAAUJZQEQAAAAAAAChLqAgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGU1Kr8bmF6t8Z/rU8Mmzep7GAAAAFAnowcPqO8hAADMkFQqAgAAAAAAAGUJFQEAAAAAAICyhIoAAAAAAABAWUJFAAAAAAAAoCyhIgAAAAAAAFCWUBEAAAAAAAAoS6gIAAAAAAAAlCVUBAAAAAAAAMoSKgIAAAAAAABlCRUBAAAAAACAsoSKU0jHjh3TkCFD6nsYTCFDhw5Ns8022wSPa9CgQbrjjjumyJgAAAAAAAAmllBxGrX99tunPn361PcwpqkAb0rq379/evPNN4t/H3PMMalbt27jHffZZ5+lXr16TeHRAQAAAAAATKFQ8eqrr06rrrpqateuXfrggw/ytqjEu/POO9P06vfff6/vIVDFH3/8kaZGzZo1S23btp3gcXPPPXdq0qTJFBkTAAAAAADAFA0VL7jggnTAAQekDTbYIH3//ffpr7/+ytujWmxaavHZo0ePtPfee+dPq1at0hxzzJGOPPLIVFFRUWxZevzxx6cBAwakli1bpl133TVvv/XWW1PXrl1zGBTHnH766ZWu++WXX6aNNtooB0sLLLBAuvbaayvtf//993PbyzFjxhS3xTzGtuHDhxe3vfLKK6l379753rPOOmtaffXV0zvvvJOr3q688soc4MY5Vc+ryaGHHpoWXnjh1Lx587TgggvmZy2EclFVF9d5/fXXK51z5plnpoUWWqj491133ZU6d+6cmjZtmtZcc808jjgvxl8bTzzxRJ73GMPss8+e1l9//fTdd9/lfffdd19abbXV8veoTZs2+dnjeavO24033pi6d++exxBzu8MOO6SxY8cW5yLmZ0IK73arrbZKLVq0SO3bt0/nnXdepWM+/PDDtMkmm6RZZpklv4N+/fqlL774orj/hRdeyHMQ7yb2L7vssmnUqFHjVU/G78cee2w+vjDG2FZd+9OXXnoprbXWWvm7E3MQ37mffvppvArV0047Lc0zzzz5mL322qtsuPrbb7+lH374odIHAAAAAABgsoeK55xzTrrkkkvSEUcckRo2bFjcvtxyy+VQZFoSoVijRo3Ss88+m84666x0xhlnpEsvvbS4P8KbpZZaKj3//PM5hBs9enQOl7bccsv8rBFgxfZCSFQIfj766KP0yCOPpFtuuSWdf/75OWisi08++SStscYaObh8+OGH83133HHH9Oeff6aDDjooj6Fnz565fWZ8VllllQleM8KvGOerr76anzXeYYSGIcLGeH9VA9D4e+utt86/v/fee2nzzTfPoVYEZLvttlv+DtRWhKhrr7126tKlS3rqqafS448/nsPXQij9888/57A6grmHHnoozTTTTGnTTTdNf//9d6XrHHbYYWm//fZLr732Wg71IsiOUK8wFzE/tTF48ODiuy1c84EHHsj74p4RKH777bfp0Ucfzdvffffd3Na0YJtttknzzjtvGjlyZH4/cY2ZZ555vPvEOQceeGAOogtjLL1OQTx/hKwRtsY1b7755vTggw/m0LtUfK8ibI2f8f2Nd1r6/atq0KBBOTQvfOabb75azQ8AAAAAAEBBozQRIlxaeumlx9seAVgEI9OSCFgiWIuKsUUWWSQHhfH3LrvskvdH1VgEQqVBUgRjESQWwrgI6SKgijAxKv7uvffeHFIuv/zy+ZjLLrssLbbYYnUaV1TNRQB0ww03FIOquFdBVLJFBVq0z6yt//znP5Uq9SJ8i+sfcsghxWc799xzcwVfiGeJsOyaa67Jf1900UV5juJZQ/z+8ssvpxNPPLFW9z/11FNzcBkha0EEbQWbbbZZpeMvv/zyNOecc+b5XXzxxYvbBw4cmPr27Vv8O+Yp3l9d5iJE+94IAgtzG1WU8e7XXXfdHGrGdyG+64UQ7qqrrsrjjcAv3m1UMh588MFp0UUXzfujgrM68a6i2jHC63JjvO6669Kvv/6a7xPVkyHeRwSvp5xySpprrrnytggdY3sE+nHvDTfcMI+38J2t6vDDD89hbUFUKgoWAQAAAACAyV6pGC09S1t3FkT7yrqGZ/VtpZVWyoFUwcorr5zeeuutYvVchGClojouwqhS8XfhnNgf4VG0wiyI4KfQCrO2Yn6j3Wl1lW8TK9qGxlgj2IqQK0LGCMYKovoyWow+/fTTxSrFZZZZphiavfHGG8WgtGCFFVao0zNFIFuTmMNoRxqtWaPyMILPUDrG6t7JxIp3XfXveH8hfkbwVhq+RYVlvMfCMRHU7bzzzmmdddZJJ598cqVWrRMjrhuVk4VAMcT7iqrJmPuCCDZLK4SjDWq5StgI+2M+Sz8AAAAAAACTPVSMMCXWcYuQKtYfjKq8qFaLiqhC1dv0ojTgmVSirWcorN0Yqq6JF9Vtk1K0G41KxFgH8+67784tP6N16e+//148JsLGqMyMirkQP+OcSWVCzxQVedFuNNqyPvPMM/kTSsc4ud7JxIjWt7HuZVQKRovaCB1vv/32yX7fqkFzhOJVW8QCAAAAAADUe6gY1VnRjjEq3X755Ze85t4FF1yQ1+mLardpSSG4KogqvWhjWVoJVioqMaNNZqn4O9pnFtpRxrqH0Ta0IKrMvv/+++Lf0dIzxNp6BVUrP5dccsk0YsSI8cLGgsaNGxerKWvjySefTB06dMhBYlT6xTN+8MEH4x0XIWKExRFCxhqCpe8z2p3GeoelohVobcUzRZvO6nzzzTd5nuI7FdWMMc/fffddra5b17koKFRklv5dqLSNn7EuZnwKog1rvMcIDwvive+///7pf//7X27JesUVV0z0GOOesVZlaQvh+G5FCB1zDwAAAAAAMM2EihGYxZpv0fIx2lX+9NNP6fPPP08ff/xx2mmnndK0JlprRuVlBFrXX399Ouecc9J+++1X4/GxvmIEY7HuYKw5eOWVV+b17WJ9whDhT8+ePdNuu+2WA8sIFyOELa3Si9+j7Wq0zIyWl48++mil9Q7D3nvvnde+i1AvgryY66uvvrrYBjNag7744ov576+//rrG8LEgQsR41lhDMdp0nn322dVW1UUw9uOPP6Y99tgjrbnmmqldu3bFffFMr7/+ejr00EPzs990001p6NCheV9pC9maRCVrhJB77rlnHntcK8LoGH+sE9imTZt08cUXp7fffjtX/pWuA1hOzEV8D+O9xLUi6K6NCOxincd4lljD8uabby6++/h+L7HEEjlkfe6553I17oABA1L37t1zKDtu3Lj8joYPH57D2bhWPFtN7X9jjLE+Y4THMcZYD7OquFfTpk3Tdtttl9eqfOSRR9I+++yTtt122+J6igAAAAAAANNEqBjrBe6+++7p119/zX83b948tW3bNk2rIiiKgCjWBoyWrhEq7brrrjUeH2sMRpgW4dziiy+ejjrqqHTcccel7bffvnhMVKtFGBcBVIR0cb2qc3T55ZfngDbWXhw4cGA64YQTKu2PgC2CtQjL4jpxXLQFLbS+3GWXXXKAGQFXVD5WrZ6sauONN84VdRGEdevWLVcuHnnkkeMdN+uss+Y2pFExV7X1aaylecstt6TbbrstVx1GIBiVj4V1+yYkqvqioi+uHfMdaxjeeeed+TsV1XgxpxHCxrzGWAcPHpxqY5VVVsnfyf79++e5iKCwNiIgjsB26aWXzvN/xhlnpPXXX78YksbYIuxcY401csgYaz1GFWeIqtSorozvTzxXv379Uq9evdKxxx5b7b0222yzHDZHUBtjjAC7qvi3dP/99+cWsLF25eabb56rNiO0BgAAAAAAqE8NKkoX9qulHj165CCsT58+aVoWzxEB25AhQ+p7KNOsWEvzwgsvrNQmdFoQlYPxHY7PjCYqYFu1apWW2ufC1LDJpF27EwAAACa30YMH1PcQAACmy9xg7NixqWXLljUe12hiLh7tK6PKK1qeRgVdixYtKu2PKjamT+eff36uootKyqiOjGrCqH4EAAAAAABg+jVRoWKs8xf23Xff4rZoFxlFj/Hzr7/+mnQjpFZOOumk/KnO6quvnu69995Jcp9Y2zFahUaLzvnnnz+Hy7FWYoj2nyNGjKj2vH//+9/5MyXEGGIsNYmWsgAAAAAAAEzm9qcffPBB2f0dOnSo6yX5hyLki091mjVrltq3bz/Zx/DJJ5/k9Smr07p16/yZEmIMMZaadOrUKc3ItD8FAABgWqb9KQDANNT+VGg49ZmSoV1NpkRwWRsRos7owSEAAAAAAMCkNFGh4lVXXVV2/4AB/hdjAAAAAAAAMEOHivvtt1+lv//444/0yy+/pMaNG6fmzZsLFQEAAAAAAGA6MtPEnPTdd99V+vz000/pjTfeSKuttlq6/vrrJ/0oAQAAAAAAgGkrVKxO586d08knnzxeFSMAAAAAAAAwA7Y/rfFijRqlTz/9dFJeEphMHjthq9SyZcv6HgYAAAAAADC9hop33XVXpb8rKirSZ599ls4999y06qqrTqqxAQAAAAAAANNqqNinT59Kfzdo0CDNOeecaa211kqnn376pBobAAAAAAAAMK2Gin///fekHwkAAAAAAAAwVZppYk467rjj0i+//DLe9nHjxuV9AAAAAAAAwPSjQUUsiFhHDRs2zGsotm3bttL2b775Jm/766+/JuUYgUnohx9+SK1atUpjx45NLVu2rO/hAAAAAAAA00BuMFGVipFDxjqKVb3wwgupdevWE3NJAAAAAAAAYHpYU3H22WfPYWJ8Fl544UrBYlQn/vTTT2n33XefHOMEAAAAAAAApoVQcciQIblKcccdd0zHHntsLoUsaNy4cerYsWNaeeWVJ8c4gUlsjf9cnxo2aVbfwwAAAIBKRg8eUN9DAADgn4aK2223Xf65wAILpFVWWSXNPPPMdTkdAAAAAAAAmN5DxYLu3bsXf//111/T77//Xml/uUUcAQAAAAAAgGnLTBNz0i+//JL23nvv1LZt29SiRYu81mLpBwAAAAAAAJjBQ8WDDz44Pfzww+mCCy5ITZo0SZdeemleY7Fdu3bpqquumvSjBAAAAAAAAKat9qfDhg3L4WGPHj3SDjvskFZfffXUqVOn1KFDh3TttdembbbZZtKPFAAAAAAAAJh2KhW//fbbtOCCCxbXT4y/w2qrrZYee+yxSTtCAAAAAAAAYNoLFSNQfO+99/Lviy66aLrpppuKFYyzzTbbpB0hAAAAAAAAMO2FitHy9IUXXsi/H3bYYem8885LTZs2Tfvvv39ebxEAAAAAAACYwddUjPCwYJ111kmvv/56Gj16dF5Xcckll5yU4wMAAAAAAACmxUrFUr/++mvq0KFD6tu3r0ARUkpDhw6tVRvgBg0apDvuuGOKjAkAAAAAAGCKh4p//fVXOv7441P79u3TLLPMkt599928/cgjj0yXXXbZPxoQTI4Ab0rq379/evPNN4t/H3PMMalbt27jHffZZ5+lXr16TeHRAQAAAAAATKFQ8cQTT8xhzqmnnpoaN25c3L744ounSy+9dGIuCXX2xx9/pKlRs2bNUtu2bSd43Nxzz52aNGkyRcYEAAAAAAAwxUPFq666Kl188cVpm222SQ0bNixuX2qppfL6itRdx44d05AhQypti+q2qHIrtMq84IILcmVbhFYLLrhguuWWW2p9/UMPPTQtvPDCqXnz5vncqCothHJRVRfXr/ruzjzzzLTQQgsV/77rrrtS586dU9OmTdOaa66Zrrzyynze999/X6sxPPHEE6lHjx55DLPPPntaf/3103fffZf33XfffWm11VbLVYdt2rRJvXv3Tu+8807x3Pfffz/f68Ybb0zdu3fPY7j22mvTDjvskMaOHZv3xacwXxOa66i03WqrrVKLFi1yxe15551X6ZgPP/wwbbLJJrkSt2XLlqlfv37piy++KO5/4YUX8hzMOuusef+yyy6bRo0aNV71ZPx+7LHH5uMLY4xt1bU/femll9Jaa62V32/Mwa677pp++umn4v7tt98+9enTJ5122mlpnnnmycfstddeU224CgAAAAAAzOCh4ieffJI6deo03va///5bwDEZRRC42Wab5YAqAt0tt9wyvfbaa7U6N8KvCLNeffXVdNZZZ6VLLrkkh4Yhwsblllsuh3Sl4u+tt946//7ee++lzTffPIdacf/ddtstHXHEEbUe+5gxY9Laa6+dunTpkp566qn0+OOPp4022ii30g0///xzOuCAA3Iw99BDD6WZZpopbbrppvk7Veqwww5L++23X37uCPUiiI1QL1qJxueggw6q1XgGDx6cQ/Dnn3++eM0HHngg74t7RqD47bffpkcffTRvjxa/0da0IOZ/3nnnTSNHjkyjR4/O15h55pnHu0+cc+CBB6auXbsWx1h6nYJ4/ghZI2yNa958883pwQcfTHvvvXel4x555JEctsbPCHXjnRZCypr89ttv6Ycffqj0AQAAAAAAqItGaSJEMDRixIjUoUOHStujcm7ppZeemEtSC1tssUXaeeed8+9RaRdh1znnnJPOP//8CZ77n//8p1KlXoRvN9xwQzrkkEOKIdm5556br1uoXoyw7Jprrsl/X3TRRWmRRRbJYVyI319++eXcCrc2olVuBJelY42grSDC0lKXX355mnPOOXMIGm11CwYOHJj69u1b/LtVq1a54i9aidbFqquumoPAQqgaVZQRsq677ro51IyqwQhS55tvvmJ1bow3Ar/ll18+VzIefPDBadFFF837o4KzOlF1GNWOjRo1KjvG6667Lv3666/5PlE9GeJ9RPB6yimnpLnmmitvi9AxtkeFcNx7ww03zOPdZZddarz2oEGDcrUkAAAAAADAFK1UPOqoo3IFVYQdUdV122235VAjAqbYx+Sx8sorj/d3bSsVo21oBGkRbEXIFSFjBGMFUfUYLUaffvrpYpXiMsssUwzN3njjjRymlVphhRXqXKlYk7feeiu3I43WrFF5GMFnKB1jiGBycs9l/IwwsRAoFoL0aGlaOCaqKiPgXWedddLJJ59cqVXrxIjrRuVkIVAM8b7i31fMfUEEm6Uth6MN6pdffln22ocffnhuEVv4fPTRR/9orAAAAAAAwIynTqFitICsqKjIrSGHDRuW2zNGCBJBYoQisS0qvai7aPcZc1tqUrWSjXajUYm4wQYbpLvvvju3/IzWpb///nvxmAgbYz2/qJgL8TPOmVSiYq+cqMiLdqPRlvWZZ57Jn1A6xlAautWnWLvxlVdeyZWCDz/8cA4db7/99sl+36otVqNKs2qL2KqaNGmSg9rSDwAAAAAAwGQLFaPF41dffZV/X3311VPr1q1zm8hffvklr5G33nrr1enm/H/R6jPW2yuIde+i/WapQhVh6d+LLbbYBK/95JNP5la1ESRGpV+8xw8++GC84yJEjIrGCCEjQI7qxYJodxrrHZaKVqC1teSSS+Y2ndX55ptvcjVeVE9GNWM803fffVer6zZu3Li4LmNdlJvL+BnVfKUVfdGG9fvvv8/hYUG0Td1///3T//73v9yS9YorrpjoMcY9Y63KWFuxIFqyRtgccw8AAAAAADDNhIpVK+nuvffeSiEIEy+qBK+++uq8VmUEtdttt12lNpfh5ptvzmsNxnqHRx99dHr22WdzG9oJiRAx2ojGGorRpvPss8+utqougrEff/wx7bHHHmnNNddM7dq1K+7bbbfd0uuvv54OPfTQfP+bbropDR06tFgtNyHRgjNCyD333DO9+OKL+VoXXHBB+vrrr/M6gW3atEkXX3xxevvtt3PlX7QXrY1ok/rTTz/lwDKuFQF3bURgF+s8xrOcd955eW7322+/vC9ami6xxBI5ZH3uuefyPA8YMCB17949h7Ljxo3L8z58+PAczsa14tlqCnhjjBEQRwvYGONvv/023jFxr6ZNm+b3HmtVPvLII2mfffZJ2267bXE9RQAAAAAAgGlqTcWaQkYmXoRuEVr17t07t9Ts06dPWmihhSodc+yxx+ZgMKr+rrrqqnT99ddXqpyrycYbb5wr6iII69atW65cPPLII8c7btZZZ81tSKNirmrr0wUWWCDdcsstef3MuH8EglH5WGivOSFR1RcVfXHtWIsx1jC88847U6NGjXI1XjzX6NGj0+KLL57HOnjw4FrMWkqrrLJK2n333VP//v1ztWcEhbVx4IEH5srLpZdeOp1wwgnpjDPOSOuvv34xJI2xRdi5xhpr5JAx1nqMKs4QYW9UV0bQGM/Vr1+/1KtXr/x+qrPZZpulnj175qA2xhjvrarmzZun+++/P7eAjbUrN99881y1ee6559bqeQAAAAAAACanBhV1SAYjTPn8889zMFIIoaLqLAInJq8IuqK6MMLGqcWJJ56YLrzwwkptQqcFUTk4cODA/JkRRWvdVq1apaX2uTA1bFJ+rUsAAACY0kYPHlDfQwAAmCFzg7Fjx6aWLVvWeFyjulw08sftt9++WJn266+/5iqxFi1aVDouqtmY/px//vm5ii5alUbLz6gmrE37VQAAAAAAAGag9qex3lvbtm1zWhmff/3rX3ndvcLfhQ9T1kknnZRmmWWWaj/RlnNSeeutt9Imm2ySW64ef/zxuYXoMccck/fFfWoaQ4xvSok1KWsaR3wAAAAAAACYzO1PmTrFOnzxqU6zZs1S+/btJ/sYPvnkkzRu3Lhq97Vu3Tp/poQYQ4ylJp06dUozOu1PAQAAmJppfwoAMB20P2XqNCVDu5pMieCyNiJEFRwCAAAAAADUY/tTAAAAAAAAYMYjVAQAAAAAAADKEioCAAAAAAAAZQkVAQAAAAAAgLIald8NTK8eO2Gr1LJly/oeBgAAAAAAMA1QqQgAAAAAAACUJVQEAAAAAAAAyhIqAgAAAAAAAGUJFQEAAAAAAICyhIoAAAAAAABAWUJFAAAAAAAAoCyhIgAAAAAAAFBWo/K7genVGv+5PjVs0qy+hwEAAADZ6MED6nsIAACUoVIRAAAAAAAAKEuoCAAAAAAAAJQlVAQAAAAAAADKEioCAAAA/6e9+wCzsrr6h70RFFEEBCvYxYoKKnYDiA1iw4YdO2pERMWWiD2gYsGOiQoW7D32imIHFHtXLIklFjBWLPNda7/fmf8ZmDnMIDAzzH1f13nhnKftp+S84/xYawMAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQsYGbOHFiatSoUZowYcJMXbe+6NatWxowYEBtDwMAAAAAAKBOEyo2cEsuuWT69NNP02qrrVbbQ2Eqo0ePziHupEmTansoAAAAAABAAydUbOAaN26cFltssdSkSZPaHkqaMmXKLNlvWVlZ+vXXX2fJvn/77bf0+++/14nzBAAAAAAAmFWEig3A/fffnzbeeOPUqlWr1KZNm7T11lun9957r9KWpt98803aY4890sILL5yaNWuWVlhhhTRixIgq9/3qq6+mnj17pubNm6dFF1007bXXXunLL7+sduvRfv365fajCy20UNpyyy2rtc+ff/459e/fPy2yyCJp3nnnzec2duzYaSr87rvvvrT22munpk2bpieffDJ9//33qU+fPnm/iy++eDrnnHOmGVPse+DAgaldu3Zp/vnnT+utt17eX8HIkSPzdbzrrrvSqquumvf90UcflTzPffbZJ/Xq1Sv9/e9/T23btk0rrbRS/vyaa65JnTt3TgsssEAOdnfffff0xRdflN+XTTbZJP99wQUXzOcT+wkRYg4ZMiQtu+yy+R517Ngx3XLLLVUeP87p22+/rfACAAAAAACoCaFiAxBh2pFHHpnGjRuXHnnkkTTXXHOl7bffvtIKu0GDBqXXX389B3JvvPFGuvTSS3PgV5loy9m9e/e05ppr5n1HePn555+n3r17V3tsV111VZpnnnnSU089lYYPH16tfR5zzDHp1ltvzdu+8MILqX379jmQ/Prrryvs+7jjjktnnHFGPo811lgjHX300enxxx9Pd955Z3rwwQdzWBjbF4uQ85lnnkk33HBDevnll9POO++cevTokd55553ydX744Yd05plnpssvvzy99tprOdycnrjub731VnrooYfS3XffnT/75Zdf0mmnnZZeeumldMcdd+QgsRAcRlvaOMcQ20WL2vPPPz+/j0Dx6quvztcrjn/EEUekPffcM59bZWL9li1blr9i3wAAAAAAADXRqCx6Q9KgRNVfVCK+8soruWovKt5efPHF1KlTp7TtttvmEPHKK6+cZrsIvYrXPf3009OYMWPSAw88UL7OJ598kkOrCMJWXHHF6VYqRtVccbA3vX1GBWFU7kXFYFT2FcK5ZZZZJlc8RnAYYWFU+UVQt9122+V1vvvuu1ylee211+agMEQIucQSS6S+ffumYcOG5YrD5ZZbLv8ZFYUFm222WVp33XXT4MGD83H33XffXNkZFYLVEUFhhKOx3whQqxIh6jrrrJP+97//5ftSOI+oHo3qyELVYevWrdPDDz+cNthgg/JtDzjggBx2XnfdddPsN7aJV0Fc87ieHQ8bnho3bVatcwAAAIBZbfzQPrU9BACABunbb7/NRUmTJ09OLVq0qHK92p9Ij1kuquxOPPHE9Nxzz+VAsVChGCFXtPAsdsghh6Qdd9wxB31bbLFFbtu54YYbVrrfqLB77LHHcgA2tWivOr1QMUR70prs86effsoh4kYbbVT++dxzz51Dv6hILBatRYu3jbkMo51pQYRzhVakIULWmCNx6nFHIBeBZEEEg1H5WBOrr776NIHi+PHj08knn5zPOYLDUvel4N13383h4eabb17h8zi3qO6sTLRojRcAAAAAAMCMEio2ANtss01aeuml0z//+c9cgRfh1WqrrZaDqKnFXIYffvhhuvfee3Orzk033TQdeuih6eyzz55m3aj+i31HK9CpxZyF1RHzFtZkn4W5IGdk39MTx27cuHEO++LPYsUhZ8xjGHMc1sTUY4mWtNGyNV6jRo3KlaMRJsb7yu5L8RjDPffck6s2iwkOAQAAAACAWUWoOIf76quvctvQCBT/9Kc/5c+efPLJkttEwLX33nvnV2wTLUUrCxXXWmutPO9ftB5t0mTmPErT2+fyyy9fPgdjBKUhKhfHjh2b259WJbaLisao1lxqqaXyZ1Ed+Pbbb6euXbvm91HpF5WKX3zxRfm1mlXefPPNfG9izsfCHIfR/rRYobIxxlQQFYwRHkYAWRg3AAAAAADArDbXLD8CtSrmH4zWnf/4xz9y68xHH300HXnkkVWuH21S77zzzrzua6+9lu6+++60yiqrVLpuVDDGvIS77bZbDvWiijDmQow5B4uDsJqY3j6j4i9atEbQGfMUvv766+nAAw/MLUH333//KvcblYaxPLaLa/Dqq6/muQ7nmuv//U8g2p7uscceqU+fPum2225LH3zwQXr++efTkCFDcmXgzBTBZoSGF154YXr//ffTXXfdlU477bQK60RoGhWRcQ/++9//5irFBRZYIA0cODAdccQR6aqrrsrXJ1rVxn7iPQAAAAAAwKwgVJzDRWh2ww035Jae0fI0wqihQ4dWuX4EXccff3yeM7BLly65DWhsX5lopRoVgxH2xfyLMW9gVAu2atWqQlhXE9XZZ1T3xbyPe+21V65sjAA0gscIUEuJ844KxGivutlmm6WNN954mjkdR4wYkUPFo446Ks+3GHNKRrhZqG6cWaIadOTIkenmm2/O1YdxTlNXg0Z701NOOSUdd9xxadFFF039+vXLn0f4OGjQoBx2RuDbo0ePHHouu+yyM3WMAAAAAAAABY3KysrKyt8Bc7xvv/02tWzZMnU8bHhq3LRZbQ8HAAAAsvFD+9T2EAAAGnRuMHny5NSiRYsq11OpCAAAAAAAAJQkVGSW+Oijj/I8hlW9YvmcotR5jhkzpraHBwAAAAAA8Ic1+eO7gMrnRpwwYULJ5XOKUucZ8yICAAAAAADUd0JFZokmTZqk9u3bp4agoZwnAAAAAADQcGl/CgAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKalF4MzKmeOH231KJFi9oeBgAAAAAAUA+oVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAACipSenFwJyqywnXp8ZNm9X2MAAAAGhAxg/tU9tDAABgBqlUBAAAAAAAAEoSKgIAAAAAAAAlCRUBAAAAAACAkoSKAAAAAAAAQElCRQAAAAAAAKAkoSIAAAAAAABQklARAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEipWw8SJE1OjRo3ShAkTUl3UrVu3NGDAgFRXxLW64447UkNT158TAAAAAACAGdVkhrekzrjtttvS3HPPneZEI0eOzIHppEmTansoAAAAAAAADZZKxSJTpkypl/tu3bp1WmCBBWbZ/kmprKws/frrr7U9DAAAAAAAgIYXKi6zzDJp2LBhFT7r1KlTOvnkk/Pfo5XkpZdemnr27JmaNWuWlltuuXTLLbdUe/+vvPJK6t69e962TZs2qW/fvum7774rX77PPvukXr16pb///e+pbdu2aaWVVsqfP//882nNNddM8847b+rcuXN68cUXp9n3q6++msfVvHnztOiii6a99torffnllxVakvbr1y9X2S200EJpyy23zMFUnNtSSy2VmjZtmo/Zv3//ap3LJZdcklZYYYU8pjjeTjvtVGX707iugwcPTvvtt18OG+N4//jHPyrs75NPPkm77bZbDiTnn3/+fJ7PPfdc+fI777wzrbXWWvl4cd1POeWUGQ7Vjj322LTiiium+eabL+9r0KBB6Zdffilf/tJLL6VNNtkkj7VFixZp7bXXTuPGjUujR49O++67b5o8eXJ+FuJVeDZKifM/7bTT8vnFubVr1y5dfPHFJduURiVkfBbHDPFnvL/vvvvyeOJ+Pfnkk+n3339PZ511Vmrfvn3+LK5tPD/F3n///Xw+cb4dO3ZMzzzzTPmyr776Ko8rxhTLV1999XT99ddX2D6e8fi88Nxuttlm6fvvvy9ffvnll6dVVlkl35uVV145PxsAAAAAAAANulIxAqgdd9wxB0977LFH2nXXXdMbb7wx3e0ihIkgb8EFF0xjx45NN998c3r44Ydz0FfskUceSW+99VZ66KGH0t13351Dx6233jqtuuqqafz48TnEGjhwYIVtIoCKsDKCxwi/7r///vT555+n3r17V1jvqquuSvPMM0966qmn0vDhw9Ott96azjvvvHTZZZeld955J887GOHR9MQxInw89dRT81jjeF26dCm5zTnnnFMeiP7lL39JhxxySN42xDl27do1/fvf/0533XVXvrbHHHNMDszCmDFjUp8+fdLhhx+eXn/99TzeaEM6dXhWXREWxvaxr/PPPz/985//zNehIO7rEksske9TXPPjjjsut3PdcMMNc+gcQeOnn36aX1Pfi6oMHTo0B3px/rG/OJe4xzUV255xxhn5mVtjjTXS8ccfn9/Hcxnnc9111+WQt9jf/va3PM4ILSNMjRCxEMj+9NNPOaS85557cjAdQXcE0hFkhzjHWD8C4ThmhJs77LBDDqTDqFGj0oknnpjvRSyP8DjGEs9aVX7++ef07bffVngBAAAAAADMUXMq7rzzzumAAw7If4/qswiGLrzwwulWZ0XYEwHO1VdfnavVwkUXXZS22WabdOaZZ5YHQbEsKr8i/AtR0Rfh2hVXXJErwTp06JCr+iKUK4j9RKAYgU7BlVdemZZccsn09ttv5yApRGVhVLUVRJC02GKL5cqzCM2iym3ddded7jX46KOP8jgj7IyAbumll87HL+XPf/5zDhMLlYIR4j322GO5GjOuzX//+98c4kWlYojKu4KoSowwbe+9987vo7owrn0EjyeddFKqqRNOOKFCFWEEbjfccEPeX+H8jj766Fx1V7huBS1btswVg3HdamKjjTbK5xDifkSwG9dg8803r9F+IsgtbPO///0vh6Jx/wvXZvnll08bb7xxhW3i/LbaaqvyaxnP0LvvvpvPLyoUi4PRww47LD3wwAPppptuys9ChIoRQEaQGPc5FAfPcf0jMI7lYdllly0PfgtjmtqQIUPyOAAAAAAAAObYSsUNNthgmvfVqVSMdaJSrRAoFoKmCAwLFXuFwKYQKBa2i4q0CBSrGkNU9kVAF61PC69CIPbee++VrxcVaVMHpD/++GMO6Q488MB0++23V6ulaIRaETDFdlHVFtVqP/zwQ8lt4hwKCqHcF198kd9HBV2EkoVAcWpxfhGmFZ9fjDcCr+kdtzI33nhjvvYxhthXhIwRJBYceeSROTiOsDWqAIuv4ex+bqYW1Z4FsX1U/W266abVvvaLL754/rNw7X/77bcc0MZzF9c/rkeEioXrEc9s7D+Wx/MSVZ3ffPNNefVtXJv999+/wr05/fTTS16zqK6MFrKF18cff1zj6wAAAAAAADRstRoqzjXXXOVtHQuK59qbHYpDx+qK9qFR8RjhXPErWpoWtyWdet9RyRiBZlRZxnx5UUkY60/vnKM68YUXXshz70VIFe0vI3yKNqxViUrIYhEsFtqbxrGnd35R2VZ8bjE/ZZxfcdhaHTGfYLQ3jcrJaC8b7UijPeiUKVPK14kWs6+99lqu7nv00Udz69kIXGflcxeKn72q7kHxPZzedavs2sd1D4VrH21Zo9oxqkcjmI5rG216C9ejcePGuRo35nKM6xBVuVFd+sEHH5TPBxpBY/G9iTaqzz77bJXjibkfo4Vs8QsAAAAAAKDehIoLL7xwrn4riLneIjwpNnVYEu9XWWWV6e471omKu6juKogWmBEoRUhTaruXX345t06tagxrrbVWDsGilWe0DS1+TS+kjGAqAskLLrggz5cXoVsEdtPTpEmTXMkX7VRjfBMnTswB3IyISroIo77++utKl8f5Rfg59bnFqxDIVdfTTz+dqywjSIyqv2ht+uGHH06zXrQoPeKII9KDDz6YW3uOGDEifx5VpFHdV1Olnpt47kLxsxfXY3pi7HH/Yh7OGRXP4HbbbZf23HPPHAxH9Wm0zC0WQWRUdkawGyFsXIMIWaNlb9u2bdP7778/zX2JNqgAAAAAAABzZKjYvXv3dM0116QxY8bkYC3mhItKrWI333xznq8wgpeYT+75559P/fr1m+6+ozouqupin1HJFVVhMX9dtA8tzKdYmd133z2HOtHuM+aqu/fee9PZZ59dYZ1DDz00B3K77bZbnpcwWk9GC8t99923ZAA2cuTIPFdjjCeCoWuvvTaHVIW586oSFX4RQkbwFYFczBMZlW+lwtFSYtzRirRXr1455Iqx3HrrrTngDFEJGceIUCvC02j7GXMgFs+NWF0RxEVrz9g+rlOcR3EVYrSDjfsZAWucW4wnrmkhAIzgNir0Isj78ssvq91+NfYTAWw8NxdffHF+jg4//PC8LK75+uuvn1utxrk9/vjj1Tq3eJ6iwjDmgozrE+cTYWXc05pcj6hEjLA1jn3QQQelzz//vHz5c889l+fqHDduXL5ut912W57/snA94p7EHIlxHePc4n83EcCee+651R4DAAAAAABAvQoVY663rl27pq233jq3voyQa/nll6+wToQoEUhFdV0EOdECNNpCTs98882Xg74I/9ZZZ52000475bnqLrroopLbxRx1//rXv3JYE/MORoXdmWeeWWGdqBaL0CoCxC222CLPfzdgwIDUqlWrkpV8sTxaV0YVWpzPww8/nI/Vpk2bkmOK7SJcihA2wqXhw4fn69ChQ4c0I6LyLSoCF1lkkdyWNMYfAVsh0I12nBFkxjpx7SKAO++886YbflZm2223zRWIERx26tQph2mDBg0qXx7H/Oqrr1KfPn1ytWLv3r1Tz549830PG264YTr44IPTLrvskisMIyisjqOOOioHc3EPY87BCN3ivAoiqI75LGPey7h3sU51xNhj3xG8xr2IcRXmS6yOCC+jEjTG0q1bt/JwtyBakz7xxBP5vsT1iPXPOeecfE1CzD15+eWX5yAx7lv87yfCapWKAAAAAADArNSobOpJDeuQqBiMqrbi0AWmJ6obIyiMF9OKNsMtW7ZMHQ8bnho3rd48kQAAADAzjB/ap7aHAABAFbnB5MmTc/FTnaxUBAAAAAAAAOq+ehsqxrxz0aq0slehVWR9EXNKVnUu8apLRo0aVeU4Z7Qd65x6rQAAAAAAAOYUdbr9aSkxV2K8KtOsWbPUrl27VF/8+OOP6d///neVy9u3b5/qiv/973/p888/r3TZ3HPPPUPzLs6p16qu0v4UAACA2qL9KQBA/W1/2iTVU61bt86vOUGEoPUlDFtggQXyq7bUp2sFAAAAAAAwp6i37U8BAAAAAACA2UOoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJTUpvRiYUz1x+m6pRYsWtT0MAAAAAACgHlCpCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUFKT0ouBOVWXE65PjZs2q+1hAAAATNf4oX1qewgAANDgqVQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICShIoAAAAAAABASUJFAAAAAAAAoCShIgAAAAAAAFCSUBEAAAAAAAAoSagIAAAAAAAAlCRUBAAAAAAAAEoSKgIAAAAAAAAlCRVryTLLLJOGDRuW6ruTTz45derUqbaHUefss88+qVevXiXXGT16dGrUqFGaNGnSbBsXAAAAAADAjBAqNqAQqyYi7LrjjjtSQzz3meH8889PI0eOLH/frVu3NGDAgArrbLjhhunTTz9NLVu2rIURAgAAAAAAVF+TGqzLVKZMmZLmmWee2h5Gg/Xbb7/l8LMuqk5QGM/OYostNlvGAwAAAAAA8EeoVCwS1WT9+vXLrwiFFlpooTRo0KBUVlZW3rL0tNNOS3369EktWrRIffv2zZ/feuutqUOHDqlp06Z5nXPOOafCfr/44ou0zTbbpGbNmqVll102jRo1qsLyiRMn5nBswoQJ5Z9FS8z4LFpkFrz22mtp6623zsdeYIEF0p/+9Kf03nvv5RakV111VbrzzjvzNlNvV1UgGue5+OKLp3nnnTctvfTSaciQIeXnGbbffvu8r8L7cMYZZ6RFF100H3///fdPP/30U42u8ZVXXll+reLYMYaCc889N62++upp/vnnT0suuWT6y1/+kr777rvy5VH516pVq3TXXXelVVddNe9jv/32q/G5F673DTfckKsF4/xXW2219Pjjj1dYL96vu+665WM97rjj0q+//lq+/JZbbsnjjfvapk2btNlmm6Xvv/9+murJ+HvsK6oXC2OMMVTW/nR6z1J8Nnjw4HzecQ+WWmqp9I9//KPk+f7888/p22+/rfACAAAAAACoCaHiVCKgatKkSXr++edzCBRB1+WXX16+/Oyzz04dO3ZML774Yg4cx48fn3r37p123XXX9Morr+SALz4vbn0ZodLHH3+cHnvssRxEXXLJJTlorIl///vfqUuXLjlsevTRR/NxI1iKkGvgwIF5DD169MjtNOMVYVkpF1xwQQ7nbrrppvTWW2/loLMQHo4dOzb/OWLEiLyvwvtYN84vQq1x48bloC3OpbouvfTSdOihh+YwNq5VHL99+/bly+eaa648rghP4z7EeR5zzDEV9vHDDz+kM888M9+TWC/Wr+m5Fxx99NHpqKOOyvdygw02yMHvV199VX69//znP6d11lknvfTSS3nsV1xxRTr99NPz8jjObrvtlu/BG2+8kQPCHXbYoTyALhbPUez/wAMPLB9jhKZTq86zFCJo7Ny5cx53BK+HHHJIvodVibA4QvLCq7JjAwAAAAAAlKL96VQicDnvvPNyBdlKK62Uw514H4FQ6N69ew6iCvbYY4+06aab5vAnrLjiiun1119PQ4cOzWHi22+/ne67774cUkZAFSKcWmWVVWo0rosvvjgHQlFdN/fcc5cfqyCq5aIirbrtND/66KO0wgorpI033jifa1QqFiy88ML5z6gKLN7fsGHDcnVivEIEbA8//HC1qxVj/bh2hx9+ePlnhWsSiuccjIAz1j/44IMrBJe//PJLfh/B7oyee0FUSe6444757xEa3n///fneRJAZx4hn4aKLLsrXZ+WVV07/+c9/0rHHHptOPPHEHAxGoBtBYuHaRdViZeK+RavT+eabr+QYI8Au9SwVRNgZYWKI8cTzGYF1PK+VOf7449ORRx5Z/j4qFQWLAAAAAABATahUnMr6669fYZ6+qDB755138vx9ISrEikWV2kYbbVThs3hf2CaWR+Xj2muvXb48AqoI7GoiWqNGu9NCoPhHRUgV+4wgqn///unBBx+c7jZxLuutt16Fz+L6VEdUZkYoF6FZVSKgjOXt2rXLrT332muvXDkY1YkFEc6tscYaaWYoHnvco7i3cY4h/ozlxc9C3Ndox/rJJ5/kUDPGGkHizjvvnP75z3+mb7755g+NZ3rPUkHx+cf4IqgsVfka1a3RMrf4BQAAAAAAUBNCxRqK+f5mtmj7GYpbZ0ZFXrGoxpuZ1lprrfTBBx/kOSJ//PHH3HZzp512SrPK9MYfcwzGfJERmMW8gtEKNKozC/M/Fu+nOOirLY0bN04PPfRQrkKN+R0vvPDCHNDGNZ3Vpg6W43r8/vvvs/y4AAAAAABAwyVUnMpzzz1X4f2zzz6b24RGiFSZaGP61FNPVfgs3kfrytgmqhKjTWaEZAUx/92kSZOmaTcaLTULooqwWIRtY8aMmSZsLK7gK65mq46oWNtll11yld2NN96Yw7yvv/66PLiaen9xrpVdn+qIysNoafrII49UujyuTwRjMV9gVIvG9YvKxuqYkXOfeuyFe1RoSxt/PvPMMxWC3rivcR5LLLFEeZgXlYSnnHJKnt8wxnH77bfP8Bin9ywBAAAAAADUFqFiJXMNxvxzEfxdf/31uQKteA7AqcUcgRGURcVfzJ941VVX5Xn4Bg4cmJdH9VqPHj3SQQcdlAO5CK4OOOCACpV78fcI0s4444zcAvPxxx9PJ5xwwjTz/8VceLvuumsaN25cbol5zTXX5HGGCOxefvnl/P7LL7+sMnwsnr8vzu/NN9/M47755ptzG81CW9ZCAPjZZ5+Vt/WM63DllVemESNG5G1OOumk9Nprr1X72p588sk5NLzgggvy+F944YV8fUP79u3zmOP9+++/n89t+PDh1dpvTc+9ICohIwSMa3DooYfm89xvv/3yspiz8OOPP06HHXZYXn7nnXfm841nIypL414OHjw434t4Zm677bb03//+t8q5MmOMsU1UZMYYK6ssnN6zBAAAAAAAUFuEilPp06dPbge67rrr5qApgrS+ffuWbCN60003pRtuuCGtttpq6cQTT0ynnnpqnrOwIEK4tm3bpq5du6Yddtgh72+RRRapsJ8I66JaLuZeHDBgQDr99NMrLG/Tpk169NFH85x+sZ9YLyoMC60wDzzwwBxgxryAUfk4dcXb1KLi7qyzzsrrr7POOjnsuvfee8tbsUb4F+09l1xyybTmmmvmz6KqcdCgQemYY47Jx//www/TIYccUu1ru/fee6dhw4alSy65JHXo0CG3O41wMcQchRF0nnnmmfk6jho1Kg0ZMqRa+63puRdEiBuvOPaTTz6Z7rrrrrTQQgvlZTGvY1yP559/Pi8/+OCD0/77718e9kaV5xNPPJH+/Oc/50rC+DyuWc+ePSs9VgSDUW0YrVJjjBFEzsizBAAAAAAAUBsalRX3d2zgunXrljp16pSDL+ZcEaAuu+yyuWVp3O+GJipeW7ZsmToeNjw1bjpz5+oEAACYFcYP7VPbQwAAgDk+N5g8eXIuqqqKSkUAAAAAAACgJKHiHCrm+2vevHmlr6padP5RVR0vXmPGjElz8rkDAAAAAADMybQ/nUN9/fXX+VWZZs2a5TkDZ7Z33323ymVxvDjunHru9Yn2pwAAQH2j/SkAANR++9Mms3AM1KLWrVvn1+zUvn371FDPHQAAAAAAYE6m/SkAAAAAAABQklARAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKalJ6MTCneuL03VKLFi1qexgAAAAAAEA9oFIRAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgpCalFwNzqi4nXJ8aN21W28MAAABmovFD+9T2EAAAgDmUSkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICShIoAAAAAAABASUJFAAAAAAAAoCShYj335ptvpvXXXz/NO++8qVOnTmnixImpUaNGacKECam+WmaZZdKwYcPSnKpbt25pwIABtT0MAAAAAACAahMq1nMnnXRSmn/++dNbb72VHnnkkbTkkkumTz/9NK222mozvM+RI0emVq1azdRxAgAAAAAAUH8JFeu59957L2288cZp6aWXTm3atEmNGzdOiy22WGrSpEml65eVlaVff/011bbffvst/f7777Nk31OmTEkNzay8ngAAAAAAAELFWmjlGW1KTz755Pz3aFV66aWXpp49e6ZmzZql5ZZbLt1yyy3V2ndsO378+HTqqafmv8c+p25/Onr06Pz+vvvuS2uvvXZq2rRpevLJJ9NLL72UNtlkk7TAAgukFi1a5GXjxo3L6++7775p8uTJebvCfqfnm2++SX369EkLLrhgmm+++fL5vPPOO9NUP951111p1VVXzeP46KOP0hdffJG22WabfO7LLrtsGjVq1DT7njRpUjrggAPSwgsvnMfavXv3PP6CGF9c08svvzzvI1rBVqcFaf/+/dMxxxyTWrdunYPY4vOsrI1sjCM+i2tUfG0feOCBtOaaa+ZziLHFOcX1XmWVVfJ4d9999/TDDz9UOH4Eu/369UstW7ZMCy20UBo0aFAOfAt+/vnnNHDgwNSuXbtcibreeuuVH7fU9QQAAAAAAJgVhIp1QARKO+64Yw7K9thjj7TrrrumN954Y7rbRZvTDh06pKOOOir/PUKoqhx33HHpjDPOyPtdY4018nGWWGKJNHbs2BxMxvK55547bbjhhjkEjTAs9jm9/Rbss88+OZSMkOuZZ57JAdmf//zn9Msvv5SvE8HamWeemcO/1157LS2yyCJ5u48//jg99thjOUy95JJLcihXbOeddy4P6mKsa621Vtp0003T119/Xb7Ou+++m2699dZ02223VXs+yauuuioHds8991w666yzcjj70EMPpZqKMPKiiy5KTz/9dD6X3r1752t43XXXpXvuuSc9+OCD6cILL5zm2FFN+vzzz6fzzz8/nXvuufm6FETgGNfxhhtuSC+//HK+Bj169KgQ1FZ2PSsTAeW3335b4QUAAAAAAFATlffIZLaKwCgq8cJpp52Wg60IoSJgK6XQ5rR58+b57+HLL7+sdN0IzDbffPPy91HVdvTRR6eVV145v19hhRXKl0X1XFTgFfY5PRF0RZj41FNP5VAyRMVhzO94xx135PMLETDGOXXs2DG/f/vtt3NQGMHaOuuskz+74oorcoVfQVRVxvIIFaMaL5x99tl5vxFC9u3bt7zl6dVXX52rGasrwtWYk7Jw/hEMxryUxdepOk4//fS00UYb5b/vv//+6fjjj89taaPqNOy00045ND322GPLt4lrc9555+XrvNJKK6VXXnklvz/wwAPzvRkxYkT+s23btnn9CHbvv//+/PngwYMrvZ5VGTJkSDrllFNqdE4AAAAAAADFVCrWARtssME076tTqVgTnTt3rvD+yCOPzEHmZpttlisYIwSbUTHWCDejRWdBzO8YYVnxecwzzzw5yJt6u2i9WhAhZ7T1LIjqze+++y7vL8LTwuuDDz6oMOaYU7ImgWIoHktYfPHFp6mSrOl+Fl100dz+tRAoFj6ber/rr79+DhSL73mEszE3YgSM8eeKK65Y4Zwff/zxCuc89fWsSoSc0c628IpqSgAAAAAAgJpQqTiLzTXXXBXmygvFLUFnl2jzOXXLzpjrL9pzRrVgVOxFq83tt99+lo0h5hwsDtKqIwLFCPuK5xMsKA4fpz6/6oh2r8VibL///nv5fQvF966q+1a8n9hHqf1W95wbN26cW73Gn8UiXKzp9YwKz0KVJwAAAAAAwIxQqTiLRfVczEtYEPPZRZVdsWeffXaa98UtQGeVqIQ74ogj8px/O+ywQ26tWaiAi0q56oqx/vrrr3luwoKvvvoqvfXWW2nVVVetcruoSoztIjwriG0mTZpU/j7mT/zss89yRWP79u0rvBZaaKE0qxSqHovvXXXnaqyO4mtVuOfRgjVCxDXXXDNf/6hunPqcq9uSFgAAAAAAYGYSKs5i3bt3T9dcc00aM2ZMbmu59957T1N9dvPNN6crr7wyzzEYFYMxh2C/fv1m2Zh+/PHHvP+o/vvwww/zXIhjx44tDzKXWWaZXC0X8wvGHI0//PBDyf1FGLbddtvl+QBjDsRoWbrnnnumdu3a5c+rEu1Re/TokQ466KAcskW4GC1ZowKvINqzRmvQXr165fBz4sSJ6emnn05/+9vf0rhx49KsEmOIFqXRGjbatEbr0RNOOGGm7T/mS4wWtBGiXn/99XkOzcMPP7w87N1jjz1Snz590m233ZZD6HgmYm7EqCwFAAAAAACY3YSKs1jMZ9e1a9e09dZbp6222iqHY8svv3yFdU455ZTcejTmx7v66qtzyFSqwu+PilAzKgkjtIoAq3fv3qlnz555HGHDDTdMBx98cNpll11yxd5ZZ5013X1GlWPMjRjnGSFgtA299957p2kFWtl2bdu2zdcoqiX79u2bFllkkfLl0d4z9tOlS5e077775vHuuuuuOQyNuQpnpQh6o5IyzmvAgAHp9NNPn2n7jmsf4e66666bDj300BwoxrkXX5dY56ijjsrhazw3EfwutdRSM20MAAAAAAAA1dWobOoJ/5itIjS7/fbbc2gEs0O04G3ZsmXqeNjw1Ljp/6sKBQAA6r/xQ/vU9hAAAIB6mhtMnjw5tWjRosr1VCoCAAAAAAAAJQkV67DBgwen5s2bV/qKdqWzS8wHWdU44lXXxHyFpcYbywEAAAAAAKi+JjVYl1mgVPfZmNcw5jusTLNms69tZefOndOECRNSfRFzNJYabywHAAAAAACg+oSKdVjr1q3zq7ZFgNm+fftUXzRp0qRejRcAAAAAAKCu0/4UAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJTUpvRiYUz1x+m6pRYsWtT0MAAAAAACgHlCpCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUFKT0ouBOVWXE65PjZs2q+1hAABAvTR+aJ/aHgIAAMBspVIRAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFScwy2zzDJp2LBhqb7bZ599Uq9evWp7GAAAAAAAAA1Sk9oeAPUv3Js0aVK64447Zutxzz///FRWVjZbjwkAAAAAAMD/ESrWA1OmTEnzzDNPashatmyZGroIVX/77bfUpIn/2QIAAAAAALOX9qe1oFu3bqlfv375FWHZQgstlAYNGlReiRctS0877bTUp0+f1KJFi9S3b9/8+a233po6dOiQmjZtmtc555xzKuz3iy++SNtss01q1qxZWnbZZdOoUaMqLJ84cWJq1KhRmjBhQvlnUXUYn40ePbr8s9deey1tvfXW+dgLLLBA+tOf/pTee++9dPLJJ6errroq3XnnnXmbqberTCyP9eI4BXH8+CzGE0aOHJlatWqVHnjggbTKKquk5s2bpx49eqRPP/20yvan33//fb4+se7iiy+er0Vc1wEDBpSvE8eYuqIyjhPHK/j4449T79698+etW7dO2223Xfm4pmfq44UYY4y14JJLLkkrrLBCmnfeedOiiy6adtppp/Jlv//+exoyZEi+V3HPOnbsmG655ZZprt19992X1l577Xzfn3zyyfTSSy+lTTbZJN+buEexbNy4cVWO8+eff07ffvtthRcAAAAAAEBNCBVrSYRzUXH2/PPP59ae5557brr88svLl5999tk5ZHrxxRdz4Dh+/Pgcfu26667plVdeyQFffF4ckEWYFSHZY489lsOpCLQiaKyJf//736lLly45wHr00Ufzcffbb7/066+/poEDB+YxFAK/eG244YYz5Xr88MMP+Zyvueaa9MQTT6SPPvooH68qRx99dHr88cdzwPnggw/mAO6FF16o0TF/+eWXtOWWW+ZwbsyYMempp54qDzSjOvSPiqCvf//+6dRTT01vvfVWuv/++/O1LYhA8eqrr07Dhw/PQe4RRxyR9txzz3xexY477rh0xhlnpDfeeCOtscYaaY899khLLLFEGjt2bL4/sXzuueeuchxxnAivC68ll1zyD58bAAAAAADQsOijWEsi2DnvvPNyJdpKK62Ug8J4f+CBB+bl3bt3T0cddVT5+hEkbbrppjlIDCuuuGJ6/fXX09ChQ3OY+Pbbb+eKtggp11lnnbzOFVdckSv/auLiiy/OwdMNN9xQHlTFsQqioi4q3xZbbLE0M0XAF+Ha8ssvn99HFWeEcZX57rvv8rlde+21+ZoUQtoI2mrixhtvzNWCEebGfQgjRozIVYsRUm6xxRZ/6JwiGJ1//vlz1WcEl0svvXRac80187K4hoMHD04PP/xw2mCDDfJnyy23XK5EvOyyy1LXrl3L9xPXYfPNN6+w3whVV1555fw+KiFLOf7449ORRx5Z/j4qFQWLAAAAAABATahUrCXrr79+eZAVIlh655138px5oXPnzhXWjyq1jTbaqMJn8b6wTSyPysdohVkQoVMEZDURrUmj3WmpyrdZYb755isPFEO0NK2qyjJasUYl4XrrrVf+WbQujXC2JqKN6LvvvpsDv6hQjFfs56effsrH+KMiCIwgMcLCvfbaK7ejjYrMEMeNv8c6hWPHKyoXpz721M9CBIQHHHBA2myzzXIF4/TGGlWn0Sa1+AUAAAAAAFATKhXrqKhwm9nmmuv/MuTC3I2FCsFiUYk4u48Zpg4xI3At3mZGVLaP4mNHxWOEsFPPPRkWXnjhap1bqf1HWBktWaPqMVq0nnjiibltbbQtjWOHe+65J7Vr126aELDUsxD72H333fO2UZ160kkn5crS7bfffrpjBgAAAAAAmBEqFWvJc889V+H9s88+m9tYNm7cuNL1o41pzPlXLN5Ha9LYJqoSY97DmGOvIObxmzRp0jRBWcyFWFyZWCzm7Iv5BSsL/sI888xTXk1ZHdU5Zk1FRWOEkMXX8JtvvsktYKc+dvFxo6qzUCkY1lprrfzZIossktq3b1/hFS1gq3NuxfuP6/Lqq69WWCeqR6Oi8Kyzzkovv/xymjhxYp6rctVVV83hYbQynfrY1WlNGvc95mCMsHKHHXbIbVsBAAAAAABmFaFiLYkwKdpYRvB3/fXXpwsvvDAdfvjhVa4f8ys+8sgj6bTTTsvhWcwheNFFF6WBAwfm5dH6s0ePHumggw7KYVuEi9Eis7jyMP4ebVejZWa0S3388cfTCSecUOE4MZdhzLm36667pnHjxuXQ7ZprrsnjDMsss0wOx+L9l19+WWX4WFAIyaK6LvYV1XXnnHPOH7p20SZ0//33z/MKRkAXQV7MK1moiiyIeSnjGr344ov5XA4++OAKFZExT+VCCy2UtttuuxykfvDBB7mqsH///umTTz6Z7jhi/3E+8XrzzTfTIYccUiHEvfvuu9MFF1yQQ9QPP/wwtzaNORzjXkUVY9y7CAbjXkYL06hqjOcg3lflxx9/zPcoxhn7jGA5Kh9rOncmAAAAAABATQgVa0mfPn1yQLTuuuumQw89NAeKffv2rXL9qKq76aabcpvL1VZbLbfSPPXUU3OYVhDVam3btk1du3bN1Wuxv6jCK3bllVfmisZo+zlgwIB0+umnV1jepk2bHNRFe87YT6z3z3/+szyMO/DAA3MoFvP8RaXe1NWTU4vtIjSN0C2qIM8888xpjjkjhg4dmud+3GabbXIl4MYbb1xhPskQ4WUEmrFetAuNEC/mbiyIvz/xxBNpqaWWytcrgrkIK2NOxerMO7jffvulvffeO9/LuFYxd+Imm2xSvjzms7ztttty+Bj7Hj58eL4WHTp0yMsjIB40aFAaMmRIXh6hcASUyy67bJXHjKrUr776Kh8zqhV79+6devbsmU455ZQZvJIAAAAAAADT16jsj05cR41169YtderUKQ0bNqy2hzJHcV2rJypRo71rx8OGp8ZNZ+4cmgAA0FCMH9qntocAAAAwU3ODyZMnlyy6UqkIAAAAAAAAlCRU5A8ZPHhwnuOwsle05azPqjqveMUcjAAAAAAAAA1Fk9oeQEM0evToNKc4+OCD87x+lWnWrFm9vq4TJkyoclm7du1m6rEAAAAAAADqMqEif0jr1q3za07Uvn372h4CAAAAAABAnaD9KQAAAAAAAFCSUBEAAAAAAAAoSagIAAAAAAAAlCRUBAAAAAAAAEpqUnoxMKd64vTdUosWLWp7GAAAAAAAQD2gUhEAAAAAAAAoSagIAAAAAAAAlCRUBAAAAAAAAEoSKgIAAAAAAAAlCRUBAAAAAACAkoSKAAAAAAAAQElCRQAAAAAAAKCkJqUXA3OqLidcnxo3bVbbwwAAgJlm/NA+tT0EAACAOZZKRQAAAAAAAKAkoSIAAAAAAABQklARAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKFiHbHPPvukXr16lb/v1q1bGjBgwAzvb/To0alRo0Zp0qRJqaFewzlB3MM77rijtocBAAAAAAA0cELFOuq2225Lp512WrXWrSyA3HDDDdOnn36aWrZsOdPG1NACrpEjR6ZWrVrNlmOdfPLJqVOnTtN8HvewZ8+es2UMAAAAAAAAVWlS5RJmyG+//ZbDt7nm+mN5bevWrf/Q9vPMM09abLHFUn0zZcqUPPY5xR89n/p4DwEAAAAAgDlPg6hUXGaZZdKwYcMqfBZVYVEdVlZWlv9caqmlUtOmTVPbtm1T//79y9f7+eef08CBA1O7du3S/PPPn9Zbb73cWnTqara77rorrbrqqnkfH3300XSDxyOPPDJv16ZNm3TMMcfkcZSqPrzkkkvSCiuskOadd9606KKLpp122qm85efjjz+ezj///BxmxmvixInTtD8tjPOBBx5Iq6yySmrevHnq0aNHroQrduWVV6YOHTrk81h88cVTv379yq9h2H777fN+C++rU3132WWXpSWXXDLNN998qXfv3mny5MnTtCz9+9//nq/9SiutlD9/5ZVXUvfu3VOzZs3yNerbt2/67rvvanQNS933grg+Bx10UL6mcW1XW221dPfdd+frt+++++axFq5r8XZViWNGhWmfPn1SixYt8rjDsccem1ZcccV8DZZbbrk0aNCg9Msvv5Tfm1NOOSW99NJL5ceKzyqrDp3edQEAAAAAAJgVGkSoWMqtt96azjvvvBx8vfPOOznAWX311cuXR6j2zDPPpBtuuCG9/PLLaeedd85hXKxb8MMPP6QzzzwzXX755em1115LiyyySMljnnPOOTk0igDvySefTF9//XW6/fbbq1x/3LhxOeg89dRT01tvvZXuv//+1KVLl7wswsQNNtggHXjggTkgjFcEeJWJcZ599tnpmmuuSU888UQOPyMwLbj00kvToYcemoOqCK8iKG3fvn1eNnbs2PzniBEj8jEK76fn3XffTTfddFP617/+lcf94osvpr/85S8V1nnkkUfyeT300EM50Pv+++/TlltumRZccMF8nJtvvjk9/PDD5QHnjFzDyvz++++5tehTTz2Vrr322vT666+nM844IzVu3Di3j41AMoLBwnUtvlalxDXu2LFjPtcID8MCCyyQxxvHiHv2z3/+Mz93YZdddklHHXVUDnMLx4rPplad61KZCMa//fbbCi8AAAAAAICaaPDtTyNYixaTm222WZp77rlzxeK6665bvixCtPgzquhCBEsRjsXngwcPzp9FxVlUEkaQVB0RVh1//PFphx12yO+HDx+eKwhLjTGqJLfeeuscTi299NJpzTXXzMtizsRorxkVcNNrlRnjjGMtv/zy+X2EURFUFpx++uk53Dr88MPLP1tnnXXynwsvvHD+MyoDa9KS86effkpXX311rvQMF154Ydpqq61yKFjYT5xbBLKFNqERuBW2i2XhoosuSttss00Ob6OqsKbXsDIRyD3//PPpjTfeyFWEIaoIC+LaRqVgTVuQRiVhXMdiJ5xwQoVqxniOIqiOCsuoOozK0SZNmpQ81nXXXTfd61KZIUOG5EpIAAAAAACAGdXgKxWj8vDHH3/MYVJU+0W126+//pqXRbVetNmMwClCn8Ir2o2+99575fuIMGyNNdao1vGinWZUokUb1YIIkzp37lzlNptvvnkOEmOMe+21Vxo1alSuOqypCB4LgWKI9qZffPFF/nv8+Z///CdtuummaWaKkLYQKIaoqowKwahMLIjK0OJ5ByPki4C2EJyFjTbaqHy7GbmGlZkwYUJaYoklygPFmaWycdx44435HCI0jGcoQsbptcmd2vSuS1UifI1rVnh9/PHHNTwjAAAAAACgoWsQoeJcc801zXx7hfnsolVoBDJRaRgVY9GaM1qLxvKYqy5aYY4fPz4HUIVXhDvRwrIgtouKtlklqhNfeOGFdP311+cg8MQTT8zhUmG+xOqKSsxiMebCdYlzqC3FIdnsuu+z8pynPp9on7vHHnukP//5z7m9a7RF/dvf/pamTJmSZoeYHzPauBa/AAAAAAAAaqJBhIrRujMq2wpiTrkPPvigQrgULSQvuOCCNHr06BwCRZVitBiNSsWo4ou5BYtfNW2JWdxSM4LB5557rvyzqIyM4LKUqMSLFq1nnXVWnttx4sSJ6dFHH83LosovxvlHg8toyxnzG5YKJWt6nKjGiwrIgmeffTaHfSuttFKV26yyyirppZdeynMIFsS8h4XtqnsNp3ffo7r0k08+SW+//Xal45gZ1zU8/fTTudI0gsSoYlxhhRXShx9+WONjTe+6AAAAAAAAzCoNIlSMOe6uueaaNGbMmBwW7r333rkCMYwcOTJdccUV6dVXX03vv/9+uvbaa3PIGCFQtMWMCrM+ffqk2267LQdSMQdfzFF3zz33zPB4Ys7CM844I91xxx3pzTffzNWRpaoOo7otAs+okowwKubUi5aXhSApwsAI2CJo/PLLL/OyGXHyySfnuQ7jWO+8806ujow5EAsKoeNnn32Wvvnmm2rtc955583XO8KwuP79+/dPvXv3LhnKxjUvbBf35bHHHkuHHXZYbv1amDewOtew1H0PXbt2zVWpO+64Y3rooYfy/b3vvvvynJmF841q1TjnuK4z0nI2RIgY4WrMoRhtc+P6RpvdYnGsOH7c4zjWzz//PEPXBQAAAAAAYFZoEKFizCkXAdLWW2+dttpqq9SrV6/yuQVbtWqV/vnPf+a56aJy7eGHH07/+te/Ups2bfLyESNG5FDxqKOOyiFebDt27Ng8V+CMin1FEBThUMwxGFWC22+/fZXrxxgj1IyQLKrVhg8fnluhdujQIS8fOHBgDstWXXXVXJ1X07n6CmI8w4YNy61gY99xvSJcLIjAMcK3aBkbVZzVEVWdO+ywQ279ucUWW+RrHPuf3tyPDzzwQPr666/TOuusk3baaac81+NFF11Uo2tY6r4X3HrrrfkYu+22W75+xxxzTHnF4IYbbpgOPvjgtMsuu+TrGlWiM2LbbbdNRxxxROrXr1/q1KlTrlwcNGhQhXUi2OzRo0faZJNN8rHi/s7IdQEAAAAAAJgVGpVNPekczCRR+RiVhFF9R90RbWCjhWzHw4anxk1rby5NAACY2cYP7VPbQwAAAKi3ucHkyZNTixYtGnalIgAAAAAAADDjmvyBbalC8+bNq1wWc/b96U9/SnOCaJEaczxW5rLLLktzmpibsWfPnlUuj/kXAQAAAAAA5kRCxVmgVLvPdu3apTnFvffem3755ZdKly266KJ5nsNogTqn6Ny5s1auAAAAAABAgyRUnAXat2+fGoKll146NSTNmjVrMPcWAAAAAACgmDkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUFKT0ouBOdUTp++WWrRoUdvDAAAAAAAA6gGVigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACU1Kb0YmFN1OeH61Lhps9oeBgAAtWT80D61PQQAAADqEZWKAAAAAAAAQElCRQAAAAAAAKAkoSIAAAAAAABQklARAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKHiHGDixImpUaNGacKECWlOEOdyxx13pDnVMsssk4YNG1bbwwAAAAAAAKg2oSLTOPnkk1OnTp1qexgAAAAAAADUEUJFasWUKVPq5b7rqoZ4zgAAAAAAwOwjVKzFlpdRDRhVgYWWn5deemnq2bNnatasWVpuueXSLbfcMkPH+u2339L++++fll122byvlVZaKZ1//vkV1hk9enRad9110/zzz59atWqVNtpoo/Thhx+mkSNHplNOOSW99NJLeUzxis+m56OPPkrbbbddat68eWrRokXq3bt3+vzzz6epfrz88svzuOadd978+TvvvJO6dOmS36+66qrpoYcemmbfH3/8cd5fjLN169b5ONHytWCfffZJvXr1Sn//+99T27Zt8/lW534MHjw47bfffmmBBRZISy21VPrHP/5R4frEuU+aNKn8s2gvG58Vjh3XJcZ0991352PON998aaeddko//PBDuuqqq/IxFlxwwdS/f/98T4r973//S7vttlu+/u3atUsXX3xxheVx3AMOOCAtvPDC+Xp2794935PpXc/K/Pzzz+nbb7+t8AIAAAAAAKgJoWIdMmjQoLTjjjvm8GiPPfZIu+66a3rjjTdqvJ/ff/89LbHEEunmm29Or7/+ejrxxBPTX//613TTTTfl5b/++msO4bp27Zpefvnl9Mwzz6S+ffvmwGyXXXZJRx11VOrQoUP69NNP8ys+m97xIuj7+uuv0+OPP56Dwffff3+a7d5999106623pttuuy0HdLHdDjvskOaZZ5703HPPpeHDh6djjz22wja//PJL2nLLLXPwN2bMmPTUU0/l4LJHjx4VqvMeeeSR9NZbb+VjR8hXHeecc07q3LlzevHFF9Nf/vKXdMghh+R91EQEiBdccEG64YYb0v3335/DyO233z7de++9+XXNNdekyy67bJqAeOjQoaljx4752Mcdd1w6/PDDKwSqO++8c/riiy/Sfffdl8aPH5/WWmuttOmmm+ZrXNX1rMqQIUNSy5Yty19LLrlkjc4RAAAAAACgSW0PgFQhSIrqtHDaaaflkOnCCy9Ml1xySY32M/fcc+dqw4KoZIvgMELFqPiLSrXJkyenrbfeOi2//PJ5nVVWWaV8/QjtmjRpkhZbbLFqHS8CvVdeeSV98MEH5YHV1VdfnYPJsWPHpnXWWSd/FiFgfB7Vd+HBBx9Mb775ZnrggQdyhWGI6sGo1iy48cYbc/gYFXkReoYRI0bkCsEI8LbYYov8WVT8xToRUFbXn//85xwmhggzzzvvvPTYY49Vq9KxOPSMCtPCdYxKxQgSo0ozrmNUX26yySZ5v8Uha1SGRpgYVlxxxRyWxvE333zz9OSTT6bnn38+h4pNmzbN65x99tnpjjvuyOFkBMCVXc+qHH/88enII48sfx/3X7AIAAAAAADUhFCxDtlggw2meV+qAq2UaKd55ZVX5rakP/74Yw6gol1miBai0TI0KgAjxNpss81y2Lj44ovP0LGimjJCquKgKsK0CP5iWSFUXHrppSsEYIXtCoFi4ZyLRdVmVORFpWKxn376Kb333nvl71dfffUaBYphjTXWKP97BJYRokaQVxPR8rQQKIZFF100tz2NQLH4s6n3W9m9LrTHjXP+7rvvUps2bSqsE/ex+Jynvp5ViWCyEE4CAAAAAADMCKHibDLXXHOlsrKyaarcZoVoxTlw4MDc3jPCqgjkot1mtBgtiGq/mOsvWnZGNeAJJ5yQKyPXX3/9NKtENWFNRbi29tprp1GjRk2zrDhQm5F9R0VnsQgWoyqycL9C8T2r7H5Vto9S+63uOUfAG5WYU4ug9o+cMwAAAAAAwIwQKs4mEYDF/ITFLSijXWixZ599NvXp06fC+zXXXLPGx4pWmhtuuGF5a89QXOFWEPuOV7THjPDxuuuuy6FiVPz99ttv1T5etE79+OOP86tQrRhzOU6aNClXLE5vu7guhSrJOOdiMZdghJ6LLLJIatGiRZpdCoFljG3BBRfMf5/RqtHKTH2e8b7QgjbO+bPPPsstaKPqEQAAAAAAoLb9XzkWs1z37t3zXHtjxozJ8w/uvffeqXHjxhXWufnmm3PL0rfffjuddNJJeV69fv361fhYK6ywQho3blyeqzD2NWjQoDy3YUGEmREkxjyLH374YZ7b8J133ikPtSLIinUiRPvyyy/Tzz//XPJ40T412o/uscce6YUXXsjjjnC0a9euqXPnziW3i/kE41pEy8+4Nn/7298qrBP7XGihhdJ2222Xl8e4ooIvqiw/+eSTNKu0b98+B6Qnn3xyvjb33HNPrvycWSL4Peuss/L9iVa1ce8PP/zw8usSIW+vXr3yvZk4cWJ6+umn87WJ+woAAAAAADC7CRVnkwjxImTbeuut01ZbbZUDo+K5+MIpp5ySW5fGXH9XX311uv7660tW+lXloIMOSjvssEPaZZdd0nrrrZe++uqrClWLMQ/gm2++mXbccccc6vXt2zcdeuihebsQn/fo0SNtsskmuWIvxlFKtPe88847c0Vfly5dcii23HLL5QrDUqLF6O23357nClx33XXTAQcckP7+979XWCfG+sQTT6Sllloqn1MEn/vvv3+eU3FWVi5GC9M477hOcT/OPPPMdPrpp8+0/R911FE5IIxK0djvueeem+e4LFzPe++9N1/LfffdN9+jXXfdNQfAMT8jAAAAAADA7NaobOqJ/qgVESRFwBZhI8xK0Xq3ZcuWqeNhw1Pjps1qezgAANSS8UP/39QLAAAANFzf/v+5weTJk0sWdKlUBAAAAAAAAEoSKtYDgwcPTs2bN6/01bNnz1l+/FGjRlV5/A4dOqS6JuZerGq88QIAAAAAAKBmmtRwfWaRUl1oDz744NS7d+9KlzVrNuvbV2677bZ5bsaq5h6sazp37pwmTJhQ28MAAAAAAACYYwgV64HWrVvnV21ZYIEF8qu+iKC1ffv2tT0MAAAAAACAOYb2pwAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAACipSenFwJzqidN3Sy1atKjtYQAAAAAAAPWASkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICSmpReDMypupxwfWrctFltDwMAoMEaP7RPbQ8BAAAAqk2lIgAAAAAAAFCSUBEAAAAAAAAoSagIAAAAAAAAlCRUBAAAAAAAAEoSKgIAAAAAAAAlCRUBAAAAAACAkoSKAAAAAAAAQElCRQAAAAAAAKAkoSIAAAAAAABQklCReunkk09OnTp1mu3H3WeffVKvXr1m+3EBAAAAAABqk1CRWg3bhHQAAAAAAAB1n1CR6frtt9/S77//nhqSX375ZZbst6ysLP3666+zZN8AAAAAAACzilCxnlpmmWXSsGHDKnwW7UCjLWgEV/HnUkstlZo2bZratm2b+vfvX77ezz//nAYOHJjatWuX5p9//rTeeuul0aNHly8fOXJkatWqVbrrrrvSqquumvfx0UcfVTmWONZVV12V7rzzztSoUaP8KuzvlVdeSd27d0/NmjVLbdq0SX379k3ffffddLc79thj04orrpjmm2++tNxyy6VBgwbNcNAXgeipp56allhiiXwucZ3uv//+8uUTJ07Mx77xxhtT165d07zzzptGjRqVw9QjjzwyX4sY+zHHHJOv7dT7HjJkSFp22WXzOXbs2DHdcsst5cvjfGLf9913X1p77bXz8Z988sn00ksvpU022SQtsMACqUWLFnnZuHHjpnsu++23X1pjjTXyPQxTpkxJa665ZurTp88MXRsAAAAAAIDqaFKttahXbr311nTeeeelG264IXXo0CF99tlnOcQq6NevX3r99dfz8ggcb7/99tSjR48cAK6wwgp5nR9++CGdeeaZ6fLLL8+B2iKLLFLl8SKgfOONN9K3336bRowYkT9r3bp1+v7779OWW26ZNthggzR27Nj0xRdfpAMOOCAfP4LLqrYLEbbFOjG+GNeBBx6YP4tgr6bOP//8dM4556TLLrssB3BXXnll2nbbbdNrr71Wfr7huOOOy+vFOhEsxt9jDLH+Kquskt/HtYqQtCACxWuvvTYNHz487+uJJ55Ie+65Z1p44YVzQFm877PPPjsHpAsuuGDq0qVLPs6ll16aGjdunCZMmJDmnnvu6Z7LBRdckIPL2F/c47/97W9p0qRJ6aKLLqpymwggCyFkiOsNAAAAAABQE0LFOVBUFS622GJps802y0FVVCyuu+665csiwIs/I7ALEe5F5V58Pnjw4PxZVAVecsklOcCanubNm+cqvQiu4rgFUYX4008/pauvvjpXRIYIv7bZZpscWC666KKVbhdOOOGEClWZMcYIQWckVIwwLyofd9111/w+jv3YY4/lSs+LL764fL0BAwakHXbYofx9LD/++OPLP4vg8IEHHihfHuOO6/Xwww/n4DREaBiViBFgFoeKUSm5+eabl7+P63/00UenlVdeOb8vDjend60jxIx9R8gaY4xziWrHqkTwecopp1Rr/wAAAAAAAJXR/nQOtPPOO6cff/wxB1xR4RfVdYV5/KLqL9p6RmvRCKgKr8cffzy999575fuYZ555cpvNPyKqECOULASKYaONNsotQ996662S20Yr0lg3wsYYX4SMpVqwViWq8v7zn//kfRWL9zG+Yp07dy7/++TJk9Onn36aW8MWNGnSpMI67777bq7ojLCw+FpGiFp8Lafed4i2qlG1GcHvGWecMc36pUSAGSHraaedlo466qi08cYbl1w/gtE4n8Lr448/rvaxAAAAAAAAgkrFemquueaaZn6/wpyDSy65ZA7tooLuoYceSn/5y1/S0KFDc3AY8xlGu83x48fnP4tFIFYQFYQxF2BteOaZZ9Iee+yRq+uifWrLli1zlWK0H52VisPP6ijMDXnPPffk+SmLxdyJpfYd80nuvvvueduYb/Gkk07K57j99ttP97gRyj711FP5/kWwOT0xlqnHAwAAAAAAUBMqFeupmLMvKumKK/I++OCDCqFgtBmNOfhGjx6dg7qoUox5/KJSMeY3bN++fYXX1C1IayIqG2O/xWIewpjLMeZWLIgwLALRlVZaqcrtnn766bT00kvn+QKjwi9ag3744YczNK5oCxptXuO4xeL9qquuWuV2EWQuvvji6bnnniv/LKo9I4wtiO0jrIsKyqmvZQS70xPVokcccUR68MEHc4vVwryS0xMB8ZtvvplD4kLbWgAAAAAAgFlJpWI91b179zRy5MgcHLZq1SqdeOKJ5ZWH8XkEddG6c7755stz8EXIGEFdmzZtchVgnz59cuVfhIz//e9/0yOPPJLbnW611VYzNJ6Y9zDmG4wKyThGhHJxnKjA23vvvXNlXhznsMMOS3vttVeeT7Gq7SJEjKAuKvfWWWedXM0XLVxnVMxdGONYfvnlU6dOnXIIN2HChDRq1KiS2x1++OG5NWmMJ+Y+PPfcc9OkSZPKl8echtGGNILBqB6MNqTRXjQCywgz47wrE61pY0w77bRTWnbZZdMnn3ySxo4dm3bcccfpnsuLL76Y7/Utt9ySW7jGmGKcMcditLsFAAAAAACYFYSK9VTMkxeViVtvvXUO4mJ+vUKlYoSMEYbFvH0RLq6++urpX//6Vw7tQoRqp59+ep6P79///ndaaKGF0vrrr5/3NaNi7saoiIzKwmgL+thjj6Vu3brlwDBCrwgHI+CM4CyCsFLbbbvttjmo69evX/r5559z0Dlo0KAcTM6I/v3757AvzjcqNKPC8K677sphYSmxflSDRjgY1ZX77bdfbk8a+yqI6x5Vo0OGDEnvv/9+vvZrrbVW+utf/1rlfiP8/eqrr3Kw+/nnn+frH5WK0e61lJ9++intueeeaZ999slhcujbt28OXSOofeKJJ6ZpaQsAAAAAADAzNCqbemI+YI4WrXIjiO542PDUuGmz2h4OAECDNX5on9oeAgAAAKRCbhBFVdGJsSrmVAQAAAAAAABKEipSLc2bN6/yNWbMGGObSXr27FnluQwePLi2hwcAAAAAADRQ5lSkWiZMmFDlsnbt2qXaVJfHVlOXX355+vHHHytd1rp169k+HgAAAAAAgCBUpFrat2+f6qq6PLaaqm8hKAAAAAAA0DBofwoAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICSmtT2AIDa8cTpu6UWLVrU9jAAAAAAAIB6QKUiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICShIoAAAAAAABASU1KLwbmVF1OuD41btqstocBAFCvjR/ap7aHAAAAALOFSkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICShIoAAAAAAABASUJFAAAAAAAAoCShIgAAAAAAAFCSUJG0zDLLpGHDhqWGpFGjRumOO+6YrcecOHFiPu6ECRNm63EBAAAAAAD+KKEiM90+++yTevXqNcvDNiEdAAAAAADA7CFUnENMmTKltofAbLgX7jMAAAAAAFAbhIp1VLdu3VK/fv3yq2XLlmmhhRZKgwYNSmVlZeUtS0877bTUp0+f1KJFi9S3b9/8+a233po6dOiQmjZtmtc555xzKuz3iy++SNtss01q1qxZWnbZZdOoUaOmW/03adKk/Nno0aPLP3vttdfS1ltvnY+9wAILpD/96U/pvffeSyeffHK66qqr0p133pm3mXq7ysQ4wpprrpnXj3MPv//+ezr11FPTEksskc+nU6dO6f7775/udmPHjk2bb755vmZx7bp27ZpeeOGFGbwTKb3yyiupe/fu+Zq1adMmX+vvvvtumsrMv//976lt27ZppZVWyp8///zzeWzzzjtv6ty5c3rxxRen2ferr76aevbsmZo3b54WXXTRtNdee6Uvv/xymudgwIAB+Xy23HLL/AzEdV5qqaXydYlj9u/fv8rx//zzz+nbb7+t8AIAAAAAAKgJoWIdFuFckyZNcjh1/vnnp3PPPTddfvnl5cvPPvvs1LFjxxxWReA4fvz41Lt377TrrrvmICyCp/h85MiRFQKwjz/+OD322GPplltuSZdcckkOGmvi3//+d+rSpUsOtB599NF83P322y/9+uuvaeDAgXkMPXr0SJ9++ml+bbjhhiX3F+cXHn744bz+bbfdlt/HOUcoGuf58ssv50Bt2223Te+8807J7f73v/+lvffeOz355JPp2WefTSussEL685//nD+vqe+//z4fd8EFF8xh5c0335yPF0FfsUceeSS99dZb6aGHHkp33313Dh0jdF111VXz9Yl7EdemWIS1EVZG8Dhu3LgcmH7++ef5+k39HMwzzzzpqaeeSsOHD8/B8XnnnZcuu+yyfC1ibsjVV1+9ynMYMmRIDlcLryWXXLLG1wEAAAAAAGjYmtT2AKhahD8RHkUVXlS/RVAY7w888MC8PAKpo446qnz9PfbYI2266aY5SAwrrrhiev3119PQoUNzmPj222+n++67L4dx66yzTl7niiuuSKusskqNxnXxxRfncOqGG25Ic889d/mxCqKiL6rjFltssWrtb+GFF85/RhVg8TYRJh577LE5JA1nnnlmDkOHDRuWx1DVdnFdiv3jH/9IrVq1So8//ngO+mriuuuuSz/99FO6+uqr0/zzz58/u+iii3K1Z4wnqgtDLIvAN8K/wjGj0jKub1QqRvXoJ598kg455JDyfcd+IlAcPHhw+WdXXnllvu9xrwrXNELRs846q3yde+65J5/vZpttlq9/VCyuu+66VZ7D8ccfn4488sjy91GpKFgEAAAAAABqQqViHbb++uvnQLFggw02yJVpv/32W34fLTWLvfHGG2mjjTaq8Fm8L2wTy6Pyce211y5fvvLKK+fArSaiNWq0Oy0EirNCBF//+c9/Kj2fOI9SotovgtcI4yL8jBatUTn40Ucf1XgccayoBi0EioUxRGAYlYkFUSlYCBQL262xxho5UCy+f8VeeumlHJJG69PCK+5HiFayBcX3K+y8887pxx9/TMstt1w+z9tvvz1XiVYlKkrjGhS/AAAAAAAAakKlYj1WHHTNLHPN9X85c2HuxvDLL79UWCcqEeuyaH361Vdf5fapSy+9dA7VItCbMmVKnboXEXQWKh6ntvjii1e576gyjEAz2rBGu9W//OUvuRo1KjFnZdALAAAAAAA0XCoV67DnnnuuwvvC/ICNGzeudP1oYxrz7hWL99FGM7aJKrioaIs5/goinIq5/QoKLUVjjsLiysRiUYE3ZsyYacLGgqjYK1RTVkehwq94m6ima9u2baXnE/MUVrVdYZ3+/fvneRSj7WiEil9++WWaEXFNo6Iw5lYs3n+Er9GSttR2MQ9ktE4tvn/F1lprrfTaa6+lZZZZJrVv377Ca3ohZQS7EUhecMEFafTo0emZZ57J7XEBAAAAAABmBaFiHRbtOmMuvAj+rr/++nThhRemww8/vMr1Y37FRx55JJ122ml5Tr6rrroqz9s3cODAvDxCsB49eqSDDjooB5YRLh5wwAEVKg/j79F29YwzzsgtPKP67YQTTqhwnH79+uX2pDHX4bhx43J71Wuuuaa8HWiEZBGoxfsI86oKHwsWWWSRfNz7778/ty6dPHly/vzoo4/OVXw33nhj3tdxxx2XA87CNahquwheYzwx/jjPmGtyRqsrY9toYRrVj6+++mpuV3rYYYelvfbaq3w+xcrsvvvuuXVttCeNeS3vvffePEdksUMPPTR9/fXXabfddktjx47NLU8feOCBtO+++5YMZUeOHJnnaozxvP/+++naa6/N5xdVmQAAAAAAALOCULEO69OnT547b911180BVIRpffv2rXL9qHy76aab0g033JBWW221dOKJJ6ZTTz017bPPPuXrjBgxIlcAdu3aNe2www55fxHOFbvyyitzRWPM5TdgwIB0+umnV1jepk2b9Oijj+b2nbGfWO+f//xneevNCNIiwIw5H6Pycepqw6nFPI9RcXfZZZflsW233Xb586g2jFA1wtKYszDCw7vuuiuHhqW2i8Dtm2++ydcjwr/Yz9TnWF3zzTdfDvoi/FtnnXXSTjvtlDbddNMc1pYS8yP+61//ytWDa665Zvrb3/42TZvTQiVmBIhbbLFFPse43jHHZaENbWVieVzvmNsxqkajDWocK+4LAAAAAADArNCorHjyPOqMbt26pU6dOqVhw4bV9lCYw0SVacuWLVPHw4anxk3r9vyYAAB13fihfWp7CAAAADBTcoPoCBnT01VFpSIAAAAAAABQklCRWW7w4MG5HWhlr549exobAAAAAABAHaf9KbNczEcYr8o0a9YstWvXLtWWujy2WUX7UwCAmUf7UwAAABpK+9Mms3VUNEitW7fOr7qoLo8NAAAAAACgrtD+FAAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACU1Kb0YmFM9cfpuqUWLFrU9DAAAAAAAoB5QqQgAAAAAAACUJFQEAAAAAAAAStL+FBqYsrKy/Oe3335b20MBAAAAAABqWSEvKOQHVREqQgPz1Vdf5T+XXHLJ2h4KAAAAAABQR/zvf/9LLVu2rHK5UBEamNatW+c/P/roo5JfDlBX/8VMBOIff/xxatGiRW0PB2rE80t95vmlPvP8Ul95dqnPPL/UZ55f6jPPLzMqKhQjUGzbtm3J9YSK0MDMNdf/TaUagaL/x0J9Fc+u55f6yvNLfeb5pT7z/FJfeXapzzy/1GeeX+ozzy8zojpFSP+XLgAAAAAAAABUQagIAAAAAAAAlCRUhAamadOm6aSTTsp/Qn3j+aU+8/xSn3l+qc88v9RXnl3qM88v9Znnl/rM88us1qgsZl8EAAAAAAAAqIJKRQAAAAAAAKAkoSIAAAAAAABQklARAAAAAAAAKEmoCAAAAAAAAJQkVIQG5OKLL07LLLNMmnfeedN6662Xnn/++doeEqQhQ4akddZZJy2wwAJpkUUWSb169UpvvfVWhXW6deuWGjVqVOF18MEHV1jno48+SltttVWab7758n6OPvro9Ouvv87ms6GhOfnkk6d5NldeeeXy5T/99FM69NBDU5s2bVLz5s3TjjvumD7//PMK+/DsUlviZ4Kpn994xTMbfPdSlzzxxBNpm222SW3bts3P4h133FFheVlZWTrxxBPT4osvnpo1a5Y222yz9M4771RY5+uvv0577LFHatGiRWrVqlXaf//903fffVdhnZdffjn96U9/yj8vL7nkkumss86aLedHw3x2f/nll3Tsscem1VdfPc0///x5nT59+qT//Oc/0/2+PuOMMyqs49mlNr5799lnn2mezR49elRYx3cvdfX5rezn4HgNHTq0fB3fv9Tl35XNrN83jB49Oq211lqpadOmqX379mnkyJGz5Rypv4SK0EDceOON6cgjj0wnnXRSeuGFF1LHjh3Tlltumb744ovaHhoN3OOPP55/CHr22WfTQw89lH+5ssUWW6Tvv/++wnoHHnhg+vTTT8tfxT+o//bbb/mHpClTpqSnn346XXXVVfmHoPjlIsxqHTp0qPBsPvnkk+XLjjjiiPSvf/0r3XzzzflZj18S7rDDDuXLPbvUprFjx1Z4duM7OOy8887l6/jupa6Inwvi59f4R3KViWfzggsuSMOHD0/PPfdcDmjiZ934ZUtB/FL7tddey8/63XffnX/Z2Ldv3/Ll3377bf4ZZOmll07jx4/Pv1SMfzzyj3/8Y7acIw3v2f3hhx/yf5sNGjQo/3nbbbflXxhuu+2206x76qmnVvg+Puyww8qXeXapre/eECFi8bN5/fXXV1juu5e6+vwWP7fxuvLKK3NoGMFMMd+/1NXflc2M3zd88MEHeZ1NNtkkTZgwIQ0YMCAdcMAB6YEHHpjt50w9UgY0COuuu27ZoYceWv7+t99+K2vbtm3ZkCFDanVcMLUvvviiLP7f0+OPP17+WdeuXcsOP/zwKre59957y+aaa66yzz77rPyzSy+9tKxFixZlP//88ywfMw3XSSedVNaxY8dKl02aNKls7rnnLrv55pvLP3vjjTfy8/3MM8/k955d6pL4nl1++eXLfv/99/zedy91VXyP3n777eXv45ldbLHFyoYOHVrhO7hp06Zl119/fX7/+uuv5+3Gjh1bvs59991X1qhRo7J///vf+f0ll1xStuCCC1Z4fo899tiylVZaaTadGQ3t2a3M888/n9f78MMPyz9beumly84777wqt/HsUlvP795771223XbbVbmN717q0/dvPMvdu3ev8JnvX+rq78pm1u8bjjnmmLIOHTpUONYuu+xStuWWW86mM6M+UqkIDUD8i5T4F1PRBqpgrrnmyu+feeaZWh0bTG3y5Mn5z9atW1f4fNSoUWmhhRZKq622Wjr++OPzv+wuiOc42kYtuuii5Z9FdUL8q8H4V7EwK0V7vWips9xyy+V/iR3tRUJ878a/Jiz+7o3WqEsttVT5d69nl7r0s8K1116b9ttvv/wvtAt891IfxL+w/uyzzyp837Zs2TK3+y/+vo22e507dy5fJ9aPn4mjsrGwTpcuXdI888xT4ZmOyrFvvvlmtp4TDftn4fgejue1WLTbi/Zma665Zq6EKW5d5tmlNkXbvGipt9JKK6VDDjkkffXVV+XLfPdSX0TLyHvuuSe3552a71/q4u/KZtbvG2Kd4n0U1vH7YkppUnIpMEf48ssvc8l78f8TCfH+zTffrLVxwdR+//333Gpho402yr/ALth9991zO5EIbmK+gph7Jn5IjxZRIX6RWNnzXVgGs0r8wjrah8QvUaIVzimnnJLn03j11Vfzsxf/cTn1LwXj2Sw8l55d6oqYY2bSpEl5bqQC373UF4XnrbLnsfj7Nn7pXaxJkyb5FzPF6yy77LLT7KOwbMEFF5yl5wHRrje+a3fbbbc8/1xB//7981xH8bxG+7L4Rx7xc8e5556bl3t2qS3R+jRa7cXz995776W//vWvqWfPnvmX0Y0bN/bdS70RbSFj7rri1pHB9y919XdlM+v3DVWtE8Hjjz/+mOcqh6kJFQGoM6JffIQxxXPSheI5N+JfWS2++OJp0003zf/huvzyy9fCSOH/xC9NCtZYY40cMkYIc9NNN/nhm3rliiuuyM9zBIgFvnsBZp+oNujdu3dMUZMuvfTSCsuOPPLICj9vxC8RDzrooDRkyJDUtGnTWhgt/J9dd921ws8K8XzGzwhRvRg/M0B9EfMpRteZeeedt8Lnvn+py78rg9qi/Sk0ANG2LP6VYLRzKBbvF1tssVobFxTr169fuvvuu9Njjz2WllhiiZLrRnAT3n333fxnPMeVPd+FZTC7xL8SXHHFFfOzGc9etJSM6q+qvns9u9QFH374YXr44YfTAQccUHI9373UVYXnrdTPuvHnF198UWF5tC/7+uuvfSdTZwLF+D5+6KGHKlQpVvV9HM/vxIkT83vPLnVFTAcQv38o/lnBdy913ZgxY3I3jun9LBx8/1JXflc2s37fUNU68bOIfyhNVYSK0ADEv6Rae+210yOPPFKhdD7eb7DBBrU6Noh/jR0/JN1+++3p0UcfnaZ1SGUmTJiQ/4yqmRDP8SuvvFLhP1gLv5BZddVVZ+HooaLvvvsuV3HFsxnfu3PPPXeF7974j9WYc7Hw3evZpS4YMWJEbk221VZblVzPdy91VfzsEL8QKf6+jZZNMV9X8fdt/NIl5p8piJ874mfiQmAe6zzxxBM54Cl+pqPFtfZlzOpAMeZojn/gEfN2TU98H8ecdIW2kp5d6opPPvkkz6lY/LOC717qQ8eO+G+3jh07Tndd37/Uld+VzazfN8Q6xfsorOP3xZRUBjQIN9xwQ1nTpk3LRo4cWfb666+X9e3bt6xVq1Zln332WW0PjQbukEMOKWvZsmXZ6NGjyz799NPy1w8//JCXv/vuu2Wnnnpq2bhx48o++OCDsjvvvLNsueWWK+vSpUv5Pn799dey1VZbrWyLLbYomzBhQtn9999ftvDCC5cdf/zxtXhmNARHHXVUfnbj2XzqqafKNttss7KFFlqo7IsvvsjLDz744LKlllqq7NFHH83P8AYbbJBfBZ5dattvv/2Wn9Fjjz22wue+e6lr/ve//5W9+OKL+RX/GXvuuefmv3/44Yd5+RlnnJF/to1n9eWXXy7bbrvtypZddtmyH3/8sXwfPXr0KFtzzTXLnnvuubInn3yybIUVVijbbbfdypdPmjSpbNFFFy3ba6+9yl599dX88/N8881Xdtlll9XKOTPnP7tTpkwp23bbbcuWWGKJ/D1a/LPwzz//nLd/+umny84777y8/L333iu79tpr83dtnz59yo/h2aU2nt9YNnDgwLJnnnkm/6zw8MMPl6211lr5u/Wnn34q34fvXurqzw5h8uTJ+Xm79NJLp9ne9y91+XdlM+v3De+//35+Zo8++uiyN954o+ziiy8ua9y4cV4XqiJUhAbkwgsvzP/PZp555ilbd911y5599tnaHhLkH+4re40YMSIv/+ijj/IvsVu3bp2D8fbt2+cfduKH/2ITJ04s69mzZ1mzZs1yqBNhzy+//FJLZ0VDscsuu5Qtvvji+Xu1Xbt2+X2EMQXxy+y//OUvZQsuuGD+QX377bfP/yFQzLNLbXrggQfyd+5bb71V4XPfvdQ1jz32WKU/L+y99955+e+//142aNCg/Iu9eGY33XTTaZ7rr776Kv8iu3nz5mUtWrQo23ffffMvHIu99NJLZRtvvHHeR3yvR1gJs+rZjSCmqp+FY7swfvz4svXWWy//YnHeeectW2WVVcoGDx5cIbQJnl1m9/Mbv9iOX1THL6jnnnvusqWXXrrswAMPnOYfLvvupa7+7BAi/IufYyMcnJrvX+ry78pm5u8b4n8rnTp1yr/XiH9IWnwMqEyj+D+laxkBAAAAAACAhsycigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAChJqAgAAAAAAACUJFQEAAAAAAAAShIqAgAAAAAAACUJFQEAAAAAAICShIoAAADQwHTr1i0NGDCgtocBAADUI0JFAAAAqEe22Wab1KNHj0qXjRkzJjVq1Ci9/PLLs31cAADAnE2oCAAAAPXI/vvvnx566KH0ySefTLNsxIgRqXPnzmmNNdaolbEBAABzLqEiAAAA1CNbb711WnjhhdPIkSMrfP7dd9+lm2++OfXq1SvttttuqV27dmm++eZLq6++err++utL7jOqG++4444Kn7Vq1arCMT7++OPUu3fv/Hnr1q3TdtttlyZOnDiTzw4AAKirhIoAAABQjzRp0iT16dMnB35lZWXln0eg+Ntvv6U999wzrb322umee+5Jr776aurbt2/aa6+90vPPPz/Dx/zll1/SlltumRZYYIHcYvWpp55KzZs3z21Yp0yZMpPODAAAqMuEigAAAFDP7Lfffum9995Ljz/+eIXWpzvuuGNaeuml08CBA1OnTp3Scsstlw477LAc/t10000zfLwbb7wx/f777+nyyy/PlY+rrLJKPt5HH32URo8ePZPOCgAAqMuEigAAAFDPrLzyymnDDTdMV155ZX7/7rvv5grCmG8xqhVPO+20HP5Fm9KoKHzggQdyADijXnrppXyMqFSM/cUr9v3TTz/lcBMAAJjzNantAQAAAAA1FwFiVCFefPHFuWpw+eWXT127dk1nnnlmOv/889OwYcNysDj//POnAQMGlGxTGnMqFrdSLbQ8LZ6vMVqqjho1apptY35HAABgzidUBAAAgHqod+/e6fDDD0/XXXdduvrqq9MhhxySw8GY73C77bbLcyuGaFv69ttvp1VXXbXKfUUw+Omnn5a/f+edd9IPP/xQ/n6ttdbKLVAXWWSR1KJFi1l8ZgAAQF2k/SkAAADUQ9GCdJdddknHH398DgT32Wef/PkKK6yQHnroofT000+nN954Ix100EHp888/L7mv7t27p4suuii9+OKLady4cenggw9Oc889d/nyPfbYIy200EI5rIw2qx988EGeS7F///7pk08+meXnCgAA1D6hIgAAANTjFqjffPNN2nLLLVPbtm3zZyeccEKuLIzPunXrlhZbbLHUq1evkvs555xz0pJLLpn+9Kc/pd133z0NHDgwzTfffOXL4+9PPPFEWmqppdIOO+yQVllllXzsmFNR5SIAADQMjcqmnjQBAAAAAAAAoIhKRQAAAAAAAKAkoSIAAAAAAABQklARAAAAAAAAKEmoCAAAAAAAAJQkVAQAAAAAAABKEioCAAAAAAAAJQkVAQAAAAAAgJKEigAAAAAAAEBJQkUAAAAAAACgJKEiAAAAAAAAUJJQEQAAAAAAAEil/H+Ijc04IiM8AQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot feature importance for LightGBM (often easier to read)\n",
    "feature_imp = pd.DataFrame(sorted(zip(lgb_clf.feature_importances_, X.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).head(20))\n",
    "plt.title('LightGBM Feature Importance (Top 20)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "978623bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembling the test dataset...\n",
      "Merging User and Product features onto test candidates...\n",
      "Test dataset is ready.\n",
      "Shape of the test feature set: (4833292, 24)\n"
     ]
    }
   ],
   "source": [
    "# --- Assemble the Test Data (CORRECTED) ---\n",
    "print(\"Assembling the test dataset...\")\n",
    "\n",
    "# 1. Identify the test orders and their corresponding users\n",
    "test_orders = orders[orders['eval_set'] == 'test']\n",
    "\n",
    "# 2. Start with the User-Product features for the test users. This is our base.\n",
    "# This DataFrame already contains all the 'up_' features.\n",
    "test_data = up_features[up_features['user_id'].isin(test_orders['user_id'])]\n",
    "\n",
    "# 3. Merge the other two feature sets (User and Product) onto this base.\n",
    "print(\"Merging User and Product features onto test candidates...\")\n",
    "test_data = test_data.merge(user_features, on='user_id', how='left')\n",
    "test_data = test_data.merge(product_features, on='product_id', how='left')\n",
    "\n",
    "# 4. Add the order_id for submission purposes.\n",
    "test_data = test_data.merge(test_orders[['user_id', 'order_id']], on='user_id', how='left')\n",
    "\n",
    "# 5. Ensure the feature columns in 'test_data' are in the same order as in 'X_train'.\n",
    "# This line should now work correctly because the column names were not altered.\n",
    "X_test = test_data[X_train.columns]\n",
    "\n",
    "print(\"Test dataset is ready.\")\n",
    "print(\"Shape of the test feature set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13dba2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions with LightGBM model...\n",
      "Predictions are complete.\n",
      "Example predictions:\n",
      "   user_id  order_id  product_id  reorder_prediction\n",
      "0        3   2774568         248            0.022709\n",
      "1        3   2774568        1005            0.055319\n",
      "2        3   2774568        1819            0.122122\n",
      "3        3   2774568        7503            0.028651\n",
      "4        3   2774568        8021            0.043543\n"
     ]
    }
   ],
   "source": [
    "# --- Make Predictions on the Test Set ---\n",
    "print(\"\\nMaking predictions with LightGBM model...\")\n",
    "\n",
    "# Use predict_proba to get the probability of the positive class (reordered=1)\n",
    "test_predictions_proba = lgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Add the predictions back to our test_data DataFrame to keep everything organized\n",
    "test_data['reorder_prediction'] = test_predictions_proba\n",
    "\n",
    "print(\"Predictions are complete.\")\n",
    "print(\"Example predictions:\")\n",
    "print(test_data[['user_id', 'order_id', 'product_id', 'reorder_prediction']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e5743f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding the best F1 threshold on the validation set...\n",
      "Best threshold: 0.2200\n",
      "Best F1 Score on validation set: 0.4429\n",
      "\n",
      "Generating submission file...\n",
      "Submission file 'submission.csv' created successfully.\n",
      "Submission head:\n",
      "   order_id                                           products\n",
      "0   2774568          17668 18599 21903 23650 39190 43961 47766\n",
      "1    329954                                               None\n",
      "2   1528013                                        21903 38293\n",
      "3   1376945  8309 13176 14947 24799 27959 28465 33572 34658...\n",
      "4   1356845           7076 10863 11520 13176 14992 22959 28134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_14024\\4186688377.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  submission['products'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Find the Optimal F1 Threshold ---\n",
    "print(\"\\nFinding the best F1 threshold on the validation set...\")\n",
    "\n",
    "# Predict probabilities on the validation set (X_val) that we created earlier\n",
    "y_val_pred_proba = lgb_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Test a range of potential thresholds\n",
    "thresholds = np.linspace(0, 0.5, 51)\n",
    "f1_scores = [f1_score(y_val, y_val_pred_proba > t) for t in thresholds]\n",
    "\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best F1 Score on validation set: {np.max(f1_scores):.4f}\")\n",
    "\n",
    "\n",
    "# --- Generate the Final Submission File ---\n",
    "print(\"\\nGenerating submission file...\")\n",
    "\n",
    "# Apply the best threshold to our test predictions\n",
    "test_data['reorder_prediction_binary'] = (test_data['reorder_prediction'] > best_threshold).astype(int)\n",
    "\n",
    "# Filter for only the products predicted to be reordered\n",
    "final_predictions = test_data[test_data['reorder_prediction_binary'] == 1]\n",
    "\n",
    "# The submission format requires a space-separated list of product_ids for each order_id.\n",
    "# We'll handle cases where an order has no reordered products predicted, submitting 'None'.\n",
    "submission = final_predictions.groupby('order_id')['product_id'].apply(\n",
    "    lambda x: ' '.join(map(str, x))\n",
    ").reset_index()\n",
    "submission.rename(columns={'product_id': 'products'}, inplace=True)\n",
    "\n",
    "# Ensure all test orders are in the submission file\n",
    "all_test_orders = test_orders[['order_id']]\n",
    "submission = all_test_orders.merge(submission, on='order_id', how='left')\n",
    "\n",
    "# Fill any orders with no predicted reorders with the string 'None'\n",
    "submission['products'].fillna('None', inplace=True)\n",
    "\n",
    "# Save the submission file\n",
    "submission_filename = 'submission.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"Submission file '{submission_filename}' created successfully.\")\n",
    "print(\"Submission head:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdd8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df05a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Prediction Pipeline for XGBoost ---\n",
      "\n",
      "Finding the best F1 threshold for XGBoost on the validation set...\n",
      "Best threshold for XGBoost: 0.2200\n",
      "Best F1 Score on validation set for XGBoost: 0.4444\n",
      "\n",
      "Making predictions on the test set with XGBoost model...\n",
      "\n",
      "Generating XGBoost submission file...\n",
      "Submission file 'submission_xgb.csv' created successfully.\n",
      "XGBoost Submission head:\n",
      "   order_id                                  products\n",
      "0   2774568       17668 18599 21903 39190 43961 47766\n",
      "1    329954                                      None\n",
      "2   1528013                               21903 38293\n",
      "3   1376945        8309 13176 14947 27959 33572 44632\n",
      "4   1356845  7076 10863 11520 13176 14992 21616 28134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# --- XGBoost: Find Optimal Threshold and Create Submission ---\n",
    "\n",
    "print(\"--- Running Prediction Pipeline for XGBoost ---\")\n",
    "\n",
    "# --- Step 1: Find the Optimal F1 Threshold (using XGBoost) ---\n",
    "print(\"\\nFinding the best F1 threshold for XGBoost on the validation set...\")\n",
    "\n",
    "# Predict probabilities on the validation set (X_val) using the trained XGBoost model\n",
    "y_val_pred_proba_xgb = xgb_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Test a range of potential thresholds (can use the same range as before)\n",
    "thresholds = np.linspace(0, 0.5, 51)\n",
    "f1_scores_xgb = [f1_score(y_val, y_val_pred_proba_xgb > t) for t in thresholds]\n",
    "\n",
    "best_threshold_xgb = thresholds[np.argmax(f1_scores_xgb)]\n",
    "print(f\"Best threshold for XGBoost: {best_threshold_xgb:.4f}\")\n",
    "print(f\"Best F1 Score on validation set for XGBoost: {np.max(f1_scores_xgb):.4f}\")\n",
    "\n",
    "\n",
    "# --- Step 2: Make Predictions on the Test Set ---\n",
    "print(\"\\nMaking predictions on the test set with XGBoost model...\")\n",
    "\n",
    "# Use the trained xgb_clf model to predict probabilities on the test set (X_test)\n",
    "test_predictions_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Add these new predictions to our main test_data DataFrame\n",
    "test_data['reorder_prediction_xgb'] = test_predictions_proba_xgb\n",
    "\n",
    "\n",
    "# --- Step 3: Generate the Final Submission File for XGBoost ---\n",
    "print(\"\\nGenerating XGBoost submission file...\")\n",
    "\n",
    "# Apply the XGBoost-specific best threshold to the XGBoost predictions\n",
    "test_data['reorder_prediction_binary_xgb'] = (test_data['reorder_prediction_xgb'] > best_threshold_xgb).astype(int)\n",
    "\n",
    "# Filter for only the products predicted to be reordered by XGBoost\n",
    "final_predictions_xgb = test_data[test_data['reorder_prediction_binary_xgb'] == 1]\n",
    "\n",
    "# Group the predictions by order_id\n",
    "submission_xgb = final_predictions_xgb.groupby('order_id')['product_id'].apply(\n",
    "    lambda x: ' '.join(map(str, x))\n",
    ").reset_index()\n",
    "submission_xgb.rename(columns={'product_id': 'products'}, inplace=True)\n",
    "\n",
    "# Ensure all test orders are in the submission file\n",
    "all_test_orders = test_orders[['order_id']]\n",
    "submission_xgb = all_test_orders.merge(submission_xgb, on='order_id', how='left')\n",
    "\n",
    "# Fill any orders with no predicted reorders with the string 'None'\n",
    "# Using the safer, modern pandas syntax to avoid the warning\n",
    "submission_xgb['products'] = submission_xgb['products'].fillna('None')\n",
    "\n",
    "# Save the submission file with a new name\n",
    "submission_filename_xgb = 'submission_xgb.csv'\n",
    "submission_xgb.to_csv(submission_filename_xgb, index=False)\n",
    "\n",
    "print(f\"Submission file '{submission_filename_xgb}' created successfully.\")\n",
    "print(\"XGBoost Submission head:\")\n",
    "print(submission_xgb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23804547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating an Ensemble of LightGBM and XGBoost ---\n",
      "\n",
      "Finding the best F1 threshold for the ENSEMBLE on the validation set...\n",
      "Best threshold for Ensemble: 0.2200\n",
      "Best F1 Score on validation set for Ensemble: 0.4440\n",
      "\n",
      "Generating Ensemble submission file...\n",
      "Submission file 'submission_ensemble.csv' created successfully.\n",
      "Ensemble Submission head:\n",
      "   order_id                                           products\n",
      "0   2774568                17668 18599 21903 39190 43961 47766\n",
      "1    329954                                               None\n",
      "2   1528013                                        21903 38293\n",
      "3   1376945  8309 13176 14947 24799 27959 28465 33572 34658...\n",
      "4   1356845     7076 10863 11520 13176 14992 21616 22959 28134\n"
     ]
    }
   ],
   "source": [
    "# --- Create an Ensemble Prediction ---\n",
    "print(\"--- Creating an Ensemble of LightGBM and XGBoost ---\")\n",
    "\n",
    "# 1. Create the blended probability prediction\n",
    "# We already have the predictions stored in our test_data DataFrame\n",
    "# Let's give equal weight to both models\n",
    "test_data['ensemble_prediction'] = 0.5 * test_data['reorder_prediction'] + 0.5 * test_data['reorder_prediction_xgb']\n",
    "\n",
    "# 2. Find the optimal F1 threshold for the ENSEMBLE predictions\n",
    "print(\"\\nFinding the best F1 threshold for the ENSEMBLE on the validation set...\")\n",
    "\n",
    "# First, create the blended probabilities for the validation set\n",
    "y_val_pred_proba_lgb = lgb_clf.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_proba_xgb = xgb_clf.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_proba_ensemble = 0.5 * y_val_pred_proba_lgb + 0.5 * y_val_pred_proba_xgb\n",
    "\n",
    "# Now find the best threshold for these new blended probabilities\n",
    "thresholds = np.linspace(0, 0.5, 51)\n",
    "f1_scores_ensemble = [f1_score(y_val, y_val_pred_proba_ensemble > t) for t in thresholds]\n",
    "best_threshold_ensemble = thresholds[np.argmax(f1_scores_ensemble)]\n",
    "\n",
    "print(f\"Best threshold for Ensemble: {best_threshold_ensemble:.4f}\")\n",
    "print(f\"Best F1 Score on validation set for Ensemble: {np.max(f1_scores_ensemble):.4f}\")\n",
    "\n",
    "\n",
    "# 3. Generate the final submission file for the Ensemble\n",
    "print(\"\\nGenerating Ensemble submission file...\")\n",
    "\n",
    "# Apply the new ensemble-specific threshold\n",
    "test_data['reorder_prediction_binary_ensemble'] = (test_data['ensemble_prediction'] > best_threshold_ensemble).astype(int)\n",
    "\n",
    "# Filter and group to create the submission file\n",
    "final_predictions_ensemble = test_data[test_data['reorder_prediction_binary_ensemble'] == 1]\n",
    "submission_ensemble = final_predictions_ensemble.groupby('order_id')['product_id'].apply(\n",
    "    lambda x: ' '.join(map(str, x))\n",
    ").reset_index()\n",
    "submission_ensemble.rename(columns={'product_id': 'products'}, inplace=True)\n",
    "\n",
    "# Merge to ensure all test orders are included\n",
    "all_test_orders = test_orders[['order_id']]\n",
    "submission_ensemble = all_test_orders.merge(submission_ensemble, on='order_id', how='left')\n",
    "submission_ensemble['products'] = submission_ensemble['products'].fillna('None')\n",
    "\n",
    "# Save the final submission file\n",
    "submission_filename_ensemble = 'submission_ensemble.csv'\n",
    "submission_ensemble.to_csv(submission_filename_ensemble, index=False)\n",
    "\n",
    "print(f\"Submission file '{submission_filename_ensemble}' created successfully.\")\n",
    "print(\"Ensemble Submission head:\")\n",
    "print(submission_ensemble.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9fca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ccb749ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:24:06,311] A new study created in memory with name: no-name-10e5736f-c1bb-4fee-937f-876583212b96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.44461:   2%|▏         | 1/50 [06:45<5:31:33, 405.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:30:52,291] Trial 0 finished with value: 0.4446103528624073 and parameters: {'learning_rate': 0.12580278832913414, 'max_depth': 7, 'subsample': 0.5624595696041073, 'colsample_bytree': 0.7767236009421671, 'min_child_weight': 7, 'gamma': 0.12315297805977238}. Best is trial 0 with value: 0.4446103528624073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:30:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.44461:   4%|▍         | 2/50 [11:11<4:18:54, 323.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:35:18,276] Trial 1 finished with value: 0.4414462831905497 and parameters: {'learning_rate': 0.21283131215372775, 'max_depth': 4, 'subsample': 0.544704395629168, 'colsample_bytree': 0.837259182096337, 'min_child_weight': 7, 'gamma': 0.2203646649043421}. Best is trial 0 with value: 0.4446103528624073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:35:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 2. Best value: 0.444995:   6%|▌         | 3/50 [17:48<4:39:41, 357.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:41:55,121] Trial 2 finished with value: 0.4449953764229457 and parameters: {'learning_rate': 0.18754329275092274, 'max_depth': 6, 'subsample': 0.7992929056881228, 'colsample_bytree': 0.7752135779154636, 'min_child_weight': 9, 'gamma': 0.10300202278829623}. Best is trial 2 with value: 0.4449953764229457.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:41:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 2. Best value: 0.444995:   8%|▊         | 4/50 [22:12<4:05:31, 320.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:46:18,925] Trial 3 finished with value: 0.44442559103237456 and parameters: {'learning_rate': 0.20417770657927486, 'max_depth': 8, 'subsample': 0.7148285776963952, 'colsample_bytree': 0.5119953686623246, 'min_child_weight': 6, 'gamma': 0.3116447053620986}. Best is trial 2 with value: 0.4449953764229457.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:46:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 2. Best value: 0.444995:  10%|█         | 5/50 [24:59<3:18:45, 265.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:49:06,006] Trial 4 finished with value: 0.44420137086436495 and parameters: {'learning_rate': 0.26606084791897183, 'max_depth': 9, 'subsample': 0.8330799066551616, 'colsample_bytree': 0.5478340590798899, 'min_child_weight': 9, 'gamma': 0.4247061931729047}. Best is trial 2 with value: 0.4449953764229457.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 2. Best value: 0.444995:  12%|█▏        | 6/50 [26:03<2:24:11, 196.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:50:09,866] Trial 5 finished with value: 0.438940226927126 and parameters: {'learning_rate': 0.28655761236480115, 'max_depth': 9, 'subsample': 0.518057546866693, 'colsample_bytree': 0.9041637972570218, 'min_child_weight': 10, 'gamma': 0.20443793303147018}. Best is trial 2 with value: 0.4449953764229457.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 6. Best value: 0.445195:  14%|█▍        | 7/50 [33:02<3:13:03, 269.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 22:57:09,071] Trial 6 finished with value: 0.4451946799235749 and parameters: {'learning_rate': 0.19070674089509412, 'max_depth': 8, 'subsample': 0.734345208406857, 'colsample_bytree': 0.8740420151571189, 'min_child_weight': 6, 'gamma': 0.05508576930741832}. Best is trial 6 with value: 0.4451946799235749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [22:57:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 6. Best value: 0.445195:  16%|█▌        | 8/50 [38:30<3:21:35, 287.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:02:36,864] Trial 7 finished with value: 0.43908034886276526 and parameters: {'learning_rate': 0.017168075433336302, 'max_depth': 5, 'subsample': 0.5827307259811962, 'colsample_bytree': 0.8053196132809739, 'min_child_weight': 7, 'gamma': 0.1708854898874777}. Best is trial 6 with value: 0.4451946799235749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:02:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 6. Best value: 0.445195:  18%|█▊        | 9/50 [42:40<3:08:37, 276.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:06:46,628] Trial 8 finished with value: 0.4400110167202796 and parameters: {'learning_rate': 0.07955373855615043, 'max_depth': 4, 'subsample': 0.7141054137560499, 'colsample_bytree': 0.573313586940617, 'min_child_weight': 9, 'gamma': 0.4357953093908653}. Best is trial 6 with value: 0.4451946799235749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:06:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 6. Best value: 0.445195:  20%|██        | 10/50 [46:21<2:52:39, 258.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:10:27,424] Trial 9 finished with value: 0.4429407023787674 and parameters: {'learning_rate': 0.24077355828589841, 'max_depth': 6, 'subsample': 0.6434338494504034, 'colsample_bytree': 0.5263602782244976, 'min_child_weight': 1, 'gamma': 0.15173932861184852}. Best is trial 6 with value: 0.4451946799235749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:10:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 10. Best value: 0.447403:  22%|██▏       | 11/50 [51:26<2:57:37, 273.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:15:33,114] Trial 10 finished with value: 0.44740334189685554 and parameters: {'learning_rate': 0.14901897357882016, 'max_depth': 7, 'subsample': 0.8918828059391453, 'colsample_bytree': 0.9886129252336541, 'min_child_weight': 3, 'gamma': 0.005914909865627094}. Best is trial 10 with value: 0.44740334189685554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:15:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 10. Best value: 0.447403:  24%|██▍       | 12/50 [56:19<2:56:51, 279.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:20:26,004] Trial 11 finished with value: 0.44679148578704897 and parameters: {'learning_rate': 0.13798366213220148, 'max_depth': 7, 'subsample': 0.9928234799312988, 'colsample_bytree': 0.997363920393525, 'min_child_weight': 3, 'gamma': 0.007030273325115383}. Best is trial 10 with value: 0.44740334189685554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:20:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 10. Best value: 0.447403:  26%|██▌       | 13/50 [1:00:59<2:52:15, 279.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:25:05,549] Trial 12 finished with value: 0.4470494460238595 and parameters: {'learning_rate': 0.1258607397670042, 'max_depth': 7, 'subsample': 0.9765950885374324, 'colsample_bytree': 0.9868967990304551, 'min_child_weight': 2, 'gamma': 0.00794523611337015}. Best is trial 10 with value: 0.44740334189685554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:25:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 10. Best value: 0.447403:  28%|██▊       | 14/50 [1:06:24<2:55:54, 293.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:30:30,694] Trial 13 finished with value: 0.44558032303322176 and parameters: {'learning_rate': 0.08002161814087153, 'max_depth': 7, 'subsample': 0.9804287565460751, 'colsample_bytree': 0.9901154111344764, 'min_child_weight': 3, 'gamma': 0.008923508274250033}. Best is trial 10 with value: 0.44740334189685554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:30:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 10. Best value: 0.447403:  30%|███       | 15/50 [1:10:01<2:37:40, 270.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:34:07,970] Trial 14 finished with value: 0.439288650379856 and parameters: {'learning_rate': 0.10112437424646228, 'max_depth': 3, 'subsample': 0.8877067847607142, 'colsample_bytree': 0.6446212180967297, 'min_child_weight': 3, 'gamma': 0.34277226990050247}. Best is trial 10 with value: 0.44740334189685554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:34:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 10. Best value: 0.447403:  32%|███▏      | 16/50 [1:15:28<2:42:53, 287.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:39:35,283] Trial 15 finished with value: 0.4421879332039498 and parameters: {'learning_rate': 0.041959565590623776, 'max_depth': 6, 'subsample': 0.9088534561673287, 'colsample_bytree': 0.9277799337395639, 'min_child_weight': 1, 'gamma': 0.07215109250611204}. Best is trial 10 with value: 0.44740334189685554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:39:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 16. Best value: 0.448225:  34%|███▍      | 17/50 [1:25:49<3:33:15, 387.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:49:56,209] Trial 16 finished with value: 0.4482248717070594 and parameters: {'learning_rate': 0.16240850670424822, 'max_depth': 8, 'subsample': 0.9269522827936151, 'colsample_bytree': 0.6565073090767827, 'min_child_weight': 4, 'gamma': 0.3025492957411847}. Best is trial 16 with value: 0.4482248717070594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  36%|███▌      | 18/50 [1:33:12<3:35:30, 404.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-18 23:57:18,356] Trial 17 finished with value: 0.4486674489879712 and parameters: {'learning_rate': 0.1679565174411024, 'max_depth': 8, 'subsample': 0.902561365241769, 'colsample_bytree': 0.6867835810382348, 'min_child_weight': 4, 'gamma': 0.2774349246149336}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [23:57:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  38%|███▊      | 19/50 [1:39:42<3:26:36, 399.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:03:48,501] Trial 18 finished with value: 0.4474766394812665 and parameters: {'learning_rate': 0.17116274282038066, 'max_depth': 8, 'subsample': 0.8164985231132093, 'colsample_bytree': 0.7082285622310209, 'min_child_weight': 5, 'gamma': 0.3266530793409319}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:03:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  40%|████      | 20/50 [1:43:03<2:50:06, 340.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:07:09,581] Trial 19 finished with value: 0.44617914644173895 and parameters: {'learning_rate': 0.23592808581482966, 'max_depth': 9, 'subsample': 0.9263195492968642, 'colsample_bytree': 0.6481520225044018, 'min_child_weight': 5, 'gamma': 0.4987744165753944}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  42%|████▏     | 21/50 [1:49:56<2:55:04, 362.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:14:03,177] Trial 20 finished with value: 0.44780087126779544 and parameters: {'learning_rate': 0.16559934594956055, 'max_depth': 8, 'subsample': 0.8526158100939742, 'colsample_bytree': 0.716432617064646, 'min_child_weight': 4, 'gamma': 0.27523359293890864}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:14:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  44%|████▍     | 22/50 [1:57:14<2:59:39, 384.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:21:21,226] Trial 21 finished with value: 0.4478979823602458 and parameters: {'learning_rate': 0.16245861811622345, 'max_depth': 8, 'subsample': 0.8576283231243884, 'colsample_bytree': 0.7041998867633258, 'min_child_weight': 4, 'gamma': 0.27563564181444283}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:21:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  46%|████▌     | 23/50 [2:06:12<3:13:52, 430.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:30:18,993] Trial 22 finished with value: 0.4472579002103886 and parameters: {'learning_rate': 0.1080960514244972, 'max_depth': 8, 'subsample': 0.7787502640925242, 'colsample_bytree': 0.6474282025386171, 'min_child_weight': 4, 'gamma': 0.2671667367840878}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:30:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  48%|████▊     | 24/50 [2:14:50<3:17:58, 456.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:38:56,546] Trial 23 finished with value: 0.4485239842600804 and parameters: {'learning_rate': 0.16386302288548302, 'max_depth': 9, 'subsample': 0.9464758896558133, 'colsample_bytree': 0.5943115049522005, 'min_child_weight': 4, 'gamma': 0.3824539988162086}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:39:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  50%|█████     | 25/50 [2:21:01<2:59:38, 431.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:45:07,673] Trial 24 finished with value: 0.4469388620368015 and parameters: {'learning_rate': 0.221073106943959, 'max_depth': 9, 'subsample': 0.9433640595377895, 'colsample_bytree': 0.5945603070177917, 'min_child_weight': 5, 'gamma': 0.3960579091017219}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:45:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 17. Best value: 0.448667:  52%|█████▏    | 26/50 [2:27:46<2:49:21, 423.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:51:52,952] Trial 25 finished with value: 0.44850438356600836 and parameters: {'learning_rate': 0.17886252292194565, 'max_depth': 9, 'subsample': 0.9469758108588843, 'colsample_bytree': 0.6068505350940014, 'min_child_weight': 2, 'gamma': 0.3786956648799554}. Best is trial 17 with value: 0.4486674489879712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:51:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  54%|█████▍    | 27/50 [2:35:31<2:47:04, 435.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 00:59:37,942] Trial 26 finished with value: 0.44873207501081935 and parameters: {'learning_rate': 0.1882429387491997, 'max_depth': 9, 'subsample': 0.9525393735184826, 'colsample_bytree': 0.6030490048831125, 'min_child_weight': 2, 'gamma': 0.3772433852924712}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:59:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  56%|█████▌    | 28/50 [2:39:11<2:16:01, 370.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:03:17,490] Trial 27 finished with value: 0.44516826655500136 and parameters: {'learning_rate': 0.2505367141078649, 'max_depth': 9, 'subsample': 0.8663051029461731, 'colsample_bytree': 0.607831796851698, 'min_child_weight': 2, 'gamma': 0.3650183935078106}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:03:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  58%|█████▊    | 29/50 [2:44:41<2:05:35, 358.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:08:48,039] Trial 28 finished with value: 0.44672287826013085 and parameters: {'learning_rate': 0.19867382655950205, 'max_depth': 9, 'subsample': 0.9563434555340938, 'colsample_bytree': 0.6834802804689404, 'min_child_weight': 2, 'gamma': 0.46427336876928904}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:08:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  60%|██████    | 30/50 [2:53:30<2:16:39, 409.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:17:37,250] Trial 29 finished with value: 0.44793447217827986 and parameters: {'learning_rate': 0.13224226038842746, 'max_depth': 9, 'subsample': 0.7692025068575065, 'colsample_bytree': 0.753222641809145, 'min_child_weight': 1, 'gamma': 0.4064592303124276}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  62%|██████▏   | 31/50 [3:01:00<2:13:33, 421.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:25:06,526] Trial 30 finished with value: 0.44178975614825633 and parameters: {'learning_rate': 0.10141043553287875, 'max_depth': 5, 'subsample': 0.9975066892741238, 'colsample_bytree': 0.5755517032294799, 'min_child_weight': 6, 'gamma': 0.3565160348047928}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:25:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  64%|██████▍   | 32/50 [3:07:57<2:06:08, 420.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:32:04,066] Trial 31 finished with value: 0.44786381877846165 and parameters: {'learning_rate': 0.1817987018963626, 'max_depth': 9, 'subsample': 0.9547958528668692, 'colsample_bytree': 0.6203338002566967, 'min_child_weight': 2, 'gamma': 0.39190800781923774}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:32:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  66%|██████▌   | 33/50 [3:13:14<1:50:20, 389.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:37:21,109] Trial 32 finished with value: 0.4460998659055615 and parameters: {'learning_rate': 0.21491212370022714, 'max_depth': 9, 'subsample': 0.8978290601798106, 'colsample_bytree': 0.5554181569136579, 'min_child_weight': 3, 'gamma': 0.23375575252337824}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:37:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  68%|██████▊   | 34/50 [3:22:03<1:55:00, 431.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:46:09,889] Trial 33 finished with value: 0.4483678185343568 and parameters: {'learning_rate': 0.14566157786302403, 'max_depth': 8, 'subsample': 0.9550290489328506, 'colsample_bytree': 0.6171491653698745, 'min_child_weight': 2, 'gamma': 0.36657164851197066}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:46:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  70%|███████   | 35/50 [3:29:03<1:46:59, 427.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:53:10,130] Trial 34 finished with value: 0.447402288968319 and parameters: {'learning_rate': 0.18007247311795693, 'max_depth': 9, 'subsample': 0.9258979723545709, 'colsample_bytree': 0.6775023478269687, 'min_child_weight': 4, 'gamma': 0.4591777404419045}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:53:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  72%|███████▏  | 36/50 [3:35:07<1:35:20, 408.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 01:59:13,541] Trial 35 finished with value: 0.4450928635033711 and parameters: {'learning_rate': 0.22128943167248272, 'max_depth': 8, 'subsample': 0.8836621084967574, 'colsample_bytree': 0.5108930562159777, 'min_child_weight': 1, 'gamma': 0.3131590971153374}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [01:59:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  74%|███████▍  | 37/50 [3:43:02<1:32:50, 428.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:07:08,486] Trial 36 finished with value: 0.4463250723829256 and parameters: {'learning_rate': 0.2028616303180359, 'max_depth': 7, 'subsample': 0.8306061140758407, 'colsample_bytree': 0.7482219556408889, 'min_child_weight': 5, 'gamma': 0.2006249981860075}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 26. Best value: 0.448732:  76%|███████▌  | 38/50 [3:50:08<1:25:34, 427.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:14:15,034] Trial 37 finished with value: 0.44766614537103566 and parameters: {'learning_rate': 0.1856884654016532, 'max_depth': 9, 'subsample': 0.9581483577468191, 'colsample_bytree': 0.5386395840552151, 'min_child_weight': 7, 'gamma': 0.42902682062607816}. Best is trial 26 with value: 0.44873207501081935.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:14:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 38. Best value: 0.449124:  78%|███████▊  | 39/50 [3:58:53<1:23:46, 456.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:22:59,654] Trial 38 finished with value: 0.4491239999575015 and parameters: {'learning_rate': 0.11569470683239357, 'max_depth': 9, 'subsample': 0.9161478771644366, 'colsample_bytree': 0.5788715071187444, 'min_child_weight': 3, 'gamma': 0.37979243312321914}. Best is trial 38 with value: 0.4491239999575015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:23:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 38. Best value: 0.449124:  80%|████████  | 40/50 [4:07:58<1:20:33, 483.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:32:04,773] Trial 39 finished with value: 0.4478701652978259 and parameters: {'learning_rate': 0.11982710226934488, 'max_depth': 8, 'subsample': 0.9161436271115126, 'colsample_bytree': 0.5681197671838552, 'min_child_weight': 3, 'gamma': 0.33769527056044935}. Best is trial 38 with value: 0.4491239999575015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:32:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 38. Best value: 0.449124:  82%|████████▏ | 41/50 [4:18:12<1:18:22, 522.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:42:18,526] Trial 40 finished with value: 0.44654628223775705 and parameters: {'learning_rate': 0.0698920351393028, 'max_depth': 9, 'subsample': 0.634372929767149, 'colsample_bytree': 0.590907686502372, 'min_child_weight': 7, 'gamma': 0.29576033170829025}. Best is trial 38 with value: 0.4491239999575015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:42:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 41. Best value: 0.449497:  84%|████████▍ | 42/50 [4:27:40<1:11:29, 536.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:51:46,661] Trial 41 finished with value: 0.4494970395365124 and parameters: {'learning_rate': 0.14851305449554678, 'max_depth': 9, 'subsample': 0.9309273399644609, 'colsample_bytree': 0.5001049153727103, 'min_child_weight': 2, 'gamma': 0.37041954148072287}. Best is trial 41 with value: 0.4494970395365124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:51:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 41. Best value: 0.449497:  86%|████████▌ | 43/50 [4:35:00<59:11, 507.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 02:59:06,688] Trial 42 finished with value: 0.4487828430748334 and parameters: {'learning_rate': 0.15272243598944063, 'max_depth': 9, 'subsample': 0.9720663686857024, 'colsample_bytree': 0.5018518995924887, 'min_child_weight': 4, 'gamma': 0.41565851980780455}. Best is trial 41 with value: 0.4494970395365124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [02:59:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 41. Best value: 0.449497:  88%|████████▊ | 44/50 [4:43:22<50:33, 505.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:07:28,441] Trial 43 finished with value: 0.44779717262892416 and parameters: {'learning_rate': 0.14821404583434772, 'max_depth': 8, 'subsample': 0.9761159685426631, 'colsample_bytree': 0.5038718325127148, 'min_child_weight': 3, 'gamma': 0.45554753732239633}. Best is trial 41 with value: 0.4494970395365124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [03:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 41. Best value: 0.449497:  90%|█████████ | 45/50 [4:52:59<43:56, 527.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:17:06,218] Trial 44 finished with value: 0.44947756492893765 and parameters: {'learning_rate': 0.11267338677403678, 'max_depth': 9, 'subsample': 0.8546841165665947, 'colsample_bytree': 0.5343650755086629, 'min_child_weight': 2, 'gamma': 0.4074276582582925}. Best is trial 41 with value: 0.4494970395365124.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [03:17:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 45. Best value: 0.449681:  92%|█████████▏| 46/50 [5:02:34<36:05, 541.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:26:40,725] Trial 45 finished with value: 0.44968115633967476 and parameters: {'learning_rate': 0.1141648221029631, 'max_depth': 9, 'subsample': 0.8604942318943458, 'colsample_bytree': 0.528809325492026, 'min_child_weight': 1, 'gamma': 0.41663601859599436}. Best is trial 45 with value: 0.44968115633967476.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [03:26:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 45. Best value: 0.449681:  94%|█████████▍| 47/50 [5:09:31<25:12, 504.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:33:37,716] Trial 46 finished with value: 0.44199210871487454 and parameters: {'learning_rate': 0.11608554528525518, 'max_depth': 5, 'subsample': 0.8060462826617186, 'colsample_bytree': 0.5350070943551128, 'min_child_weight': 1, 'gamma': 0.4881511806527416}. Best is trial 45 with value: 0.44968115633967476.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [03:33:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 45. Best value: 0.449681:  96%|█████████▌| 48/50 [5:16:04<15:41, 470.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:40:10,497] Trial 47 finished with value: 0.43957185741791566 and parameters: {'learning_rate': 0.09069659087031776, 'max_depth': 3, 'subsample': 0.8429989692331331, 'colsample_bytree': 0.519375955315789, 'min_child_weight': 1, 'gamma': 0.43306925014913966}. Best is trial 45 with value: 0.44968115633967476.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [03:40:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 45. Best value: 0.449681:  98%|█████████▊| 49/50 [5:25:59<08:28, 508.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:50:05,682] Trial 48 finished with value: 0.4480967108309956 and parameters: {'learning_rate': 0.06489814565824638, 'max_depth': 9, 'subsample': 0.875508265359589, 'colsample_bytree': 0.5003474697660149, 'min_child_weight': 2, 'gamma': 0.4086309975587149}. Best is trial 45 with value: 0.44968115633967476.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [03:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 45. Best value: 0.449681: 100%|██████████| 50/50 [5:34:01<00:00, 400.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 03:58:08,114] Trial 49 finished with value: 0.4455192170222717 and parameters: {'learning_rate': 0.13704130882962504, 'max_depth': 7, 'subsample': 0.709933737863388, 'colsample_bytree': 0.5468805202001132, 'min_child_weight': 8, 'gamma': 0.4159234769726423}. Best is trial 45 with value: 0.44968115633967476.\n",
      "\n",
      "Tuning complete.\n",
      "Best trial F1 score: 0.4497\n",
      "Best parameters found:\n",
      "{'learning_rate': 0.1141648221029631, 'max_depth': 9, 'subsample': 0.8604942318943458, 'colsample_bytree': 0.528809325492026, 'min_child_weight': 1, 'gamma': 0.41663601859599436}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- Hyperparameter Tuning with Optuna ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Define the objective function for Optuna to optimize.\n",
    "    A 'trial' is a single run with a specific set of hyperparameters.\n",
    "    \"\"\"\n",
    "    # 1. Suggest a set of hyperparameters for this trial\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': 1000, # High n_estimators, will use early stopping\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'early_stopping_rounds':50,\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5)\n",
    "    }\n",
    "\n",
    "    # 2. Train the XGBoost model with the suggested params\n",
    "    model = xgb.XGBClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=False) # Keep the output clean during tuning\n",
    "\n",
    "    # 3. Evaluate the model and find the best F1 score\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # We need to find the best threshold for *this specific trial*\n",
    "    thresholds = np.linspace(0, 0.5, 26) # Check a smaller range of thresholds to speed up tuning\n",
    "    f1_scores = [f1_score(y_val, y_pred_proba > t) for t in thresholds]\n",
    "    \n",
    "    best_f1 = np.max(f1_scores)\n",
    "    \n",
    "    # 4. Return the score to be maximized\n",
    "    return best_f1\n",
    "\n",
    "# --- Run the study ---\n",
    "# We want to MAXIMIZE the F1 score, so we set direction='maximize'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start the optimization. n_trials=50 is a good starting point.\n",
    "# For a serious attempt, you might run 100-200 trials.\n",
    "print(\"Starting hyperparameter tuning for XGBoost...\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# --- Print the results ---\n",
    "print(\"\\nTuning complete.\")\n",
    "print(f\"Best trial F1 score: {study.best_value:.4f}\")\n",
    "print(\"Best parameters found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebd821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re-training XGBoost with the best found parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:51:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRe-training XGBoost with the best found parameters...\")\n",
    "\n",
    "# 1. Retrieve and update best parameters\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False,\n",
    "})\n",
    "# High upper bound, early stopping will cut it down\n",
    "best_params['n_estimators'] = 2000\n",
    "\n",
    "# 2. Initialize model with constructor-based early stopping\n",
    "final_xgb_tuned = xgb.XGBClassifier(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=100  # ✔️ Must go here, not in fit()\n",
    ")\n",
    "\n",
    "# (Optional) Alternatively, with callback interface in constructor:\n",
    "# early_stop = EarlyStopping(rounds=100, save_best=True, metric_name='logloss')\n",
    "# final_xgb_tuned = xgb.XGBClassifier(\n",
    "#     **best_params,\n",
    "#     random_state=42,\n",
    "#     callbacks=[early_stop]\n",
    "# )\n",
    "\n",
    "# 3. Train model with validation monitor\n",
    "final_xgb_tuned.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"📈 Early stopping triggered at iteration: {final_xgb_tuned.best_iteration}\")\n",
    "\n",
    "# 4. Determine optimal F1 threshold\n",
    "print(\"\\nFinding the best F1 threshold for the tuned model...\")\n",
    "y_val_proba = final_xgb_tuned.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.linspace(0, 0.5, 51)\n",
    "f1_scores = [f1_score(y_val, y_val_proba > t) for t in thresholds]\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(f\"Best F1 Score on validation: {best_f1:.4f} at threshold {best_threshold:.4f}\")\n",
    "\n",
    "# 5. Generate the final submission\n",
    "print(\"\\nGenerating final submission file with the tuned model...\")\n",
    "test_proba = final_xgb_tuned.predict_proba(X_test)[:, 1]\n",
    "test_data['reorder_prediction_binary_tuned'] = (test_proba > best_threshold).astype(int)\n",
    "\n",
    "preds = test_data[test_data['reorder_prediction_binary_tuned'] == 1]\n",
    "submission = (\n",
    "    preds\n",
    "    .groupby('order_id')['product_id']\n",
    "    .apply(lambda x: ' '.join(map(str, x)))\n",
    "    .reset_index()\n",
    "    .rename(columns={'product_id': 'products'})\n",
    ")\n",
    "\n",
    "submission = test_orders[['order_id']].merge(submission, on='order_id', how='left')\n",
    "submission['products'] = submission['products'].fillna('None')\n",
    "\n",
    "submission_filename = 'submission_xgb_tuned.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\n✔ Submission file '{submission_filename}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320392c9",
   "metadata": {},
   "source": [
    "The top competitors realized that using a single, global F1 threshold (like the 0.22 we found) is a major weakness. A user who typically buys 20 items should have more predicted reorders than a user who buys 3. The best way to proceed is with Dynamic Thresholding, also called a \"Top-N\" strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4539fc7d",
   "metadata": {},
   "source": [
    "Instead of asking \"Which products have a probability > 0.22?\", we will ask a smarter question for each user:\n",
    "\"Based on this user's history, they typically reorder N items. What are the N products with the highest probability from my model?\"\n",
    "This personalizes the size of the predicted shopping basket for every single user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33466ebd",
   "metadata": {},
   "source": [
    "The Plan\n",
    "Estimate N: For each user, we will estimate their expected number of reorders (N) based on their prior order history. A simple and effective way is to calculate the average number of items they reordered in their past baskets.\n",
    "Generate Submission: For each order_id in the test set, we will take the N products with the highest predicted probabilities from your already-trained tuned XGBoost model and submit those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89b9b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Re-training the one final, tuned XGBoost model... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [11:15:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.528809325492026, device=None,\n",
       "              early_stopping_rounds=100, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=0.41663601859599436, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1141648221029631,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.528809325492026, device=None,\n",
       "              early_stopping_rounds=100, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=0.41663601859599436, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1141648221029631,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.528809325492026, device=None,\n",
       "              early_stopping_rounds=100, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None, feature_weights=None,\n",
       "              gamma=0.41663601859599436, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1141648221029631,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 4: Re-train the FINAL Tuned XGBoost Model ---\n",
    "print(\"\\n Re-training the one final, tuned XGBoost model... ---\")\n",
    "\n",
    "# These are the best parameters you found from your Optuna run\n",
    "best_params = {\n",
    "    'learning_rate': 0.1141648221029631,\n",
    "    'max_depth': 9,\n",
    "    'subsample': 0.8604942318943458,\n",
    "    'colsample_bytree': 0.528809325492026,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0.41663601859599436,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False,\n",
    "    'n_estimators': 2000,\n",
    "    'early_stopping_rounds': 100\n",
    "}\n",
    "\n",
    "# Initialize and train the model using the syntax that works for your environment\n",
    "final_xgb_tuned = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "final_xgb_tuned.fit(X_train, y_train,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79a38f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating expected number of reorders (N) for each user...\n",
      "Done. Example of user 'N' values:\n",
      "   user_id  expected_reorders_n\n",
      "0        1                    5\n",
      "1        2                    8\n",
      "2        3                    5\n",
      "3        4                    1\n",
      "4        5                    5\n",
      "\n",
      "Generating new submission file using Top-N strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_20768\\2512050276.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['expected_reorders_n'].fillna(global_avg_reorders, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission_xgb_tuned_top_n.csv' created successfully.\n",
      "This file was generated using the dynamic Top-N strategy.\n",
      "It is very likely to be your highest-scoring submission yet.\n",
      "\n",
      "Submission Head:\n",
      "   order_id                                           products\n",
      "0        17                                        13107 21463\n",
      "1        34                       47766 16083 39475 2596 21137\n",
      "2       137                24852 23794 38689 41787 25890 29594\n",
      "3       182  39275 5479 13629 9337 47672 11520 32109 41149 ...\n",
      "4       257          24852 49235 29837 27104 27966 37646 30233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_20768\\2512050276.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_n_submission = test_data.groupby('order_id').apply(get_top_n_products).reset_index(name='products')\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Estimate 'N' (Expected Reorders) for Each User ---\n",
    "print(\"Estimating expected number of reorders (N) for each user...\")\n",
    "\n",
    "# We need to go back to our merged prior data to see historical reorders\n",
    "# If you don't have 'prior_merged' loaded, you will need to recreate it.\n",
    "# Let's assume 'prior_merged' is available.\n",
    "\n",
    "# Filter for only the products that were reordered\n",
    "prior_reorders = prior_merged[prior_merged['reordered'] == 1]\n",
    "\n",
    "# Count how many reordered items were in each specific order\n",
    "reorders_per_order = prior_reorders.groupby(['user_id', 'order_id']).size().reset_index(name='reorder_count')\n",
    "\n",
    "# Now, calculate the average number of reordered items for each user\n",
    "# We use .mean() for the average and round it to the nearest integer.\n",
    "user_expected_reorders = reorders_per_order.groupby('user_id')['reorder_count'].mean().round().astype(int).reset_index()\n",
    "user_expected_reorders.rename(columns={'reorder_count': 'expected_reorders_n'}, inplace=True)\n",
    "\n",
    "print(\"Done. Example of user 'N' values:\")\n",
    "print(user_expected_reorders.head())\n",
    "\n",
    "\n",
    "# --- Step 2: Generate Submission using the Top-N Strategy ---\n",
    "print(\"\\nGenerating new submission file using Top-N strategy...\")\n",
    "\n",
    "# First, ensure our test data has the raw prediction probabilities.\n",
    "# Let's add the probabilities from our best tuned model to test_data\n",
    "test_predictions_tuned = final_xgb_tuned.predict_proba(X_test)[:, 1]\n",
    "test_data['reorder_probability'] = test_predictions_tuned\n",
    "\n",
    "# Add the 'expected_reorders_n' to our test data\n",
    "test_data = test_data.merge(user_expected_reorders, on='user_id', how='left')\n",
    "\n",
    "# For any new users in the test set (who have no prior orders), their 'N' will be NaN.\n",
    "# We need a fallback. A common strategy is to use the overall average number of reorders.\n",
    "global_avg_reorders = int(user_expected_reorders['expected_reorders_n'].mean())\n",
    "test_data['expected_reorders_n'].fillna(global_avg_reorders, inplace=True)\n",
    "test_data['expected_reorders_n'] = test_data['expected_reorders_n'].astype(int)\n",
    "\n",
    "\n",
    "# Now, for each order, get the top N products\n",
    "# We define a function to apply to each group of products in an order\n",
    "def get_top_n_products(df):\n",
    "    # Sort products by probability, descending\n",
    "    df_sorted = df.sort_values(by='reorder_probability', ascending=False)\n",
    "    \n",
    "    # Get the number of products to return (N)\n",
    "    # All rows in this df have the same N, so we can take the first\n",
    "    n = df_sorted['expected_reorders_n'].iloc[0]\n",
    "    \n",
    "    # If N is 0, return 'None'\n",
    "    if n == 0:\n",
    "        return 'None'\n",
    "    \n",
    "    # Get the top N product_ids and join them into a string\n",
    "    top_products = df_sorted.head(n)['product_id']\n",
    "    return ' '.join(map(str, top_products))\n",
    "\n",
    "# Group by order_id and apply our function\n",
    "top_n_submission = test_data.groupby('order_id').apply(get_top_n_products).reset_index(name='products')\n",
    "\n",
    "# Save the new submission file\n",
    "submission_filename_top_n = 'submission_xgb_tuned_top_n.csv'\n",
    "top_n_submission.to_csv(submission_filename_top_n, index=False)\n",
    "\n",
    "print(f\"\\nSubmission file '{submission_filename_top_n}' created successfully.\")\n",
    "print(\"This file was generated using the dynamic Top-N strategy.\")\n",
    "print(\"It is very likely to be your highest-scoring submission yet.\")\n",
    "print(\"\\nSubmission Head:\")\n",
    "print(top_n_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effbd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1328775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Re-loading all raw data... ---\n",
      "\n",
      "--- Step 2: Building the FULL set of original features... ---\n",
      "\n",
      "--- Step 3: Engineering High-Resolution Temporal Features... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_5692\\624832793.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  user_order_timeline['days_since_prior_order'].fillna(0, inplace=True)\n",
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_5692\\624832793.py:65: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  up_time_features['user_product_avg_purchase_gap'].fillna(-1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Re-assembling final data with ALL features... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_5692\\624832793.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['reordered'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: Re-training the tuned XGBoost model... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:58:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 6: Evaluating the new, feature-enriched model... ---\n",
      "Your previous best F1 score (with original features) was: 0.4497\n",
      "The new F1 score with ALL features (original + temporal) is: 0.4506\n",
      "SUCCESS! The new temporal features provided a measurable improvement.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- Step 1: Re-load All Raw Data ---\n",
    "print(\"--- Step 1: Re-loading all raw data... ---\")\n",
    "orders = pd.read_csv('./data/orders.csv')\n",
    "products = pd.read_csv('./data/products.csv')\n",
    "order_products_prior = pd.read_csv('./data/order_products__prior.csv')\n",
    "order_products_train = pd.read_csv('./data/order_products__train.csv')\n",
    "\n",
    "# --- Step 2: Full Original Feature Engineering ---\n",
    "print(\"\\n--- Step 2: Building the FULL set of original features... ---\")\n",
    "prior_orders_subset = orders[orders['eval_set'] == 'prior']\n",
    "prior_merged = order_products_prior.merge(prior_orders_subset, on='order_id', how='left')\n",
    "\n",
    "# P-Features\n",
    "product_features = prior_merged.groupby('product_id').agg(\n",
    "    product_total_orders=('order_id', 'count'),\n",
    "    product_reorder_rate=('reordered', 'mean'),\n",
    "    product_unique_users=('user_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# U-Features\n",
    "user_features = orders[orders['eval_set'] != 'test'].groupby('user_id').agg(\n",
    "    user_total_orders=('order_number', 'max'),\n",
    "    user_avg_days_since_prior=('days_since_prior_order', 'mean')\n",
    ").reset_index()\n",
    "user_product_stats = prior_merged.groupby('user_id').agg(\n",
    "    user_total_products=('product_id', 'count'),\n",
    "    user_reorder_ratio=('reordered', 'mean'),\n",
    "    user_distinct_products=('product_id', 'nunique')\n",
    ").reset_index()\n",
    "user_features = user_features.merge(user_product_stats, on='user_id', how='left')\n",
    "\n",
    "# UP-Features\n",
    "up_features = prior_merged.groupby(['user_id', 'product_id']).agg(\n",
    "    up_total_purchases=('order_id', 'count'),\n",
    "    up_last_order_number=('order_number', 'max')\n",
    ").reset_index()\n",
    "up_features = up_features.merge(user_features[['user_id', 'user_total_orders']], on='user_id', how='left')\n",
    "up_features['up_orders_since_last_purchase'] = up_features['user_total_orders'] - up_features['up_last_order_number']\n",
    "up_features['up_reorder_rate'] = up_features['up_total_purchases'] / up_features['user_total_orders']\n",
    "\n",
    "\n",
    "# --- Step 3: ADVANCED TEMPORAL FEATURE ENGINEERING ---\n",
    "print(\"\\n--- Step 3: Engineering High-Resolution Temporal Features... ---\")\n",
    "# (This section is already complete and correct)\n",
    "user_order_timeline = orders.loc[orders['eval_set'] == 'prior', ['user_id', 'order_id', 'days_since_prior_order']].copy()\n",
    "user_order_timeline['days_since_prior_order'].fillna(0, inplace=True)\n",
    "user_order_timeline['user_order_timeline_days'] = user_order_timeline.groupby('user_id')['days_since_prior_order'].cumsum()\n",
    "prior_merged_full_time = prior_merged.merge(user_order_timeline[['order_id', 'user_order_timeline_days']], on='order_id', how='left')\n",
    "prior_merged_full_time.sort_values(by=['user_id', 'product_id', 'user_order_timeline_days'], inplace=True)\n",
    "prior_merged_full_time['days_between_purchases'] = prior_merged_full_time.groupby(['user_id', 'product_id'])['user_order_timeline_days'].diff()\n",
    "up_time_features = prior_merged_full_time.groupby(['user_id', 'product_id']).agg(\n",
    "    user_product_avg_purchase_gap=('days_between_purchases', 'mean'),\n",
    "    last_purchase_day=('user_order_timeline_days', 'max')\n",
    ").reset_index()\n",
    "user_final_day = user_order_timeline.groupby('user_id')['user_order_timeline_days'].max().reset_index()\n",
    "user_final_day.rename(columns={'user_order_timeline_days': 'user_total_days'}, inplace=True)\n",
    "up_time_features = up_time_features.merge(user_final_day, on='user_id', how='left')\n",
    "up_time_features['days_since_product_last_purchased'] = up_time_features['user_total_days'] - up_time_features['last_purchase_day']\n",
    "up_time_features['user_product_avg_purchase_gap'].fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "# --- Step 4: Re-assemble Final Training and Test Sets with ALL Features ---\n",
    "print(\"\\n--- Step 4: Re-assembling final data with ALL features... ---\")\n",
    "train_orders = orders[orders['eval_set'] == 'train']\n",
    "train_labels = order_products_train.merge(train_orders[['order_id', 'user_id']], on='order_id', how='left')\n",
    "train_labels['reordered'] = 1\n",
    "candidates = up_features[['user_id', 'product_id']]\n",
    "candidates = candidates[candidates['user_id'].isin(train_orders['user_id'])]\n",
    "data = candidates.merge(train_labels[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n",
    "data['reordered'].fillna(0, inplace=True)\n",
    "\n",
    "# Merge ALL features\n",
    "data = data.merge(up_features, on=['user_id', 'product_id'], how='left')\n",
    "data = data.merge(user_features, on='user_id', how='left')\n",
    "data = data.merge(product_features, on='product_id', how='left')\n",
    "data = data.merge(up_time_features, on=['user_id', 'product_id'], how='left') # <-- MERGING NEW FEATURES\n",
    "\n",
    "test_orders = orders[orders['eval_set'] == 'test']\n",
    "test_data = up_features[up_features['user_id'].isin(test_orders['user_id'])]\n",
    "test_data = test_data.merge(user_features, on='user_id', how='left')\n",
    "test_data = test_data.merge(product_features, on='product_id', how='left')\n",
    "test_data = test_data.merge(up_time_features, on=['user_id', 'product_id'], how='left')\n",
    "test_data = test_data.merge(test_orders[['user_id', 'order_id']], on='user_id', how='left')\n",
    "\n",
    "X = data.drop(['user_id', 'product_id', 'reordered'], axis=1)\n",
    "y = data['reordered']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_test = test_data[X_train.columns]\n",
    "del data, prior_merged\n",
    "\n",
    "\n",
    "# --- Step 5: Re-train the Tuned XGBoost Model on the ENRICHED Data ---\n",
    "print(\"\\n--- Step 5: Re-training the tuned XGBoost model... ---\")\n",
    "best_params = {\n",
    "    'learning_rate': 0.1141648221029631, 'max_depth': 9, 'subsample': 0.8604942318943458,\n",
    "    'colsample_bytree': 0.528809325492026, 'min_child_weight': 1, 'gamma': 0.41663601859599436,\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'logloss', 'use_label_encoder': False, 'n_estimators': 2000, 'early_stopping_rounds': 100\n",
    "}\n",
    "final_xgb_tuned_v2 = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "# CORRECTED FIT METHOD for your version of XGBoost\n",
    "final_xgb_tuned_v2.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "\n",
    "# --- Step 6: Evaluate the New Model ---\n",
    "print(\"\\n--- Step 6: Evaluating the new, feature-enriched model... ---\")\n",
    "y_val_pred_proba_v2 = final_xgb_tuned_v2.predict_proba(X_val)[:, 1]\n",
    "thresholds = np.linspace(0, 0.5, 51)\n",
    "f1_scores_v2 = [f1_score(y_val, y_val_pred_proba_v2 > t) for t in thresholds]\n",
    "best_f1_v2 = np.max(f1_scores_v2)\n",
    "best_threshold_v2 = thresholds[np.argmax(f1_scores_v2)]\n",
    "\n",
    "print(f\"Your previous best F1 score (with original features) was: 0.4497\")\n",
    "print(f\"The new F1 score with ALL features (original + temporal) is: {best_f1_v2:.4f}\")\n",
    "\n",
    "if best_f1_v2 > 0.4497:\n",
    "    print(\"SUCCESS! The new temporal features provided a measurable improvement.\")\n",
    "else:\n",
    "    print(\"The new features did not improve the score on top of the full original set. This is a valuable finding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c41375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the final, most advanced submission file...\n",
      "Recreating 'prior_merged' to calculate Top-N statistics...\n",
      "'prior_merged' is now available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_5692\\1222659417.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['expected_reorders_n'].fillna(global_avg_reorders, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission_advanced_features_top_n.csv' created successfully.\n",
      "This file contains predictions from your best model and your best submission logic.\n",
      "Congratulations on completing this advanced feature engineering cycle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_5692\\1222659417.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_n_submission_v2 = test_data.groupby('order_id').apply(get_top_n_products).reset_index(name='products')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Final Step: Generate Submission with the Best Model and Best Logic (CORRECTED) ---\n",
    "\n",
    "print(\"Generating the final, most advanced submission file...\")\n",
    "\n",
    "# --- FIX: Re-create 'prior_merged' as it was deleted to save memory ---\n",
    "print(\"Recreating 'prior_merged' to calculate Top-N statistics...\")\n",
    "prior_orders_subset = orders[orders['eval_set'] == 'prior']\n",
    "prior_merged = order_products_prior.merge(prior_orders_subset, on='order_id', how='left')\n",
    "print(\"'prior_merged' is now available.\")\n",
    "\n",
    "\n",
    "# --- Continue with the Top-N logic as before ---\n",
    "# Let's quickly recreate the 'expected_reorders_n' DataFrame.\n",
    "prior_reorders = prior_merged[prior_merged['reordered'] == 1]\n",
    "reorders_per_order = prior_reorders.groupby(['user_id', 'order_id']).size().reset_index(name='reorder_count')\n",
    "user_expected_reorders = reorders_per_order.groupby('user_id')['reorder_count'].mean().round().astype(int).reset_index()\n",
    "user_expected_reorders.rename(columns={'reorder_count': 'expected_reorders_n'}, inplace=True)\n",
    "\n",
    "# Add the expected_reorders_n to our latest test_data\n",
    "# The 'test_data' and 'X_test' objects from the previous cell are still in memory\n",
    "test_data = test_data.merge(user_expected_reorders, on='user_id', how='left')\n",
    "global_avg_reorders = int(user_expected_reorders['expected_reorders_n'].mean())\n",
    "test_data['expected_reorders_n'].fillna(global_avg_reorders, inplace=True)\n",
    "test_data['expected_reorders_n'] = test_data['expected_reorders_n'].astype(int)\n",
    "\n",
    "# Use our new, more powerful model ('final_xgb_tuned_v2') to predict probabilities\n",
    "test_predictions_v2 = final_xgb_tuned_v2.predict_proba(X_test)[:, 1]\n",
    "test_data['reorder_probability'] = test_predictions_v2\n",
    "\n",
    "# --- Use the Top-N Logic ---\n",
    "def get_top_n_products(df):\n",
    "    df_sorted = df.sort_values(by='reorder_probability', ascending=False)\n",
    "    n = df_sorted['expected_reorders_n'].iloc[0]\n",
    "    if n == 0:\n",
    "        return 'None'\n",
    "    top_products = df_sorted.head(n)['product_id']\n",
    "    return ' '.join(map(str, top_products))\n",
    "\n",
    "# Group by order_id and apply the function\n",
    "top_n_submission_v2 = test_data.groupby('order_id').apply(get_top_n_products).reset_index(name='products')\n",
    "\n",
    "# Save the new submission file with a new name\n",
    "submission_filename_final = 'submission_advanced_features_top_n.csv'\n",
    "top_n_submission_v2.to_csv(submission_filename_final, index=False)\n",
    "\n",
    "print(f\"\\nSubmission file '{submission_filename_final}' created successfully.\")\n",
    "print(\"This file contains predictions from your best model and your best submission logic.\")\n",
    "print(\"Congratulations on completing this advanced feature engineering cycle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93ca5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Training the Prod2Vec Model ---\n",
      "Preparing order sentences...\n",
      "Training Word2Vec model... (This may take a few minutes)\n",
      "Extracting vectors into a DataFrame...\n",
      "Prod2Vec features created successfully.\n",
      "Shape of new features: (49222, 20)\n",
      "            p2v_vec_0  p2v_vec_1  p2v_vec_2  p2v_vec_3  p2v_vec_4  p2v_vec_5  \\\n",
      "product_id                                                                     \n",
      "24852       -0.002681   0.001182   0.025517   0.045046  -0.046515  -0.035584   \n",
      "13176        0.036559   0.025351   0.033788   0.003814   0.031754  -0.017027   \n",
      "21137       -0.048018   0.025036  -0.043798  -0.021959  -0.000175  -0.001481   \n",
      "21903       -0.007888   0.001607  -0.020703  -0.038413  -0.007540   0.012349   \n",
      "47209       -0.004283   0.014133   0.027007   0.035263  -0.028516   0.009294   \n",
      "\n",
      "            p2v_vec_6  p2v_vec_7  p2v_vec_8  p2v_vec_9  p2v_vec_10  \\\n",
      "product_id                                                           \n",
      "24852        0.032294   0.044865  -0.025077  -0.018817    0.036903   \n",
      "13176       -0.004732   0.028843  -0.037608  -0.019681   -0.037558   \n",
      "21137       -0.038306   0.048074   0.024910   0.046166   -0.040790   \n",
      "21903       -0.004440   0.027668  -0.013715   0.011300    0.027279   \n",
      "47209        0.030444  -0.023990  -0.015536   0.033988    0.008157   \n",
      "\n",
      "            p2v_vec_11  p2v_vec_12  p2v_vec_13  p2v_vec_14  p2v_vec_15  \\\n",
      "product_id                                                               \n",
      "24852        -0.007667   -0.022683    0.032770   -0.024301   -0.009080   \n",
      "13176        -0.004650    0.047691   -0.036596   -0.011669   -0.009689   \n",
      "21137         0.022479   -0.020685    0.004123    0.042493   -0.022311   \n",
      "21903         0.041730   -0.007269   -0.046041    0.021853    0.002859   \n",
      "47209         0.000950    0.017368    0.001089    0.048094    0.025303   \n",
      "\n",
      "            p2v_vec_16  p2v_vec_17  p2v_vec_18  p2v_vec_19  \n",
      "product_id                                                  \n",
      "24852         0.014383    0.004959   -0.041426   -0.047244  \n",
      "13176         0.040387   -0.029654    0.000226   -0.023769  \n",
      "21137         0.022588   -0.033935   -0.017742    0.046993  \n",
      "21903         0.037210   -0.004066   -0.013192   -0.043765  \n",
      "47209        -0.044587   -0.035208    0.004507    0.031963  \n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(\"--- Step 1: Training the Prod2Vec Model ---\")\n",
    "\n",
    "# 1a. Prepare the 'sentences'\n",
    "# We need a list of lists, where each inner list is an order containing product_ids as strings.\n",
    "print(\"Preparing order sentences...\")\n",
    "# To be safe, let's ensure prior_merged is available\n",
    "try:\n",
    "    prior_merged\n",
    "except NameError:\n",
    "    print(\"Recreating 'prior_merged'...\")\n",
    "    prior_orders_subset = orders[orders['eval_set'] == 'prior']\n",
    "    prior_merged = order_products_prior.merge(prior_orders_subset, on='order_id', how='left')\n",
    "\n",
    "# Convert product_ids to string, then group into lists\n",
    "p2v_sentences = prior_merged.groupby('order_id')['product_id'].apply(lambda x: list(map(str, x))).tolist()\n",
    "\n",
    "# 1b. Train the Word2Vec model\n",
    "print(\"Training Word2Vec model... (This may take a few minutes)\")\n",
    "# vector_size: The number of new features we are creating (e.g., 20)\n",
    "# window: How many products before/after to consider as context\n",
    "# min_count: Ignore products that appear less than this many times\n",
    "prod2vec_model = Word2Vec(sentences=p2v_sentences,\n",
    "                          vector_size=20,\n",
    "                          window=5,\n",
    "                          min_count=3,\n",
    "                          workers=-1) # Use all available CPU cores\n",
    "\n",
    "# 1c. Create a DataFrame from the learned vectors\n",
    "print(\"Extracting vectors into a DataFrame...\")\n",
    "prod2vec_features = pd.DataFrame(prod2vec_model.wv.vectors,\n",
    "                                 index=prod2vec_model.wv.key_to_index.keys())\n",
    "prod2vec_features.columns = [f'p2v_vec_{i}' for i in range(prod2vec_model.vector_size)]\n",
    "prod2vec_features.index.name = 'product_id'\n",
    "\n",
    "# The index is a string, so convert it to int to be mergeable\n",
    "prod2vec_features.index = prod2vec_features.index.astype(int)\n",
    "\n",
    "print(\"Prod2Vec features created successfully.\")\n",
    "print(\"Shape of new features:\", prod2vec_features.shape)\n",
    "print(prod2vec_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722b7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running the full pipeline with ALL features (Original + Temporal + Prod2Vec) ---\n",
      "Building original and temporal features...\n",
      "Assembling final data with Prod2Vec features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhir\\AppData\\Local\\Temp\\ipykernel_5692\\3824427487.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-training the tuned XGBoost model on the ULTIMATE feature set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the new, ULTIMATE model...\n",
      "\n",
      "Your previous best F1 score was: 0.4506\n",
      "The new F1 score with Prod2Vec features is: 0.4353\n",
      "The Prod2Vec features did not improve the score. This is also a valuable finding!\n"
     ]
    }
   ],
   "source": [
    "# --- The Definitive Script: All Features Combined ---\n",
    "print(\"\\n--- Running the full pipeline with ALL features (Original + Temporal + Prod2Vec) ---\")\n",
    "\n",
    "# --- Step 2.1: Re-build Full Feature Set (from previous steps) ---\n",
    "print(\"Building original and temporal features...\")\n",
    "# (This is a condensed version of the code from our last step)\n",
    "prior_orders_subset = orders[orders['eval_set'] == 'prior']\n",
    "prior_merged = order_products_prior.merge(prior_orders_subset, on='order_id', how='left')\n",
    "# Full P-Features, U-Features, UP-Features\n",
    "product_features = prior_merged.groupby('product_id').agg(product_reorder_rate=('reordered', 'mean')).reset_index()\n",
    "user_features = orders[orders['eval_set'] != 'test'].groupby('user_id').agg(user_total_orders=('order_number', 'max')).reset_index()\n",
    "up_features = prior_merged.groupby(['user_id', 'product_id']).agg(up_total_purchases=('order_id', 'count')).reset_index()\n",
    "# Full Temporal Features\n",
    "user_order_timeline = orders.loc[orders['eval_set'] == 'prior', ['user_id', 'order_id', 'days_since_prior_order']].copy()\n",
    "user_order_timeline['days_since_prior_order'] = user_order_timeline['days_since_prior_order'].fillna(0)\n",
    "user_order_timeline['user_order_timeline_days'] = user_order_timeline.groupby('user_id')['days_since_prior_order'].cumsum()\n",
    "prior_merged_full_time = prior_merged.merge(user_order_timeline[['order_id', 'user_order_timeline_days']], on='order_id', how='left')\n",
    "prior_merged_full_time.sort_values(by=['user_id', 'product_id', 'user_order_timeline_days'], inplace=True)\n",
    "prior_merged_full_time['days_between_purchases'] = prior_merged_full_time.groupby(['user_id', 'product_id'])['user_order_timeline_days'].diff()\n",
    "up_time_features = prior_merged_full_time.groupby(['user_id', 'product_id']).agg(user_product_avg_purchase_gap=('days_between_purchases', 'mean'), last_purchase_day=('user_order_timeline_days', 'max')).reset_index()\n",
    "user_final_day = user_order_timeline.groupby('user_id')['user_order_timeline_days'].max().reset_index(name='user_total_days')\n",
    "up_time_features = up_time_features.merge(user_final_day, on='user_id', how='left')\n",
    "up_time_features['days_since_product_last_purchased'] = up_time_features['user_total_days'] - up_time_features['last_purchase_day']\n",
    "up_time_features['user_product_avg_purchase_gap'] = up_time_features['user_product_avg_purchase_gap'].fillna(-1)\n",
    "\n",
    "\n",
    "# --- Step 2.2: Re-assemble Data, now with Prod2Vec ---\n",
    "print(\"Assembling final data with Prod2Vec features...\")\n",
    "train_orders = orders[orders['eval_set'] == 'train']\n",
    "train_labels = order_products_train.merge(train_orders[['order_id', 'user_id']], on='order_id', how='left')\n",
    "train_labels['reordered'] = 1\n",
    "candidates = up_features[['user_id', 'product_id']]\n",
    "candidates = candidates[candidates['user_id'].isin(train_orders['user_id'])]\n",
    "data = candidates.merge(train_labels[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n",
    "data['reordered'] = data['reordered'].fillna(0)\n",
    "\n",
    "# Merge ALL features (Original, Temporal, AND Prod2Vec)\n",
    "data = data.merge(up_features, on=['user_id', 'product_id'], how='left')\n",
    "data = data.merge(user_features, on='user_id', how='left')\n",
    "data = data.merge(product_features, on='product_id', how='left')\n",
    "data = data.merge(up_time_features, on=['user_id', 'product_id'], how='left')\n",
    "data = data.merge(prod2vec_features, on='product_id', how='left') # <-- MERGING THE NEW EMBEDDINGS\n",
    "\n",
    "# Assemble test data\n",
    "test_orders = orders[orders['eval_set'] == 'test']\n",
    "test_data = up_features[up_features['user_id'].isin(test_orders['user_id'])]\n",
    "test_data = test_data.merge(user_features, on='user_id', how='left')\n",
    "test_data = test_data.merge(product_features, on='product_id', how='left')\n",
    "test_data = test_data.merge(up_time_features, on=['user_id', 'product_id'], how='left')\n",
    "test_data = test_data.merge(prod2vec_features, on='product_id', how='left') # <-- MERGING THE NEW EMBEDDINGS\n",
    "test_data = test_data.merge(test_orders[['user_id', 'order_id']], on='user_id', how='left')\n",
    "\n",
    "X = data.drop(['user_id', 'product_id', 'reordered'], axis=1)\n",
    "y = data['reordered']\n",
    "# Fill any NaNs that might have been introduced from the p2v merge (for rare products)\n",
    "X.fillna(0, inplace=True) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_test = test_data[X_train.columns]\n",
    "X_test.fillna(0, inplace=True)\n",
    "del data, prior_merged\n",
    "\n",
    "\n",
    "# --- Step 2.3: Re-train and Evaluate the ULTIMATE Model ---\n",
    "print(\"Re-training the tuned XGBoost model on the ULTIMATE feature set...\")\n",
    "best_params = { # Using the same best params\n",
    "    'learning_rate': 0.1141648221029631, 'max_depth': 9, 'subsample': 0.8604942318943458,\n",
    "    'colsample_bytree': 0.528809325492026, 'min_child_weight': 1, 'gamma': 0.41663601859599436,\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'logloss', 'use_label_encoder': False, 'n_estimators': 2000, 'early_stopping_rounds': 100\n",
    "}\n",
    "final_xgb_tuned_v3 = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "final_xgb_tuned_v3.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# --- Step 2.4: Final Evaluation ---\n",
    "print(\"Evaluating the new, ULTIMATE model...\")\n",
    "y_val_pred_proba_v3 = final_xgb_tuned_v3.predict_proba(X_val)[:, 1]\n",
    "thresholds = np.linspace(0, 0.5, 51)\n",
    "f1_scores_v3 = [f1_score(y_val, y_val_pred_proba_v3 > t) for t in thresholds]\n",
    "best_f1_v3 = np.max(f1_scores_v3)\n",
    "\n",
    "print(f\"\\nYour previous best F1 score was: 0.4506\")\n",
    "print(f\"The new F1 score with Prod2Vec features is: {best_f1_v3:.4f}\")\n",
    "\n",
    "if best_f1_v3 > 0.4506:\n",
    "    print(\"MASSIVE SUCCESS! The Prod2Vec embeddings provided a significant improvement.\")\n",
    "else:\n",
    "    print(\"The Prod2Vec features did not improve the score. This is also a valuable finding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b72f1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-21 14:23:12,504] A new study created in memory with name: no-name-3f218f64-b2b2-4aa8-82bb-1899696fbc3a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NEW hyperparameter tuning for the ULTIMATE feature set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:23:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:   3%|▎         | 1/30 [30:13<14:36:21, 1813.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 14:53:25,674] Trial 0 finished with value: 0.43625478824712705 and parameters: {'learning_rate': 0.013482517845144195, 'max_depth': 9, 'subsample': 0.6982964294755112, 'colsample_bytree': 0.5844548676657558, 'min_child_weight': 6, 'gamma': 0.38082157377094805}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:53:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:   7%|▋         | 2/30 [36:28<7:31:30, 967.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 14:59:41,231] Trial 1 finished with value: 0.4350188574197054 and parameters: {'learning_rate': 0.09821044299975439, 'max_depth': 8, 'subsample': 0.6675045218871803, 'colsample_bytree': 0.5819755601810276, 'min_child_weight': 5, 'gamma': 0.27032967180827894}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:59:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:  10%|█         | 3/30 [39:45<4:37:02, 615.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 15:02:58,167] Trial 2 finished with value: 0.43534325605335966 and parameters: {'learning_rate': 0.17132960160743108, 'max_depth': 9, 'subsample': 0.9257451958481883, 'colsample_bytree': 0.5369174186568997, 'min_child_weight': 12, 'gamma': 0.8881311582323258}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [15:03:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:  13%|█▎        | 4/30 [44:25<3:29:24, 483.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 15:07:38,411] Trial 3 finished with value: 0.4343226975600285 and parameters: {'learning_rate': 0.1624896281260634, 'max_depth': 7, 'subsample': 0.759710481690609, 'colsample_bytree': 0.48003968664569374, 'min_child_weight': 4, 'gamma': 0.8705661223951987}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [15:07:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:  17%|█▋        | 5/30 [47:34<2:37:04, 377.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 15:10:47,031] Trial 4 finished with value: 0.43434294691352066 and parameters: {'learning_rate': 0.17681247761874427, 'max_depth': 10, 'subsample': 0.8160730154378755, 'colsample_bytree': 0.5482316253647213, 'min_child_weight': 12, 'gamma': 0.4360560243216155}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [15:10:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:  20%|██        | 6/30 [54:53<2:39:12, 398.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 15:18:05,869] Trial 5 finished with value: 0.4355647672833704 and parameters: {'learning_rate': 0.12076176290816047, 'max_depth': 6, 'subsample': 0.6063041235560225, 'colsample_bytree': 0.41139398125481963, 'min_child_weight': 5, 'gamma': 0.6371864310686265}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [15:18:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.436255:  23%|██▎       | 7/30 [1:16:14<4:23:12, 686.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 15:39:26,667] Trial 6 finished with value: 0.43612621367020293 and parameters: {'learning_rate': 0.013103102347145231, 'max_depth': 10, 'subsample': 0.812320577732736, 'colsample_bytree': 0.698832116898858, 'min_child_weight': 2, 'gamma': 0.17921985720027667}. Best is trial 0 with value: 0.43625478824712705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [15:39:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 7. Best value: 0.436587:  27%|██▋       | 8/30 [1:37:26<5:20:08, 873.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 16:00:39,044] Trial 7 finished with value: 0.4365873724096718 and parameters: {'learning_rate': 0.020647719942689144, 'max_depth': 7, 'subsample': 0.9401117636513305, 'colsample_bytree': 0.5631561668814455, 'min_child_weight': 14, 'gamma': 0.2230573251394441}. Best is trial 7 with value: 0.4365873724096718.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [16:00:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 7. Best value: 0.436587:  30%|███       | 9/30 [1:40:04<3:47:22, 649.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 16:03:17,403] Trial 8 finished with value: 0.43408436827503954 and parameters: {'learning_rate': 0.19301498754043186, 'max_depth': 10, 'subsample': 0.7708341533925761, 'colsample_bytree': 0.7172067659941189, 'min_child_weight': 10, 'gamma': 0.12324402895895636}. Best is trial 7 with value: 0.4365873724096718.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [16:03:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 7. Best value: 0.436587:  33%|███▎      | 10/30 [1:46:49<3:11:21, 574.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 16:10:02,242] Trial 9 finished with value: 0.4357642929564503 and parameters: {'learning_rate': 0.12017727424883913, 'max_depth': 6, 'subsample': 0.9758737450716449, 'colsample_bytree': 0.514951519171216, 'min_child_weight': 12, 'gamma': 0.5077525919098664}. Best is trial 7 with value: 0.4365873724096718.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [16:10:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 7. Best value: 0.436587:  37%|███▋      | 11/30 [2:01:32<3:31:41, 668.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 16:24:44,791] Trial 10 finished with value: 0.43573331398422355 and parameters: {'learning_rate': 0.05898656384882057, 'max_depth': 5, 'subsample': 0.8953011050291197, 'colsample_bytree': 0.7890971513432121, 'min_child_weight': 15, 'gamma': 0.020931358609248496}. Best is trial 7 with value: 0.4365873724096718.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [16:24:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  40%|████      | 12/30 [2:23:54<4:21:59, 873.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 16:47:06,649] Trial 11 finished with value: 0.4366920080792495 and parameters: {'learning_rate': 0.012195783861243259, 'max_depth': 8, 'subsample': 0.7031135693615356, 'colsample_bytree': 0.6369646457701883, 'min_child_weight': 8, 'gamma': 0.348453578248489}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [16:47:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  43%|████▎     | 13/30 [2:36:49<3:59:00, 843.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 17:00:01,651] Trial 12 finished with value: 0.4363932380577491 and parameters: {'learning_rate': 0.049532572949187025, 'max_depth': 7, 'subsample': 0.883168132396897, 'colsample_bytree': 0.6581685992810977, 'min_child_weight': 8, 'gamma': 0.6350490533439955}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [17:00:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  47%|████▋     | 14/30 [2:46:57<3:26:01, 772.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 17:10:10,367] Trial 13 finished with value: 0.43607431885983 and parameters: {'learning_rate': 0.04793734882178633, 'max_depth': 8, 'subsample': 0.692465511434907, 'colsample_bytree': 0.6349170914467857, 'min_child_weight': 9, 'gamma': 0.286123888333681}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [17:10:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  50%|█████     | 15/30 [3:11:34<4:06:13, 984.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 17:34:47,178] Trial 14 finished with value: 0.43618023839852527 and parameters: {'learning_rate': 0.03409887194839388, 'max_depth': 7, 'subsample': 0.9967134734097732, 'colsample_bytree': 0.4438736709087904, 'min_child_weight': 15, 'gamma': 0.0058196861058348315}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [17:34:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  53%|█████▎    | 16/30 [3:19:57<3:15:58, 839.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 17:43:10,324] Trial 15 finished with value: 0.43573480165030265 and parameters: {'learning_rate': 0.08401428061193965, 'max_depth': 8, 'subsample': 0.8492164516505771, 'colsample_bytree': 0.6507795280898159, 'min_child_weight': 7, 'gamma': 0.6032438099782386}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [17:43:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  57%|█████▋    | 17/30 [3:32:49<2:57:30, 819.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 17:56:01,691] Trial 16 finished with value: 0.4361838726245506 and parameters: {'learning_rate': 0.07264607443735213, 'max_depth': 6, 'subsample': 0.7442588404283605, 'colsample_bytree': 0.7463541755645341, 'min_child_weight': 10, 'gamma': 0.3095837830647098}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [17:56:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  60%|██████    | 18/30 [3:49:04<2:53:14, 866.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 18:12:17,162] Trial 17 finished with value: 0.4362341026848799 and parameters: {'learning_rate': 0.026522457702558937, 'max_depth': 9, 'subsample': 0.6034176979425829, 'colsample_bytree': 0.6070602966556938, 'min_child_weight': 1, 'gamma': 0.17672109748147447}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [18:12:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  63%|██████▎   | 19/30 [4:07:11<2:50:57, 932.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 18:30:23,982] Trial 18 finished with value: 0.43600631294153014 and parameters: {'learning_rate': 0.036654256618319586, 'max_depth': 5, 'subsample': 0.9358322525891674, 'colsample_bytree': 0.4893900991223943, 'min_child_weight': 13, 'gamma': 0.4948486972817644}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [18:30:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  67%|██████▋   | 20/30 [4:11:58<2:03:05, 738.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 18:35:10,721] Trial 19 finished with value: 0.43582334021858293 and parameters: {'learning_rate': 0.07019515259853515, 'max_depth': 7, 'subsample': 0.7220314949622338, 'colsample_bytree': 0.6883863619218664, 'min_child_weight': 10, 'gamma': 0.9980848223190103}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [18:35:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  70%|███████   | 21/30 [4:13:53<1:22:43, 551.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 18:37:05,936] Trial 20 finished with value: 0.4348972361496706 and parameters: {'learning_rate': 0.15058540689323957, 'max_depth': 8, 'subsample': 0.6452940864785208, 'colsample_bytree': 0.6079680120986416, 'min_child_weight': 8, 'gamma': 0.11609708739006888}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [18:37:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  73%|███████▎  | 22/30 [4:28:06<1:25:35, 641.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 18:51:18,978] Trial 21 finished with value: 0.436539044537628 and parameters: {'learning_rate': 0.010869278263391326, 'max_depth': 7, 'subsample': 0.8769980779257782, 'colsample_bytree': 0.657816337813547, 'min_child_weight': 8, 'gamma': 0.6720588640672942}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [18:51:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  77%|███████▋  | 23/30 [4:43:32<1:24:50, 727.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 19:06:44,955] Trial 22 finished with value: 0.43618636742385897 and parameters: {'learning_rate': 0.01093141181136839, 'max_depth': 6, 'subsample': 0.866683942932314, 'colsample_bytree': 0.6372018441726205, 'min_child_weight': 7, 'gamma': 0.7453261727941947}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [19:06:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  80%|████████  | 24/30 [4:54:57<1:11:27, 714.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 19:18:10,188] Trial 23 finished with value: 0.4364019055729171 and parameters: {'learning_rate': 0.037593957508639635, 'max_depth': 7, 'subsample': 0.9414886188036906, 'colsample_bytree': 0.5691086776797402, 'min_child_weight': 9, 'gamma': 0.3865868247214005}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [19:18:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  83%|████████▎ | 25/30 [5:06:43<59:19, 711.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 19:29:55,849] Trial 24 finished with value: 0.43645454959138935 and parameters: {'learning_rate': 0.02252313511330573, 'max_depth': 8, 'subsample': 0.842871013564188, 'colsample_bytree': 0.6767401547850691, 'min_child_weight': 4, 'gamma': 0.7371018174295967}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [19:30:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  87%|████████▋ | 26/30 [5:13:37<41:30, 622.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 19:36:50,381] Trial 25 finished with value: 0.43585214682552426 and parameters: {'learning_rate': 0.05341826613555754, 'max_depth': 9, 'subsample': 0.9101969635827244, 'colsample_bytree': 0.740549463521755, 'min_child_weight': 11, 'gamma': 0.5480306491414468}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [19:36:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  90%|█████████ | 27/30 [5:26:46<33:37, 672.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 19:49:59,198] Trial 26 finished with value: 0.43624361037056614 and parameters: {'learning_rate': 0.020137445226718946, 'max_depth': 7, 'subsample': 0.9555445395522387, 'colsample_bytree': 0.6259697855758491, 'min_child_weight': 7, 'gamma': 0.7134651036385582}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [19:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  93%|█████████▎| 28/30 [5:38:40<22:49, 684.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 20:01:52,624] Trial 27 finished with value: 0.4358594026110332 and parameters: {'learning_rate': 0.03640681120866887, 'max_depth': 6, 'subsample': 0.7863715888467495, 'colsample_bytree': 0.5521750480775174, 'min_child_weight': 13, 'gamma': 0.2376702602916972}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [20:01:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692:  97%|█████████▋| 29/30 [5:43:59<09:35, 575.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 20:07:11,611] Trial 28 finished with value: 0.4358603947890542 and parameters: {'learning_rate': 0.0668455576933666, 'max_depth': 8, 'subsample': 0.8404170496743468, 'colsample_bytree': 0.6666924287150677, 'min_child_weight': 8, 'gamma': 0.35976591699822225}. Best is trial 11 with value: 0.4366920080792495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhir\\anaconda3\\envs\\instacart-mba\\lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [20:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 11. Best value: 0.436692: 100%|██████████| 30/30 [5:59:32<00:00, 719.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 20:22:44,842] Trial 29 finished with value: 0.4362199412076526 and parameters: {'learning_rate': 0.010517444052498817, 'max_depth': 9, 'subsample': 0.7282658385434602, 'colsample_bytree': 0.5981832993171019, 'min_child_weight': 6, 'gamma': 0.37560936917708626}. Best is trial 11 with value: 0.4366920080792495.\n",
      "\n",
      "New tuning complete.\n",
      "Your previous best F1 score was: 0.4506\n",
      "Best F1 score found in this new study: 0.4367\n",
      "Best parameters for the ULTIMATE dataset:\n",
      "{'learning_rate': 0.012195783861243259, 'max_depth': 8, 'subsample': 0.7031135693615356, 'colsample_bytree': 0.6369646457701883, 'min_child_weight': 8, 'gamma': 0.348453578248489}\n",
      "\n",
      "Even after re-tuning, the embeddings didn't help. We now know to discard them and stick to our previous best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- The Correct Next Step: Re-tune Hyperparameters on the ULTIMATE Feature Set ---\n",
    "\n",
    "# The X_train, X_val, y_train, y_val from the previous step (with all features) are still in memory.\n",
    "# We will use them to find new, optimal parameters.\n",
    "\n",
    "def objective_v3(trial):\n",
    "    \"\"\"\n",
    "    An objective function for Optuna, specifically for our new, wide dataset.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2), # Slightly lower range might be better for complex data\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.8), # Give a wider range for this crucial param\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 1.0),\n",
    "        'early_stopping_rounds': 100\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=False)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    thresholds = np.linspace(0.1, 0.4, 31) # Focus the search on the relevant threshold area\n",
    "    f1_scores = [f1_score(y_val, y_pred_proba > t) for t in thresholds]\n",
    "    \n",
    "    best_f1 = np.max(f1_scores)\n",
    "    return best_f1\n",
    "\n",
    "# --- Run the new tuning study ---\n",
    "# Let's start a new study for these new features\n",
    "study_v3 = optuna.create_study(direction='maximize')\n",
    "\n",
    "print(\"Starting NEW hyperparameter tuning for the ULTIMATE feature set...\")\n",
    "# n_trials=30 is a reasonable start to see if we can beat the old score.\n",
    "# If results are promising, you could run for more.\n",
    "study_v3.optimize(objective_v3, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "# --- Print the results ---\n",
    "print(\"\\nNew tuning complete.\")\n",
    "print(f\"Your previous best F1 score was: 0.4506\")\n",
    "print(f\"Best F1 score found in this new study: {study_v3.best_value:.4f}\")\n",
    "print(\"Best parameters for the ULTIMATE dataset:\")\n",
    "print(study_v3.best_params)\n",
    "\n",
    "if study_v3.best_value > 0.4506:\n",
    "    print(\"\\nSUCCESS! By re-tuning, we have confirmed the new features are valuable.\")\n",
    "else:\n",
    "    print(\"\\nEven after re-tuning, the embeddings didn't help. We now know to discard them and stick to our previous best model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7713f69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating the FINAL, SYNCHRONIZED set of deployment artifacts ---\n",
      "Building the champion feature set (Original + Temporal)...\n",
      "Creating the unified feature store...\n",
      "Saving the final, robust artifacts...\n",
      "\n",
      "Artifact generation complete. The API is now ready.\n"
     ]
    }
   ],
   "source": [
    "# --- The FINAL Artifact Generation Script ---\n",
    "\n",
    "print(\"--- Creating the FINAL, SYNCHRONIZED set of deployment artifacts ---\")\n",
    "\n",
    "# --- Step A: Re-build the EXACT feature set for the champion model ---\n",
    "# This mirrors the logic that produced your best F1 score of 0.4506\n",
    "print(\"Building the champion feature set (Original + Temporal)...\")\n",
    "prior_orders_subset = orders[orders['eval_set'] == 'prior']\n",
    "prior_merged = order_products_prior.merge(prior_orders_subset, on='order_id', how='left')\n",
    "\n",
    "# Full P, U, and UP features\n",
    "product_features = prior_merged.groupby('product_id').agg(product_reorder_rate=('reordered', 'mean'), product_total_orders=('order_id', 'count'), product_unique_users=('user_id', 'nunique')).reset_index()\n",
    "user_features = orders[orders['eval_set'] != 'test'].groupby('user_id').agg(user_total_orders=('order_number', 'max'), user_avg_days_since_prior=('days_since_prior_order', 'mean')).reset_index()\n",
    "user_product_stats = prior_merged.groupby('user_id').agg(user_total_products=('product_id', 'count'), user_reorder_ratio=('reordered', 'mean'), user_distinct_products=('product_id', 'nunique')).reset_index()\n",
    "user_features = user_features.merge(user_product_stats, on='user_id', how='left')\n",
    "up_features = prior_merged.groupby(['user_id', 'product_id']).agg(up_total_purchases=('order_id', 'count'), up_last_order_number=('order_number', 'max')).reset_index()\n",
    "up_features = up_features.merge(user_features[['user_id', 'user_total_orders']], on='user_id', how='left') # This creates user_total_orders_x\n",
    "up_features['up_orders_since_last_purchase'] = up_features['user_total_orders'] - up_features['up_last_order_number']\n",
    "up_features['up_reorder_rate'] = up_features['up_total_purchases'] / up_features['user_total_orders']\n",
    "\n",
    "# Temporal Features\n",
    "user_order_timeline = orders.loc[orders['eval_set'] == 'prior', ['user_id', 'order_id', 'days_since_prior_order']].copy()\n",
    "user_order_timeline['days_since_prior_order'] = user_order_timeline['days_since_prior_order'].fillna(0)\n",
    "user_order_timeline['user_order_timeline_days'] = user_order_timeline.groupby('user_id')['days_since_prior_order'].cumsum()\n",
    "prior_merged_full_time = prior_merged.merge(user_order_timeline[['order_id', 'user_order_timeline_days']], on='order_id', how='left')\n",
    "prior_merged_full_time.sort_values(by=['user_id', 'product_id', 'user_order_timeline_days'], inplace=True)\n",
    "prior_merged_full_time['days_between_purchases'] = prior_merged_full_time.groupby(['user_id', 'product_id'])['user_order_timeline_days'].diff()\n",
    "up_time_features = prior_merged_full_time.groupby(['user_id', 'product_id']).agg(user_product_avg_purchase_gap=('days_between_purchases', 'mean'), last_purchase_day=('user_order_timeline_days', 'max')).reset_index()\n",
    "user_final_day = user_order_timeline.groupby('user_id')['user_order_timeline_days'].max().reset_index(name='user_total_days')\n",
    "up_time_features = up_time_features.merge(user_final_day, on='user_id', how='left')\n",
    "up_time_features['days_since_product_last_purchased'] = up_time_features['user_total_days'] - up_time_features['last_purchase_day']\n",
    "up_time_features['user_product_avg_purchase_gap'] = up_time_features['user_product_avg_purchase_gap'].fillna(-1)\n",
    "\n",
    "# Top-N Feature\n",
    "prior_reorders = prior_merged[prior_merged['reordered'] == 1]\n",
    "reorders_per_order = prior_reorders.groupby(['user_id', 'order_id']).size().reset_index(name='reorder_count')\n",
    "user_expected_reorders = reorders_per_order.groupby('user_id')['reorder_count'].mean().round().astype(int).reset_index(name='expected_reorders_n')\n",
    "\n",
    "# --- Step B: Create the SINGLE, UNIFIED feature store ---\n",
    "print(\"Creating the unified feature store...\")\n",
    "# Get all possible candidates (all users, all products they've ever bought)\n",
    "all_candidates = up_features[['user_id', 'product_id']]\n",
    "# Merge all features onto this master list\n",
    "feature_store = all_candidates.merge(up_features, on=['user_id', 'product_id'], how='left')\n",
    "feature_store = feature_store.merge(user_features, on='user_id', how='left')\n",
    "feature_store = feature_store.merge(product_features, on='product_id', how='left')\n",
    "feature_store = feature_store.merge(up_time_features, on=['user_id', 'product_id'], how='left')\n",
    "feature_store = feature_store.merge(user_expected_reorders, on='user_id', how='left')\n",
    "feature_store.fillna(0, inplace=True)\n",
    "\n",
    "# --- Step C: Save the ONLY artifacts the API needs ---\n",
    "print(\"Saving the final, robust artifacts...\")\n",
    "# 1. The Model\n",
    "final_xgb_tuned_v2.save_model(\"instacart_xgb_model.json\")\n",
    "# 2. The Unified Feature Store\n",
    "feature_store.to_parquet(\"feature_store.parquet\")\n",
    "# 3. The list of columns, derived from the final feature store\n",
    "model_columns = [col for col in feature_store.columns if col not in ['user_id', 'product_id', 'expected_reorders_n']]\n",
    "with open('model_columns.txt', 'w') as f:\n",
    "    f.write(','.join(model_columns))\n",
    "\n",
    "print(\"\\nArtifact generation complete. The API is now ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c2fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the product name lookup artifact...\n",
      "Artifact 'products_lookup.parquet' created successfully.\n",
      "You can now restart your Flask API.\n"
     ]
    }
   ],
   "source": [
    "# --- Final Artifact: Product Name Lookup ---\n",
    "\n",
    "print(\"Creating the product name lookup artifact...\")\n",
    "\n",
    "# products DataFrame should be loaded from the previous steps\n",
    "# We only need the ID and the name\n",
    "product_name_lookup = products[['product_id', 'product_name']]\n",
    "\n",
    "# Save it in the efficient Parquet format\n",
    "product_name_lookup.to_parquet('products_lookup.parquet')\n",
    "\n",
    "print(\"Artifact 'products_lookup.parquet' created successfully.\")\n",
    "print(\"You can now restart your Flask API.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instacart-mba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
